{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– LangGraph å¤š Agent ç³»ç»Ÿå®žæˆ˜\n",
    "\n",
    "æœ¬ Notebook å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph æž„å»ºå¤æ‚çš„å¤š Agent åä½œç³»ç»Ÿã€‚\n",
    "\n",
    "## ðŸ“‹ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "- LangGraph åŸºç¡€æ¦‚å¿µï¼ˆStateã€Nodeã€Edgeï¼‰\n",
    "- æž„å»ºçŠ¶æ€æœºå·¥ä½œæµ\n",
    "- å¤š Agent åä½œæ¨¡å¼\n",
    "- æ¡ä»¶è·¯ç”±å’Œå†³ç­–\n",
    "- å®žæˆ˜æ¡ˆä¾‹ï¼šæ™ºèƒ½å†…å®¹åˆ›ä½œå›¢é˜Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ å®‰è£…ä¾èµ–\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langgraph langchain langchain-openai\n",
    "%pip install -q sentence-transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ é…ç½® DeepSeek API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ é…ç½® DeepSeek API\n",
      "============================================================\n",
      "âš ï¸  è¯·å°†ä¸‹æ–¹çš„ 'your-deepseek-api-key-here' æ›¿æ¢ä¸ºä½ çš„ API Key\n",
      "\n",
      "ðŸ“ èŽ·å– API Key:\n",
      "1. è®¿é—® https://platform.deepseek.com/\n",
      "2. æ³¨å†Œ/ç™»å½•è´¦å·\n",
      "3. åˆ›å»º API Key\n",
      "============================================================\n",
      "\n",
      "âœ… DeepSeek é…ç½®å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"ðŸ”§ é…ç½® DeepSeek API\")\n",
    "print(\"=\"*60)\n",
    "print(\"æœ¬ Notebook ä½¿ç”¨ DeepSeek æ¨¡åž‹ï¼ˆå…¼å®¹ OpenAI APIï¼‰\")\n",
    "print(\"\\nðŸ“ èŽ·å– API Key:\")\n",
    "print(\"1. è®¿é—® https://platform.deepseek.com/\")\n",
    "print(\"2. æ³¨å†Œ/ç™»å½•è´¦å·\")\n",
    "print(\"3. åˆ›å»º API Key\")\n",
    "print(\"\\nðŸ’° è´¹ç”¨è¯´æ˜Ž:\")\n",
    "print(\"DeepSeek æ¯” OpenAI ä¾¿å®œå¾ˆå¤šï¼Œé€‚åˆå­¦ä¹ å’Œå¼€å‘\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ–¹å¼1ï¼šåœ¨ç»ˆç«¯ä¸­è®¾ç½®çŽ¯å¢ƒå˜é‡ï¼ˆæŽ¨èï¼‰\n",
    "# export OPENAI_API_KEY=\"your-deepseek-api-key-here\"\n",
    "# export OPENAI_API_BASE=\"https://api.deepseek.com\"\n",
    "\n",
    "# æ–¹å¼2ï¼šä¸´æ—¶åœ¨ Notebook ä¸­è®¾ç½®ï¼ˆä»…æœ¬æ¬¡è¿è¡Œæœ‰æ•ˆï¼Œä¸ä¼šå½±å“ç³»ç»ŸçŽ¯å¢ƒå˜é‡ï¼‰\n",
    "# å¦‚æžœä½ æ²¡æœ‰åœ¨ç»ˆç«¯è®¾ç½®ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢ä¸¤è¡Œçš„æ³¨é‡Šå¹¶å¡«å…¥ä½ çš„ API Key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-deepseek-api-key-here\"\n",
    "# os.environ[\"OPENAI_API_BASE\"] = \"https://api.deepseek.com\"\n",
    "\n",
    "# æ£€æŸ¥é…ç½®\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.deepseek.com\")\n",
    "\n",
    "if not api_key or api_key == \"your-deepseek-api-key-here\":\n",
    "    print(\"\\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ API Keyï¼\")\n",
    "    print(\"\\nè¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€é…ç½®ï¼š\")\n",
    "    print(\"1. åœ¨ç»ˆç«¯è¿è¡Œï¼š\")\n",
    "    print(\"   export OPENAI_API_KEY='your-actual-api-key'\")\n",
    "    print(\"   export OPENAI_API_BASE='https://api.deepseek.com'\")\n",
    "    print(\"\\n2. æˆ–åœ¨ä¸Šæ–¹å–æ¶ˆæ³¨é‡Šå¹¶å¡«å…¥ä½ çš„ API Key\")\n",
    "else:\n",
    "    # ç¡®ä¿ API Base è®¾ç½®æ­£ç¡®\n",
    "    if not api_base or api_base == \"https://api.openai.com\":\n",
    "        os.environ[\"OPENAI_API_BASE\"] = \"https://api.deepseek.com\"\n",
    "        print(f\"\\nâœ… API Key å·²é…ç½®\")\n",
    "        print(f\"âœ… API Base å·²è®¾ç½®ä¸º: https://api.deepseek.com\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… API Key å·²é…ç½®\")\n",
    "        print(f\"âœ… API Base: {api_base}\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_base=\"https://api.deepseek.com\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"âœ… ä½¿ç”¨æ¨¡åž‹: deepseek-chat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€ã€LangGraph åŸºç¡€æ¦‚å¿µ\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "```\n",
    "State (çŠ¶æ€)\n",
    "   â†“\n",
    "Node (èŠ‚ç‚¹/Agent)\n",
    "   â†“\n",
    "Edge (è¾¹/è½¬æ¢)\n",
    "   â†“\n",
    "Graph (æ•´ä¸ªå·¥ä½œæµ)\n",
    "```\n",
    "\n",
    "### ç®€å•ç¤ºä¾‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡Œæ­¥éª¤ 1\n",
      "æ‰§è¡Œæ­¥éª¤ 2\n",
      "\n",
      "ç»“æžœ:\n",
      "æ¶ˆæ¯: ['æ­¥éª¤1å®Œæˆ', 'æ­¥éª¤2å®Œæˆ']\n",
      "è®¡æ•°: 2\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "\n",
    "# 1. å®šä¹‰çŠ¶æ€\n",
    "class SimpleState(TypedDict):\n",
    "    messages: list[str]\n",
    "    counter: int\n",
    "\n",
    "# 2. å®šä¹‰èŠ‚ç‚¹å‡½æ•°\n",
    "def step1(state: SimpleState):\n",
    "    print(\"æ‰§è¡Œæ­¥éª¤ 1\")\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\"æ­¥éª¤1å®Œæˆ\"],\n",
    "        \"counter\": state[\"counter\"] + 1\n",
    "    }\n",
    "\n",
    "def step2(state: SimpleState):\n",
    "    print(\"æ‰§è¡Œæ­¥éª¤ 2\")\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\"æ­¥éª¤2å®Œæˆ\"],\n",
    "        \"counter\": state[\"counter\"] + 1\n",
    "    }\n",
    "\n",
    "# 3. æž„å»ºå›¾\n",
    "workflow = StateGraph(SimpleState)\n",
    "workflow.add_node(\"step1\", step1)\n",
    "workflow.add_node(\"step2\", step2)\n",
    "\n",
    "# 4. æ·»åŠ è¾¹\n",
    "workflow.set_entry_point(\"step1\")\n",
    "workflow.add_edge(\"step1\", \"step2\")\n",
    "workflow.add_edge(\"step2\", END)\n",
    "\n",
    "# 5. ç¼–è¯‘å¹¶è¿è¡Œ\n",
    "app = workflow.compile()\n",
    "\n",
    "result = app.invoke({\"messages\": [], \"counter\": 0})\n",
    "print(\"\\nç»“æžœ:\")\n",
    "print(f\"æ¶ˆæ¯: {result['messages']}\")\n",
    "print(f\"è®¡æ•°: {result['counter']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 å®šä¹‰çŠ¶æ€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "import operator\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    topic: str\n",
    "    research_notes: str\n",
    "    draft_content: str\n",
    "    final_content: str\n",
    "    messages: Annotated[List, operator.add]\n",
    "    next_agent: str\n",
    "    iteration: int\n",
    "    max_iterations: int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 åˆ›å»ºå„ä¸ª Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent å®šä¹‰å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ç ”ç©¶å‘˜ Agent\n",
    "def researcher_agent(state: AgentState) -> AgentState:\n",
    "    print(\"\\nðŸ“š ç ”ç©¶å‘˜ Agent å·¥ä½œä¸­...\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶å‘˜ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œç ”ç©¶ï¼Œæä¾›å…³é”®è¦ç‚¹å’Œæœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚\n",
    "\n",
    "ä¸»é¢˜ï¼š{topic}\n",
    "\n",
    "è¯·æä¾›ï¼š\n",
    "1. æ ¸å¿ƒæ¦‚å¿µå®šä¹‰\n",
    "2. é‡è¦ç‰¹ç‚¹ï¼ˆ3-5ä¸ªï¼‰\n",
    "3. å®žé™…åº”ç”¨åœºæ™¯\n",
    "4. æ³¨æ„äº‹é¡¹\n",
    "\n",
    "ç ”ç©¶ç¬”è®°ï¼š\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"topic\": state[\"topic\"]})\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"research_notes\": result.content,\n",
    "        \"messages\": [f\"[ç ”ç©¶å‘˜] å®Œæˆç ”ç©¶: {state['topic'][:50]}...\"],\n",
    "        \"next_agent\": \"writer\"\n",
    "    }\n",
    "\n",
    "# ä½œå®¶ Agent\n",
    "def writer_agent(state: AgentState) -> AgentState:\n",
    "    print(\"\\nâœï¸ ä½œå®¶ Agent å·¥ä½œä¸­...\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ä½œå®¶ã€‚åŸºäºŽç ”ç©¶å‘˜æä¾›çš„ç¬”è®°ï¼Œæ’°å†™ä¸€ç¯‡ç»“æž„æ¸…æ™°ã€é€šä¿—æ˜“æ‡‚çš„æ–‡ç« ã€‚\n",
    "\n",
    "ä¸»é¢˜ï¼š{topic}\n",
    "\n",
    "ç ”ç©¶ç¬”è®°ï¼š\n",
    "{research_notes}\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "- ä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜å’Œæ®µè½ç»“æž„\n",
    "- è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé€‚åˆåˆå­¦è€…\n",
    "- åŒ…å«å®žä¾‹è¯´æ˜Ž\n",
    "- å­—æ•°çº¦500å­—\n",
    "\n",
    "æ–‡ç« å†…å®¹ï¼š\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"topic\": state[\"topic\"],\n",
    "        \"research_notes\": state[\"research_notes\"]\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"draft_content\": result.content,\n",
    "        \"messages\": [f\"[ä½œå®¶] å®Œæˆåˆç¨¿æ’°å†™\"],\n",
    "        \"next_agent\": \"editor\"\n",
    "    }\n",
    "\n",
    "# ç¼–è¾‘ Agent\n",
    "def editor_agent(state: AgentState) -> AgentState:\n",
    "    print(\"\\nðŸ” ç¼–è¾‘ Agent å·¥ä½œä¸­...\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–è¾‘ã€‚è¯·å®¡æ ¸å¹¶æ”¹è¿›ä»¥ä¸‹æ–‡ç« ã€‚\n",
    "\n",
    "åŽŸæ–‡ï¼š\n",
    "{draft_content}\n",
    "\n",
    "è¯·ï¼š\n",
    "1. æ£€æŸ¥è¯­æ³•å’Œè¡¨è¾¾\n",
    "2. ä¼˜åŒ–ç»“æž„å’Œé€»è¾‘\n",
    "3. ç¡®ä¿å†…å®¹å‡†ç¡®æ€§\n",
    "4. å¢žå¼ºå¯è¯»æ€§\n",
    "\n",
    "å¦‚æžœæ–‡ç« è´¨é‡å·²ç»å¾ˆå¥½ï¼Œä¿æŒåŽŸæ ·å¹¶æ·»åŠ ç®€çŸ­è¯„ä»·ã€‚\n",
    "å¦‚æžœéœ€è¦æ”¹è¿›ï¼Œè¯·ç›´æŽ¥è¾“å‡ºæ”¹è¿›åŽçš„ç‰ˆæœ¬ã€‚\n",
    "\n",
    "æœ€ç»ˆæ–‡ç« ï¼š\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"draft_content\": state[\"draft_content\"]})\n",
    "    \n",
    "    new_iteration = state[\"iteration\"] + 1\n",
    "    \n",
    "    # å†³å®šæ˜¯å¦éœ€è¦å†æ¬¡è¿­ä»£\n",
    "    if new_iteration >= state[\"max_iterations\"]:\n",
    "        next_agent = \"END\"\n",
    "    else:\n",
    "        # å¯ä»¥æ ¹æ®è´¨é‡è¯„ä¼°å†³å®šæ˜¯å¦ç»§ç»­\n",
    "        next_agent = \"END\"  # ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸€æ¬¡è¿­ä»£åŽç»“æŸ\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"final_content\": result.content,\n",
    "        \"messages\": [f\"[ç¼–è¾‘] å®Œæˆå®¡æ ¸å’Œæ”¹è¿›\"],\n",
    "        \"next_agent\": next_agent,\n",
    "        \"iteration\": new_iteration\n",
    "    }\n",
    "\n",
    "print(\"âœ… Agent å®šä¹‰å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·¥ä½œæµæž„å»ºå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# è·¯ç”±å‡½æ•°ï¼šå†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹\n",
    "def route_agent(state: AgentState) -> str:\n",
    "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
    "    if next_agent == \"END\":\n",
    "        return END\n",
    "    return next_agent\n",
    "\n",
    "# åˆ›å»ºå›¾\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"writer\", writer_agent)\n",
    "workflow.add_node(\"editor\", editor_agent)\n",
    "\n",
    "# è®¾ç½®å…¥å£\n",
    "workflow.set_entry_point(\"researcher\")\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹\n",
    "workflow.add_conditional_edges(\n",
    "    \"researcher\",\n",
    "    route_agent,\n",
    "    {\"writer\": \"writer\", END: END}\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"writer\",\n",
    "    route_agent,\n",
    "    {\"editor\": \"editor\", END: END}\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"editor\",\n",
    "    route_agent,\n",
    "    {\"writer\": \"writer\", END: END}\n",
    ")\n",
    "\n",
    "# ç¼–è¯‘\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"âœ… å·¥ä½œæµæž„å»ºå®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 è¿è¡Œå¤š Agent ç³»ç»Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ å¯åŠ¨å¤š Agent å†…å®¹åˆ›ä½œç³»ç»Ÿ...\n",
      "ðŸ“ ä¸»é¢˜: æ·±åº¦å­¦ä¹ ä¸­çš„ Transformer æž¶æž„\n",
      "\n",
      "============================================================\n",
      "\n",
      "ðŸ“š ç ”ç©¶å‘˜ Agent å·¥ä½œä¸­...\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****here is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# è¿è¡Œå·¥ä½œæµ\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m final_state \u001b[38;5;241m=\u001b[39m app\u001b[38;5;241m.\u001b[39minvoke(initial_state)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸŽ‰ åˆ›ä½œå®Œæˆï¼\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/main.py:3085\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3082\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3083\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3085\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3086\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3087\u001b[0m     config,\n\u001b[1;32m   3088\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3089\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3091\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3092\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3093\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3094\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3095\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3096\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3097\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3098\u001b[0m ):\n\u001b[1;32m   3099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/main.py:2674\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2673\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2674\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2675\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2676\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2677\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2678\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2679\u001b[0m ):\n\u001b[1;32m   2680\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2682\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2683\u001b[0m     )\n\u001b[1;32m   2684\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     run_with_retry(\n\u001b[1;32m    163\u001b[0m         t,\n\u001b[1;32m    164\u001b[0m         retry_policy,\n\u001b[1;32m    165\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    166\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    167\u001b[0m                 _call,\n\u001b[1;32m    168\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    169\u001b[0m                 retry_policy\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    170\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    171\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[1;32m    172\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    173\u001b[0m             ),\n\u001b[1;32m    174\u001b[0m         },\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mresearcher_agent\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      7\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶å‘˜ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œç ”ç©¶ï¼Œæä¾›å…³é”®è¦ç‚¹å’Œæœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mç ”ç©¶ç¬”è®°ï¼š\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstate,\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearch_notes\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ç ”ç©¶å‘˜] å®Œæˆç ”ç©¶: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m50\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:3246\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3244\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3245\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3246\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 395\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    396\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    397\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    398\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    399\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    400\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    401\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    402\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    403\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    404\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 842\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    843\u001b[0m                 m,\n\u001b[1;32m    844\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    845\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    846\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    847\u001b[0m             )\n\u001b[1;32m    848\u001b[0m         )\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m   1092\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1093\u001b[0m     )\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1213\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_response\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1212\u001b[0m         e\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mhttp_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_response_headers\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1218\u001b[0m ):\n\u001b[1;32m   1219\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1208\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[1;32m   1202\u001b[0m             response,\n\u001b[1;32m   1203\u001b[0m             schema\u001b[38;5;241m=\u001b[39moriginal_schema_obj,\n\u001b[1;32m   1204\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mgeneration_info,\n\u001b[1;32m   1205\u001b[0m             output_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_version,\n\u001b[1;32m   1206\u001b[0m         )\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1208\u001b[0m         raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m   1209\u001b[0m         response \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mparse()\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1155\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1158\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m   1159\u001b[0m             {\n\u001b[1;32m   1160\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1161\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1162\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   1163\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1164\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1165\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1166\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1168\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   1169\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   1171\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   1172\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1173\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1174\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m   1175\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1176\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[1;32m   1177\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m   1178\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1179\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[1;32m   1180\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1181\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1182\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1183\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   1184\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1185\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1186\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1187\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1188\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1189\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1190\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1191\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1192\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n\u001b[1;32m   1193\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[1;32m   1194\u001b[0m             },\n\u001b[1;32m   1195\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[1;32m   1197\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[1;32m   1198\u001b[0m         ),\n\u001b[1;32m   1199\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1200\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1201\u001b[0m         ),\n\u001b[1;32m   1202\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1203\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1204\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m   1205\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****here is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}",
      "\u001b[0mDuring task with name 'researcher' and id '37b5b606-3180-d048-fa95-5d67cb7143bf'"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–çŠ¶æ€\n",
    "initial_state = {\n",
    "    \"topic\": \"æ·±åº¦å­¦ä¹ ä¸­çš„ Transformer æž¶æž„\",\n",
    "    \"research_notes\": \"\",\n",
    "    \"draft_content\": \"\",\n",
    "    \"final_content\": \"\",\n",
    "    \"messages\": [],\n",
    "    \"next_agent\": \"researcher\",\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 2\n",
    "}\n",
    "\n",
    "print(\"ðŸš€ å¯åŠ¨å¤š Agent å†…å®¹åˆ›ä½œç³»ç»Ÿ...\")\n",
    "print(f\"ðŸ“ ä¸»é¢˜: {initial_state['topic']}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è¿è¡Œå·¥ä½œæµ\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nðŸŽ‰ åˆ›ä½œå®Œæˆï¼\")\n",
    "print(\"\\nðŸ“‹ å·¥ä½œæµç¨‹:\")\n",
    "for msg in final_state[\"messages\"]:\n",
    "    print(f\"  {msg}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nðŸ“š ç ”ç©¶ç¬”è®°:\")\n",
    "print(final_state[\"research_notes\"][:300] + \"...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nðŸ“„ æœ€ç»ˆæ–‡ç« :\")\n",
    "print(final_state[\"final_content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‰ã€é«˜çº§ç‰¹æ€§ï¼šåŠ¨æ€è·¯ç”±å’Œå¾ªçŽ¯\n",
    "\n",
    "### 3.1 å¸¦è´¨é‡æ£€æŸ¥çš„å¾ªçŽ¯æ”¹è¿›\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è´¨é‡è¯„ä¼° Agent\n",
    "def quality_checker(state: AgentState) -> AgentState:\n",
    "    print(\"\\nðŸŽ¯ è´¨é‡æ£€æŸ¥ Agent å·¥ä½œä¸­...\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"è¯„ä¼°ä»¥ä¸‹æ–‡ç« çš„è´¨é‡ï¼Œå¹¶ç»™å‡º1-10çš„åˆ†æ•°ã€‚\n",
    "\n",
    "æ–‡ç« ï¼š\n",
    "{content}\n",
    "\n",
    "è¯·åªå›žç­”ä¸€ä¸ªæ•°å­—ï¼ˆ1-10ï¼‰å’Œç®€çŸ­è¯„ä»·ï¼ˆä¸€å¥è¯ï¼‰ã€‚\n",
    "æ ¼å¼ï¼šåˆ†æ•°: X, è¯„ä»·: XXX\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"content\": state[\"final_content\"]})\n",
    "    \n",
    "    # ç®€å•è§£æžåˆ†æ•°\n",
    "    try:\n",
    "        score_str = result.content.split(\"åˆ†æ•°:\")[1].split(\",\")[0].strip()\n",
    "        score = int(score_str)\n",
    "    except:\n",
    "        score = 8  # é»˜è®¤åˆ†æ•°\n",
    "    \n",
    "    # å¦‚æžœåˆ†æ•°ä½ŽäºŽ8ä¸”æœªè¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿”å›žç»™ä½œå®¶æ”¹è¿›\n",
    "    new_iteration = state[\"iteration\"] + 1\n",
    "    if score < 8 and new_iteration < state[\"max_iterations\"]:\n",
    "        next_agent = \"writer\"\n",
    "        message = f\"[è´¨æ£€] åˆ†æ•°{score}/10, éœ€è¦æ”¹è¿›\"\n",
    "    else:\n",
    "        next_agent = \"END\"\n",
    "        message = f\"[è´¨æ£€] åˆ†æ•°{score}/10, è´¨é‡è¾¾æ ‡\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": [message],\n",
    "        \"next_agent\": next_agent,\n",
    "        \"iteration\": new_iteration\n",
    "    }\n",
    "\n",
    "print(\"âœ… è´¨é‡æ£€æŸ¥ Agent å®šä¹‰å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å››ã€å¯è§†åŒ–å·¥ä½œæµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“å°å·¥ä½œæµç»“æž„\n",
    "def visualize_workflow():\n",
    "    print(\"\\nðŸ“Š å¤š Agent å·¥ä½œæµç»“æž„:\")\n",
    "    print(\"\\n\")\n",
    "    print(\"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"    â”‚   å¼€å§‹      â”‚\")\n",
    "    print(\"    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "    print(\"           â”‚\")\n",
    "    print(\"           â†“\")\n",
    "    print(\"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"    â”‚  ç ”ç©¶å‘˜      â”‚ â† æ”¶é›†ä¿¡æ¯\")\n",
    "    print(\"    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "    print(\"           â”‚\")\n",
    "    print(\"           â†“\")\n",
    "    print(\"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"    â”‚   ä½œå®¶       â”‚ â† æ’°å†™å†…å®¹\")\n",
    "    print(\"    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "    print(\"           â”‚\")\n",
    "    print(\"           â†“\")\n",
    "    print(\"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"    â”‚   ç¼–è¾‘       â”‚ â† å®¡æ ¸æ”¹è¿›\")\n",
    "    print(\"    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "    print(\"           â”‚\")\n",
    "    print(\"           â†“\")\n",
    "    print(\"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"    â”‚è´¨é‡æ£€æŸ¥(å¯é€‰)â”‚ â† è¯„ä¼°è´¨é‡\")\n",
    "    print(\"    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "    print(\"           â”‚\")\n",
    "    print(\"      [åˆ†æ•°>=8?]\")\n",
    "    print(\"       â†™     â†˜\")\n",
    "    print(\"     æ˜¯       å¦\")\n",
    "    print(\"     â†“         â†“\")\n",
    "    print(\"   ç»“æŸ    è¿”å›žä½œå®¶\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "visualize_workflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äº”ã€æ›´å¤šå®žç”¨æ¡ˆä¾‹\n",
    "\n",
    "### 5.1 å®¢æœå›¢é˜Ÿ Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®¢æœå›¢é˜Ÿç¤ºä¾‹ï¼šåˆ†ç±» â†’ ä¸“å®¶ â†’ è´¨æ£€\n",
    "\n",
    "class CustomerServiceState(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    response: str\n",
    "    satisfaction: str\n",
    "\n",
    "def classifier_agent(state):\n",
    "    \"\"\"åˆ†ç±» Agentï¼šåˆ¤æ–­é—®é¢˜ç±»åž‹\"\"\"\n",
    "    print(\"ðŸ“‹ åˆ†ç±» Agent: åˆ†æžé—®é¢˜ç±»åž‹...\")\n",
    "    categories = [\"æŠ€æœ¯é—®é¢˜\", \"è´¦å•é—®é¢˜\", \"äº§å“å’¨è¯¢\", \"æŠ•è¯‰å»ºè®®\"]\n",
    "    # ç®€åŒ–ï¼šç›´æŽ¥åˆ†ç±»\n",
    "    return {**state, \"category\": \"æŠ€æœ¯é—®é¢˜\"}\n",
    "\n",
    "def technical_agent(state):\n",
    "    \"\"\"æŠ€æœ¯æ”¯æŒ Agent\"\"\"\n",
    "    print(\"ðŸ”§ æŠ€æœ¯æ”¯æŒ Agent: å¤„ç†æŠ€æœ¯é—®é¢˜...\")\n",
    "    return {**state, \"response\": \"è¿™æ˜¯æŠ€æœ¯æ”¯æŒçš„å›žç­”...\"}\n",
    "\n",
    "def billing_agent(state):\n",
    "    \"\"\"è´¦å• Agent\"\"\"\n",
    "    print(\"ðŸ’° è´¦å• Agent: å¤„ç†è´¦å•é—®é¢˜...\")\n",
    "    return {**state, \"response\": \"è¿™æ˜¯è´¦å•éƒ¨é—¨çš„å›žç­”...\"}\n",
    "\n",
    "print(\"âœ… å®¢æœå›¢é˜Ÿ Agent å®šä¹‰å®Œæˆï¼\")\n",
    "print(\"\\nðŸ’¡ æç¤º: è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•æ ¹æ®åˆ†ç±»è·¯ç”±åˆ°ä¸åŒçš„ä¸“å®¶ Agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ä»£ç å®¡æŸ¥å›¢é˜Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»£ç å®¡æŸ¥å›¢é˜Ÿï¼šå®‰å…¨å®¡æŸ¥ + æ€§èƒ½å®¡æŸ¥ + é£Žæ ¼å®¡æŸ¥\n",
    "\n",
    "class CodeReviewState(TypedDict):\n",
    "    code: str\n",
    "    security_issues: list\n",
    "    performance_issues: list\n",
    "    style_issues: list\n",
    "    approved: bool\n",
    "\n",
    "def security_reviewer(state):\n",
    "    \"\"\"å®‰å…¨å®¡æŸ¥ Agent\"\"\"\n",
    "    print(\"ðŸ”’ å®‰å…¨å®¡æŸ¥ Agent: æ£€æŸ¥å®‰å…¨æ¼æ´ž...\")\n",
    "    # è¿™é‡Œå¯ä»¥é›†æˆå®žé™…çš„å®‰å…¨æ£€æŸ¥å·¥å…·\n",
    "    return {**state, \"security_issues\": []}\n",
    "\n",
    "def performance_reviewer(state):\n",
    "    \"\"\"æ€§èƒ½å®¡æŸ¥ Agent\"\"\"\n",
    "    print(\"âš¡ æ€§èƒ½å®¡æŸ¥ Agent: åˆ†æžæ€§èƒ½é—®é¢˜...\")\n",
    "    return {**state, \"performance_issues\": []}\n",
    "\n",
    "def style_reviewer(state):\n",
    "    \"\"\"ä»£ç é£Žæ ¼ Agent\"\"\"\n",
    "    print(\"ðŸŽ¨ é£Žæ ¼å®¡æŸ¥ Agent: æ£€æŸ¥ä»£ç è§„èŒƒ...\")\n",
    "    return {**state, \"style_issues\": []}\n",
    "\n",
    "print(\"âœ… ä»£ç å®¡æŸ¥å›¢é˜Ÿå®šä¹‰å®Œæˆï¼\")\n",
    "print(\"\\nðŸ’¡ æç¤º: å¯ä»¥å¹¶è¡Œè¿è¡Œå¤šä¸ªå®¡æŸ¥ Agentï¼Œæé«˜æ•ˆçŽ‡\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…­ã€æ€»ç»“\n",
    "\n",
    "### âœ… æŽŒæ¡çš„æŠ€èƒ½\n",
    "\n",
    "1. **LangGraph åŸºç¡€**\n",
    "   - State çŠ¶æ€ç®¡ç†\n",
    "   - Node èŠ‚ç‚¹å®šä¹‰\n",
    "   - Edge è¾¹å’Œè·¯ç”±\n",
    "   - Graph å·¥ä½œæµç¼–æŽ’\n",
    "\n",
    "2. **å¤š Agent åä½œ**\n",
    "   - Agent è§’è‰²åˆ†å·¥\n",
    "   - çŠ¶æ€ä¼ é€’å’Œå…±äº«\n",
    "   - æ¡ä»¶è·¯ç”±\n",
    "   - å¾ªçŽ¯å’Œè¿­ä»£\n",
    "\n",
    "3. **å®žæˆ˜æ¨¡å¼**\n",
    "   - ä¸²è¡Œåä½œï¼ˆç ”ç©¶â†’å†™ä½œâ†’ç¼–è¾‘ï¼‰\n",
    "   - å¹¶è¡Œå¤„ç†ï¼ˆå¤šä¸ªå®¡æŸ¥ Agentï¼‰\n",
    "   - æ¡ä»¶åˆ†æ”¯ï¼ˆæ ¹æ®åˆ†ç±»è·¯ç”±ï¼‰\n",
    "   - è´¨é‡å¾ªçŽ¯ï¼ˆä¸è¾¾æ ‡é‡åšï¼‰\n",
    "\n",
    "### ðŸš€ åº”ç”¨åœºæ™¯\n",
    "\n",
    "- ðŸ“ å†…å®¹åˆ›ä½œå›¢é˜Ÿ\n",
    "- ðŸŽ¯ å®¢æˆ·æœåŠ¡ç³»ç»Ÿ\n",
    "- ðŸ” ä»£ç å®¡æŸ¥æµç¨‹\n",
    "- ðŸ“Š æ•°æ®åˆ†æžç®¡é“\n",
    "- ðŸ¤– æ™ºèƒ½åŠ©æ‰‹ç³»ç»Ÿ\n",
    "\n",
    "### ðŸ’¡ æœ€ä½³å®žè·µ\n",
    "\n",
    "1. **æ¸…æ™°çš„çŠ¶æ€è®¾è®¡**ï¼šå®šä¹‰å®Œæ•´çš„çŠ¶æ€ç»“æž„\n",
    "2. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ª Agent ä¸“æ³¨ä¸€ä¸ªä»»åŠ¡\n",
    "3. **é”™è¯¯å¤„ç†**ï¼šè€ƒè™‘å¼‚å¸¸æƒ…å†µå’Œå›žé€€æœºåˆ¶\n",
    "4. **æ€§èƒ½ä¼˜åŒ–**ï¼šå¹¶è¡Œå¤„ç†ç‹¬ç«‹ä»»åŠ¡\n",
    "5. **å¯è§‚æµ‹æ€§**ï¼šæ·»åŠ æ—¥å¿—å’Œç›‘æŽ§\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ‰ æ­å–œï¼ä½ å·²ç»æŽŒæ¡äº† LangGraph å¤š Agent ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€èƒ½ï¼**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
