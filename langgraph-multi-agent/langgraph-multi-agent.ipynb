{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¤– LangGraph å¤š Agent ç³»ç»Ÿå®æˆ˜\n",
        "\n",
        "æœ¬ Notebook å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph æ„å»ºå¤æ‚çš„å¤š Agent åä½œç³»ç»Ÿã€‚\n",
        "\n",
        "## ğŸ“‹ å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "- LangGraph åŸºç¡€æ¦‚å¿µï¼ˆStateã€Nodeã€Edgeï¼‰\n",
        "- æ„å»ºçŠ¶æ€æœºå·¥ä½œæµ\n",
        "- å¤š Agent åä½œæ¨¡å¼\n",
        "- æ¡ä»¶è·¯ç”±å’Œå†³ç­–\n",
        "- ä½¿ç”¨ LangSmith ç›‘æ§è°ƒè¯•\n",
        "- å®æˆ˜æ¡ˆä¾‹ï¼šæ™ºèƒ½å†…å®¹åˆ›ä½œå›¢é˜Ÿ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ å®‰è£…ä¾èµ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q langgraph langchain langchain-openai langsmith\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ é…ç½® DeepSeek API å’Œ LangSmith\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "print(\"ğŸ”§ é…ç½® DeepSeek API å’Œ LangSmith\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# DeepSeek API é…ç½®æ£€æŸ¥\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.deepseek.com\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"\\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ° DeepSeek API Keyï¼\")\n",
        "    print(\"è¯·åœ¨ç»ˆç«¯è¿è¡Œï¼š\")\n",
        "    print(\"   export OPENAI_API_KEY='your-deepseek-api-key'\")\n",
        "    print(\"   export OPENAI_API_BASE='https://api.deepseek.com'\")\n",
        "else:\n",
        "    print(f\"\\nâœ… DeepSeek API å·²é…ç½®\")\n",
        "    print(f\"âœ… API Base: {api_base}\")\n",
        "\n",
        "# LangSmith é…ç½®æ£€æŸ¥\n",
        "langsmith_key = os.environ.get(\"LANGCHAIN_API_KEY\", \"\")\n",
        "langsmith_tracing = os.environ.get(\"LANGCHAIN_TRACING_V2\", \"\")\n",
        "langsmith_project = os.environ.get(\"LANGCHAIN_PROJECT\", \"langgraph-multi-agent\")\n",
        "\n",
        "if not langsmith_key or langsmith_tracing != \"true\":\n",
        "    print(\"\\nâš ï¸  è­¦å‘Š: LangSmith æœªå®Œå…¨é…ç½®ï¼\")\n",
        "    print(\"è¯·åœ¨ç»ˆç«¯è¿è¡Œï¼š\")\n",
        "    print(\"   export LANGCHAIN_TRACING_V2='true'\")\n",
        "    print(\"   export LANGCHAIN_API_KEY='your-langsmith-api-key'\")\n",
        "    print(\"   export LANGCHAIN_PROJECT='langgraph-multi-agent'\")\n",
        "    print(\"\\nè®¿é—® https://smith.langchain.com/ è·å– API Key\")\n",
        "else:\n",
        "    print(f\"\\nâœ… LangSmith ç›‘æ§å·²å¯ç”¨\")\n",
        "    print(f\"âœ… Project: {langsmith_project}\")\n",
        "    print(f\"âœ… è®¿é—® https://smith.langchain.com/ æŸ¥çœ‹æ‰§è¡Œè¯¦æƒ…\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# åˆå§‹åŒ– LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"deepseek-chat\",\n",
        "    openai_api_base=\"https://api.deepseek.com\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… é…ç½®å®Œæˆï¼æ‰€æœ‰æ‰§è¡Œå°†è‡ªåŠ¨ä¸Šä¼ åˆ° LangSmith å¹³å°\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä¸€ã€LangGraph åŸºç¡€æ¦‚å¿µ\n",
        "\n",
        "### æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "```\n",
        "State (çŠ¶æ€)\n",
        "   â†“\n",
        "Node (èŠ‚ç‚¹/Agent)\n",
        "   â†“\n",
        "Edge (è¾¹/è½¬æ¢)\n",
        "   â†“\n",
        "Graph (æ•´ä¸ªå·¥ä½œæµ)\n",
        "```\n",
        "\n",
        "### ç®€å•ç¤ºä¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict\n",
        "\n",
        "# 1. å®šä¹‰çŠ¶æ€\n",
        "class SimpleState(TypedDict):\n",
        "    messages: list[str]\n",
        "    counter: int\n",
        "\n",
        "# 2. å®šä¹‰èŠ‚ç‚¹å‡½æ•°\n",
        "def step1(state: SimpleState):\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [\"æ­¥éª¤1å®Œæˆ\"],\n",
        "        \"counter\": state[\"counter\"] + 1\n",
        "    }\n",
        "\n",
        "def step2(state: SimpleState):\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [\"æ­¥éª¤2å®Œæˆ\"],\n",
        "        \"counter\": state[\"counter\"] + 1\n",
        "    }\n",
        "\n",
        "# 3. æ„å»ºå›¾\n",
        "workflow = StateGraph(SimpleState)\n",
        "workflow.add_node(\"step1\", step1)\n",
        "workflow.add_node(\"step2\", step2)\n",
        "\n",
        "# 4. æ·»åŠ è¾¹\n",
        "workflow.set_entry_point(\"step1\")\n",
        "workflow.add_edge(\"step1\", \"step2\")\n",
        "workflow.add_edge(\"step2\", END)\n",
        "\n",
        "# 5. ç¼–è¯‘å¹¶è¿è¡Œ\n",
        "app = workflow.compile()\n",
        "\n",
        "result = app.invoke({\"messages\": [], \"counter\": 0})\n",
        "print(\"\\nç»“æœ:\")\n",
        "print(f\"æ¶ˆæ¯: {result['messages']}\")\n",
        "print(f\"è®¡æ•°: {result['counter']}\")\n",
        "print(\"\\nğŸ’¡ æ‰€æœ‰æ‰§è¡Œç»†èŠ‚å·²è‡ªåŠ¨ä¸Šä¼ åˆ° LangSmithï¼Œè¯·è®¿é—®æ§åˆ¶å°æŸ¥çœ‹å¯è§†åŒ–æµç¨‹ï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## äºŒã€å¤š Agent å†…å®¹åˆ›ä½œç³»ç»Ÿ\n",
        "\n",
        "### 2.1 å®šä¹‰çŠ¶æ€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "import operator\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    topic: str\n",
        "    research_notes: str\n",
        "    draft_content: str\n",
        "    final_content: str\n",
        "    messages: Annotated[List, operator.add]\n",
        "    next_agent: str\n",
        "    iteration: int\n",
        "    max_iterations: int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 åˆ›å»ºå„ä¸ª Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# ç ”ç©¶å‘˜ Agent\n",
        "def researcher_agent(state: AgentState) -> AgentState:\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶å‘˜ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œç ”ç©¶ï¼Œæä¾›å…³é”®è¦ç‚¹å’Œæœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚\n",
        "\n",
        "ä¸»é¢˜ï¼š{topic}\n",
        "\n",
        "è¯·æä¾›ï¼š\n",
        "1. æ ¸å¿ƒæ¦‚å¿µå®šä¹‰\n",
        "2. é‡è¦ç‰¹ç‚¹ï¼ˆ3-5ä¸ªï¼‰\n",
        "3. å®é™…åº”ç”¨åœºæ™¯\n",
        "4. æ³¨æ„äº‹é¡¹\n",
        "\n",
        "ç ”ç©¶ç¬”è®°ï¼š\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"topic\": state[\"topic\"]})\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"research_notes\": result.content,\n",
        "        \"messages\": [f\"[ç ”ç©¶å‘˜] å®Œæˆç ”ç©¶: {state['topic'][:50]}...\"],\n",
        "        \"next_agent\": \"writer\"\n",
        "    }\n",
        "\n",
        "# ä½œå®¶ Agent\n",
        "def writer_agent(state: AgentState) -> AgentState:\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ä½œå®¶ã€‚åŸºäºç ”ç©¶å‘˜æä¾›çš„ç¬”è®°ï¼Œæ’°å†™ä¸€ç¯‡ç»“æ„æ¸…æ™°ã€é€šä¿—æ˜“æ‡‚çš„æ–‡ç« ã€‚\n",
        "\n",
        "ä¸»é¢˜ï¼š{topic}\n",
        "\n",
        "ç ”ç©¶ç¬”è®°ï¼š\n",
        "{research_notes}\n",
        "\n",
        "è¦æ±‚ï¼š\n",
        "- ä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜å’Œæ®µè½ç»“æ„\n",
        "- è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé€‚åˆåˆå­¦è€…\n",
        "- åŒ…å«å®ä¾‹è¯´æ˜\n",
        "- å­—æ•°çº¦500å­—\n",
        "\n",
        "æ–‡ç« å†…å®¹ï¼š\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\n",
        "        \"topic\": state[\"topic\"],\n",
        "        \"research_notes\": state[\"research_notes\"]\n",
        "    })\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"draft_content\": result.content,\n",
        "        \"messages\": [f\"[ä½œå®¶] å®Œæˆåˆç¨¿æ’°å†™\"],\n",
        "        \"next_agent\": \"editor\"\n",
        "    }\n",
        "\n",
        "# ç¼–è¾‘ Agent\n",
        "def editor_agent(state: AgentState) -> AgentState:\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–è¾‘ã€‚è¯·å®¡æ ¸å¹¶æ”¹è¿›ä»¥ä¸‹æ–‡ç« ã€‚\n",
        "\n",
        "åŸæ–‡ï¼š\n",
        "{draft_content}\n",
        "\n",
        "è¯·ï¼š\n",
        "1. æ£€æŸ¥è¯­æ³•å’Œè¡¨è¾¾\n",
        "2. ä¼˜åŒ–ç»“æ„å’Œé€»è¾‘\n",
        "3. ç¡®ä¿å†…å®¹å‡†ç¡®æ€§\n",
        "4. å¢å¼ºå¯è¯»æ€§\n",
        "\n",
        "å¦‚æœæ–‡ç« è´¨é‡å·²ç»å¾ˆå¥½ï¼Œä¿æŒåŸæ ·å¹¶æ·»åŠ ç®€çŸ­è¯„ä»·ã€‚\n",
        "å¦‚æœéœ€è¦æ”¹è¿›ï¼Œè¯·ç›´æ¥è¾“å‡ºæ”¹è¿›åçš„ç‰ˆæœ¬ã€‚\n",
        "\n",
        "æœ€ç»ˆæ–‡ç« ï¼š\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"draft_content\": state[\"draft_content\"]})\n",
        "    \n",
        "    new_iteration = state[\"iteration\"] + 1\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"final_content\": result.content,\n",
        "        \"messages\": [f\"[ç¼–è¾‘] å®Œæˆå®¡æ ¸å’Œæ”¹è¿›\"],\n",
        "        \"next_agent\": \"END\",\n",
        "        \"iteration\": new_iteration\n",
        "    }\n",
        "\n",
        "print(\"âœ… Agent å®šä¹‰å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# è·¯ç”±å‡½æ•°ï¼šå†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹\n",
        "def route_agent(state: AgentState) -> str:\n",
        "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
        "    if next_agent == \"END\":\n",
        "        return END\n",
        "    return next_agent\n",
        "\n",
        "# åˆ›å»ºå›¾\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# æ·»åŠ èŠ‚ç‚¹\n",
        "workflow.add_node(\"researcher\", researcher_agent)\n",
        "workflow.add_node(\"writer\", writer_agent)\n",
        "workflow.add_node(\"editor\", editor_agent)\n",
        "\n",
        "# è®¾ç½®å…¥å£\n",
        "workflow.set_entry_point(\"researcher\")\n",
        "\n",
        "# æ·»åŠ æ¡ä»¶è¾¹\n",
        "workflow.add_conditional_edges(\n",
        "    \"researcher\",\n",
        "    route_agent,\n",
        "    {\"writer\": \"writer\", END: END}\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"writer\",\n",
        "    route_agent,\n",
        "    {\"editor\": \"editor\", END: END}\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"editor\",\n",
        "    route_agent,\n",
        "    {\"writer\": \"writer\", END: END}\n",
        ")\n",
        "\n",
        "# ç¼–è¯‘\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"âœ… å·¥ä½œæµæ„å»ºå®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 è¿è¡Œå¤š Agent ç³»ç»Ÿ\n",
        "\n",
        "æ‰€æœ‰æ‰§è¡Œç»†èŠ‚ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ° LangSmith å¹³å°ï¼Œä½ å¯ä»¥ï¼š\n",
        "- æŸ¥çœ‹æ¯ä¸ª Agent çš„æ‰§è¡Œæ—¶é—´\n",
        "- æŸ¥çœ‹æ¯æ¬¡ LLM è°ƒç”¨çš„ Prompt å’Œå“åº”\n",
        "- åˆ†æ Token ä½¿ç”¨å’Œæˆæœ¬\n",
        "- å¯è§†åŒ–æ•´ä¸ªå·¥ä½œæµçš„æ‰§è¡Œè·¯å¾„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆå§‹åŒ–çŠ¶æ€\n",
        "initial_state = {\n",
        "    \"topic\": \"æ·±åº¦å­¦ä¹ ä¸­çš„ Transformer æ¶æ„\",\n",
        "    \"research_notes\": \"\",\n",
        "    \"draft_content\": \"\",\n",
        "    \"final_content\": \"\",\n",
        "    \"messages\": [],\n",
        "    \"next_agent\": \"researcher\",\n",
        "    \"iteration\": 0,\n",
        "    \"max_iterations\": 2\n",
        "}\n",
        "\n",
        "print(\"ğŸš€ å¯åŠ¨å¤š Agent å†…å®¹åˆ›ä½œç³»ç»Ÿ...\")\n",
        "print(f\"ğŸ“ ä¸»é¢˜: {initial_state['topic']}\\n\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nğŸ’¡ æ‰§è¡Œè¿‡ç¨‹æ­£åœ¨ä¸Šä¼ åˆ° LangSmith...\")\n",
        "print(\"   è®¿é—® https://smith.langchain.com/ æŸ¥çœ‹å®æ—¶æ‰§è¡Œè¯¦æƒ…\\n\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# è¿è¡Œå·¥ä½œæµ\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nğŸ‰ åˆ›ä½œå®Œæˆï¼\")\n",
        "print(\"\\nğŸ“‹ å·¥ä½œæµç¨‹:\")\n",
        "for msg in final_state[\"messages\"]:\n",
        "    print(f\"  {msg}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nğŸ“„ æœ€ç»ˆæ–‡ç« :\")\n",
        "print(final_state[\"final_content\"][:500] + \"...\\n\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"\\nğŸ” æƒ³æŸ¥çœ‹è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹ï¼Ÿ\")\n",
        "print(\"   è®¿é—® LangSmith å¹³å°æŸ¥çœ‹ï¼š\")\n",
        "print(\"   - æ¯ä¸ª Agent çš„æ‰§è¡Œæ—¶é—´\")\n",
        "print(\"   - LLM è°ƒç”¨çš„å®Œæ•´ Prompt å’Œå“åº”\")\n",
        "print(\"   - Token ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬\")\n",
        "print(\"   - å·¥ä½œæµå¯è§†åŒ–å›¾è¡¨\")\n",
        "print(\"\\n   https://smith.langchain.com/\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä¸‰ã€é«˜çº§ç‰¹æ€§ï¼šåŠ¨æ€è·¯ç”±å’Œå¾ªç¯\n",
        "\n",
        "### 3.1 å¸¦è´¨é‡æ£€æŸ¥çš„å¾ªç¯æ”¹è¿›\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è´¨é‡è¯„ä¼° Agent\n",
        "def quality_checker(state: AgentState) -> AgentState:\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"è¯„ä¼°ä»¥ä¸‹æ–‡ç« çš„è´¨é‡ï¼Œå¹¶ç»™å‡º1-10çš„åˆ†æ•°ã€‚\n",
        "\n",
        "æ–‡ç« ï¼š\n",
        "{content}\n",
        "\n",
        "è¯·åªå›ç­”ä¸€ä¸ªæ•°å­—ï¼ˆ1-10ï¼‰å’Œç®€çŸ­è¯„ä»·ï¼ˆä¸€å¥è¯ï¼‰ã€‚\n",
        "æ ¼å¼ï¼šåˆ†æ•°: X, è¯„ä»·: XXX\n",
        "\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"content\": state[\"final_content\"]})\n",
        "    \n",
        "    try:\n",
        "        score_str = result.content.split(\"åˆ†æ•°:\")[1].split(\",\")[0].strip()\n",
        "        score = int(score_str)\n",
        "    except:\n",
        "        score = 8\n",
        "    \n",
        "    new_iteration = state[\"iteration\"] + 1\n",
        "    if score < 8 and new_iteration < state[\"max_iterations\"]:\n",
        "        next_agent = \"writer\"\n",
        "        message = f\"[è´¨æ£€] åˆ†æ•°{score}/10, éœ€è¦æ”¹è¿›\"\n",
        "    else:\n",
        "        next_agent = \"END\"\n",
        "        message = f\"[è´¨æ£€] åˆ†æ•°{score}/10, è´¨é‡è¾¾æ ‡\"\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"messages\": [message],\n",
        "        \"next_agent\": next_agent,\n",
        "        \"iteration\": new_iteration\n",
        "    }\n",
        "\n",
        "print(\"âœ… è´¨é‡æ£€æŸ¥ Agent å®šä¹‰å®Œæˆï¼\")\n",
        "print(\"\\nğŸ’¡ åœ¨ LangSmith ä¸­å¯ä»¥çœ‹åˆ°è´¨é‡æ£€æŸ¥çš„å¾ªç¯è¿­ä»£è¿‡ç¨‹\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## å››ã€æ€»ç»“\n",
        "\n",
        "### âœ… æŒæ¡çš„æŠ€èƒ½\n",
        "\n",
        "1. **LangGraph åŸºç¡€**\n",
        "   - State çŠ¶æ€ç®¡ç†\n",
        "   - Node èŠ‚ç‚¹å®šä¹‰\n",
        "   - Edge è¾¹å’Œè·¯ç”±\n",
        "   - Graph å·¥ä½œæµç¼–æ’\n",
        "\n",
        "2. **å¤š Agent åä½œ**\n",
        "   - Agent è§’è‰²åˆ†å·¥\n",
        "   - çŠ¶æ€ä¼ é€’å’Œå…±äº«\n",
        "   - æ¡ä»¶è·¯ç”±\n",
        "   - å¾ªç¯å’Œè¿­ä»£\n",
        "\n",
        "3. **LangSmith ç›‘æ§**\n",
        "   - è‡ªåŠ¨è¿½è¸ªæ‰€æœ‰æ‰§è¡Œ\n",
        "   - å¯è§†åŒ–å·¥ä½œæµ\n",
        "   - æ€§èƒ½å’Œæˆæœ¬åˆ†æ\n",
        "   - è°ƒè¯•å’Œä¼˜åŒ–\n",
        "\n",
        "### ğŸš€ åº”ç”¨åœºæ™¯\n",
        "\n",
        "- ğŸ“ å†…å®¹åˆ›ä½œå›¢é˜Ÿ\n",
        "- ğŸ¯ å®¢æˆ·æœåŠ¡ç³»ç»Ÿ\n",
        "- ğŸ” ä»£ç å®¡æŸ¥æµç¨‹\n",
        "- ğŸ“Š æ•°æ®åˆ†æç®¡é“\n",
        "- ğŸ¤– æ™ºèƒ½åŠ©æ‰‹ç³»ç»Ÿ\n",
        "\n",
        "### ğŸ’¡ æœ€ä½³å®è·µ\n",
        "\n",
        "1. **æ¸…æ™°çš„çŠ¶æ€è®¾è®¡**ï¼šå®šä¹‰å®Œæ•´çš„çŠ¶æ€ç»“æ„\n",
        "2. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ª Agent ä¸“æ³¨ä¸€ä¸ªä»»åŠ¡\n",
        "3. **ä½¿ç”¨ LangSmith**ï¼šç›‘æ§æ‰€æœ‰æ‰§è¡Œç»†èŠ‚\n",
        "4. **é”™è¯¯å¤„ç†**ï¼šè€ƒè™‘å¼‚å¸¸æƒ…å†µå’Œå›é€€æœºåˆ¶\n",
        "5. **æ€§èƒ½ä¼˜åŒ–**ï¼šé€šè¿‡ LangSmith åˆ†æç“¶é¢ˆ\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ‰ æ­å–œï¼ä½ å·²ç»æŒæ¡äº† LangGraph å¤š Agent ç³»ç»Ÿå’Œ LangSmith ç›‘æ§çš„æ ¸å¿ƒæŠ€èƒ½ï¼**\n",
        "\n",
        "**ğŸ” ä¸‹ä¸€æ­¥ï¼š**\n",
        "è®¿é—® [https://smith.langchain.com/](https://smith.langchain.com/) æŸ¥çœ‹ä½ çš„æ‰§è¡Œè®°å½•ï¼Œåˆ†ææ€§èƒ½å’Œæˆæœ¬ï¼\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
