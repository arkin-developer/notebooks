{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🤖 LangGraph 多 Agent 系统实战\n",
        "\n",
        "本 Notebook 展示如何使用 LangGraph 构建复杂的多 Agent 协作系统，并通过 LangSmith 进行详细的监控和调试。\n",
        "\n",
        "## 📋 学习目标\n",
        "\n",
        "- LangGraph 基础概念（State、Node、Edge）\n",
        "- 构建状态机工作流\n",
        "- 多 Agent 协作模式\n",
        "- 条件路由和决策\n",
        "- **使用 LangSmith 监控每个 Agent 的执行细节**\n",
        "- 实战案例：智能内容创作团队\n",
        "\n",
        "## 💡 LangSmith 监控特性\n",
        "\n",
        "在本 Notebook 中，你将能在 LangSmith 上看到：\n",
        "- ✅ 每个 Agent 的执行时间\n",
        "- ✅ 每个 Agent 的输入状态和输出状态\n",
        "- ✅ Agent 之间的调用关系\n",
        "- ✅ 每次 LLM 调用的完整 Prompt 和响应\n",
        "- ✅ Token 使用和成本统计\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📦 安装依赖\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q langgraph langchain langchain-openai langsmith\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 配置环境变量\n",
        "\n",
        "**系统环境变量**（已在 `~/.zshrc` 中配置）：\n",
        "- `LANGCHAIN_API_KEY` - LangSmith API Key\n",
        "- `OPENAI_API_KEY` - DeepSeek API Key\n",
        "\n",
        "**项目环境变量**（自动设置）：\n",
        "- `LANGCHAIN_TRACING_V2=true` - 启用 LangSmith 追踪\n",
        "- `LANGCHAIN_PROJECT=langgraph-multi-agent` - 项目名称\n",
        "- `OPENAI_API_BASE=https://api.deepseek.com` - DeepSeek API 地址\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "print(\"🔧 配置环境\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 自动设置项目环境变量\n",
        "os.environ.setdefault(\"LANGCHAIN_TRACING_V2\", \"true\")\n",
        "os.environ.setdefault(\"LANGCHAIN_PROJECT\", \"langgraph-multi-agent\")\n",
        "os.environ.setdefault(\"OPENAI_API_BASE\", \"https://api.deepseek.com\")\n",
        "\n",
        "# 检查系统环境变量\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "langsmith_key = os.environ.get(\"LANGCHAIN_API_KEY\", \"\")\n",
        "\n",
        "print(\"\\n📋 配置状态：\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "if api_key:\n",
        "    print(f\"✅ OPENAI_API_KEY: {api_key[:8]}...{api_key[-4:]} (系统)\")\n",
        "else:\n",
        "    print(\"❌ OPENAI_API_KEY: 未设置\")\n",
        "\n",
        "print(f\"✅ OPENAI_API_BASE: {os.environ['OPENAI_API_BASE']} (项目)\")\n",
        "\n",
        "if langsmith_key:\n",
        "    print(f\"✅ LANGCHAIN_API_KEY: {langsmith_key[:12]}...{langsmith_key[-4:]} (系统)\")\n",
        "else:\n",
        "    print(\"❌ LANGCHAIN_API_KEY: 未设置\")\n",
        "\n",
        "print(f\"✅ LANGCHAIN_TRACING_V2: {os.environ['LANGCHAIN_TRACING_V2']} (项目)\")\n",
        "print(f\"✅ LANGCHAIN_PROJECT: {os.environ['LANGCHAIN_PROJECT']} (项目)\")\n",
        "\n",
        "print(\"-\"*60)\n",
        "\n",
        "if not api_key or not langsmith_key:\n",
        "    print(\"\\n⚠️  请确保在 ~/.zshrc 中配置了必需的环境变量\")\n",
        "    print(\"   然后重启 Jupyter Kernel\")\n",
        "else:\n",
        "    print(\"\\n✅ 所有配置就绪！\")\n",
        "    print(f\"✅ 访问 https://smith.langchain.com/ 查看执行详情\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 初始化 LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"deepseek-chat\",\n",
        "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"\\n✅ LLM 初始化完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 一、多 Agent 内容创作系统\n",
        "\n",
        "### 1.1 定义状态\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "import operator\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"多 Agent 系统的共享状态\"\"\"\n",
        "    topic: str                    # 主题\n",
        "    research_notes: str           # 研究笔记\n",
        "    draft_content: str            # 草稿\n",
        "    final_content: str            # 最终内容\n",
        "    messages: Annotated[List, operator.add]  # 执行日志\n",
        "    next_agent: str               # 下一个 Agent\n",
        "    iteration: int                # 当前迭代次数\n",
        "    max_iterations: int           # 最大迭代次数\n",
        "\n",
        "print(\"✅ AgentState 定义完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 创建 Agent（带完整追踪）\n",
        "\n",
        "每个 Agent 使用 `@traceable` 装饰器，在 LangSmith 中可以看到：\n",
        "- 🔍 Agent 的输入状态\n",
        "- 🔍 Agent 的输出状态  \n",
        "- 🔍 Agent 内部的所有 LLM 调用\n",
        "- 🔍 执行时间和 Token 使用\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langsmith import traceable\n",
        "\n",
        "# ============================================================================\n",
        "# 研究员 Agent\n",
        "# ============================================================================\n",
        "\n",
        "@traceable(\n",
        "    name=\"🔬 研究员 Agent\",\n",
        "    run_type=\"chain\",\n",
        "    tags=[\"agent\", \"researcher\", \"content-creation\"],\n",
        "    metadata={\"role\": \"researcher\", \"task\": \"research_and_analysis\"}\n",
        ")\n",
        "def researcher_agent(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    研究员 Agent：负责收集和分析信息\n",
        "    \n",
        "    在 LangSmith 中可以看到：\n",
        "    - Input: topic\n",
        "    - Output: research_notes\n",
        "    - 执行时间\n",
        "    - LLM 调用详情\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🔬 [研究员 Agent] 开始执行\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"📥 输入 - 主题: {state['topic']}\")\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"你是一个专业的研究员。请针对以下主题进行研究，提供关键要点和有价值的信息。\n",
        "\n",
        "主题：{topic}\n",
        "\n",
        "请提供：\n",
        "1. 核心概念定义\n",
        "2. 重要特点（3-5个）\n",
        "3. 实际应用场景\n",
        "4. 注意事项\n",
        "\n",
        "研究笔记：\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke(\n",
        "        {\"topic\": state[\"topic\"]},\n",
        "        config={\n",
        "            \"metadata\": {\n",
        "                \"agent\": \"researcher\",\n",
        "                \"step\": \"research\",\n",
        "                \"topic\": state[\"topic\"],\n",
        "                \"phase\": \"data_collection\"\n",
        "            },\n",
        "            \"tags\": [\"research_phase\"],\n",
        "            \"run_name\": f\"📚 研究: {state['topic'][:30]}\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    print(f\"📤 输出 - 生成了 {len(result.content)} 字的研究笔记\")\n",
        "    print(f\"✅ [研究员 Agent] 执行完成\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"research_notes\": result.content,\n",
        "        \"messages\": [f\"[研究员] 完成研究: {state['topic'][:50]}...\"],\n",
        "        \"next_agent\": \"writer\"\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 作家 Agent\n",
        "# ============================================================================\n",
        "\n",
        "@traceable(\n",
        "    name=\"✍️ 作家 Agent\",\n",
        "    run_type=\"chain\",\n",
        "    tags=[\"agent\", \"writer\", \"content-creation\"],\n",
        "    metadata={\"role\": \"writer\", \"task\": \"content_writing\"}\n",
        ")\n",
        "def writer_agent(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    作家 Agent：负责撰写文章\n",
        "    \n",
        "    在 LangSmith 中可以看到：\n",
        "    - Input: research_notes\n",
        "    - Output: draft_content\n",
        "    - 执行时间\n",
        "    - LLM 调用详情\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✍️ [作家 Agent] 开始执行\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"📥 输入 - 研究笔记长度: {len(state['research_notes'])} 字\")\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"你是一个专业的技术作家。基于研究员提供的笔记，撰写一篇结构清晰、通俗易懂的文章。\n",
        "\n",
        "主题：{topic}\n",
        "\n",
        "研究笔记：\n",
        "{research_notes}\n",
        "\n",
        "要求：\n",
        "- 使用清晰的标题和段落结构\n",
        "- 语言通俗易懂，适合初学者\n",
        "- 包含实例说明\n",
        "- 字数约500字\n",
        "\n",
        "文章内容：\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke(\n",
        "        {\n",
        "            \"topic\": state[\"topic\"],\n",
        "            \"research_notes\": state[\"research_notes\"]\n",
        "        },\n",
        "        config={\n",
        "            \"metadata\": {\n",
        "                \"agent\": \"writer\",\n",
        "                \"step\": \"writing\",\n",
        "                \"research_notes_length\": len(state[\"research_notes\"]),\n",
        "                \"phase\": \"content_creation\"\n",
        "            },\n",
        "            \"tags\": [\"writing_phase\"],\n",
        "            \"run_name\": f\"📝 撰写: {state['topic'][:30]}\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    print(f\"📤 输出 - 生成了 {len(result.content)} 字的文章草稿\")\n",
        "    print(f\"✅ [作家 Agent] 执行完成\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"draft_content\": result.content,\n",
        "        \"messages\": [f\"[作家] 完成初稿撰写\"],\n",
        "        \"next_agent\": \"editor\"\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 编辑 Agent\n",
        "# ============================================================================\n",
        "\n",
        "@traceable(\n",
        "    name=\"📝 编辑 Agent\",\n",
        "    run_type=\"chain\",\n",
        "    tags=[\"agent\", \"editor\", \"content-creation\"],\n",
        "    metadata={\"role\": \"editor\", \"task\": \"review_and_improve\"}\n",
        ")\n",
        "def editor_agent(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    编辑 Agent：负责审核和改进文章\n",
        "    \n",
        "    在 LangSmith 中可以看到：\n",
        "    - Input: draft_content\n",
        "    - Output: final_content\n",
        "    - 当前迭代次数\n",
        "    - 执行时间\n",
        "    - LLM 调用详情\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"📝 [编辑 Agent] 开始执行\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"📥 输入 - 草稿长度: {len(state['draft_content'])} 字\")\n",
        "    print(f\"🔄 当前迭代: {state['iteration'] + 1}/{state['max_iterations']}\")\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"你是一个专业的编辑。请审核并改进以下文章。\n",
        "\n",
        "原文：\n",
        "{draft_content}\n",
        "\n",
        "请：\n",
        "1. 检查语法和表达\n",
        "2. 优化结构和逻辑\n",
        "3. 确保内容准确性\n",
        "4. 增强可读性\n",
        "\n",
        "如果文章质量已经很好，保持原样并添加简短评价。\n",
        "如果需要改进，请直接输出改进后的版本。\n",
        "\n",
        "最终文章：\"\"\"\n",
        "    )\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke(\n",
        "        {\"draft_content\": state[\"draft_content\"]},\n",
        "        config={\n",
        "            \"metadata\": {\n",
        "                \"agent\": \"editor\",\n",
        "                \"step\": \"editing\",\n",
        "                \"iteration\": state[\"iteration\"] + 1,\n",
        "                \"max_iterations\": state[\"max_iterations\"],\n",
        "                \"draft_length\": len(state[\"draft_content\"]),\n",
        "                \"phase\": \"quality_control\"\n",
        "            },\n",
        "            \"tags\": [\"editing_phase\"],\n",
        "            \"run_name\": f\"🔍 编辑: 第{state['iteration'] + 1}轮\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    new_iteration = state[\"iteration\"] + 1\n",
        "    \n",
        "    print(f\"📤 输出 - 最终文章长度: {len(result.content)} 字\")\n",
        "    print(f\"✅ [编辑 Agent] 执行完成\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"final_content\": result.content,\n",
        "        \"messages\": [f\"[编辑] 完成审核和改进\"],\n",
        "        \"next_agent\": \"END\",\n",
        "        \"iteration\": new_iteration\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"✅ Agent 定义完成！\")\n",
        "print(\"\\n💡 每个 Agent 都使用 @traceable 装饰器\")\n",
        "print(\"   在 LangSmith 中可以看到完整的执行过程\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 构建工作流\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 路由函数：决定下一个节点\n",
        "def route_agent(state: AgentState) -> str:\n",
        "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
        "    if next_agent == \"END\":\n",
        "        return END\n",
        "    return next_agent\n",
        "\n",
        "# 创建图\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# 添加节点\n",
        "workflow.add_node(\"researcher\", researcher_agent)\n",
        "workflow.add_node(\"writer\", writer_agent)\n",
        "workflow.add_node(\"editor\", editor_agent)\n",
        "\n",
        "# 设置入口\n",
        "workflow.set_entry_point(\"researcher\")\n",
        "\n",
        "# 添加条件边\n",
        "workflow.add_conditional_edges(\n",
        "    \"researcher\",\n",
        "    route_agent,\n",
        "    {\"writer\": \"writer\", END: END}\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"writer\",\n",
        "    route_agent,\n",
        "    {\"editor\": \"editor\", END: END}\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"editor\",\n",
        "    route_agent,\n",
        "    {\"writer\": \"writer\", END: END}\n",
        ")\n",
        "\n",
        "# 编译\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"✅ 工作流构建完成！\")\n",
        "print(\"\\n📊 工作流结构：\")\n",
        "print(\"   研究员 → 作家 → 编辑 → 结束\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 运行多 Agent 系统\n",
        "\n",
        "**在 LangSmith 中查看：**\n",
        "1. 访问 https://smith.langchain.com/\n",
        "2. 选择项目：`langgraph-multi-agent`\n",
        "3. 找到最新的 Run\n",
        "4. 展开树形结构，你将看到：\n",
        "   - 🔬 研究员 Agent（包含输入输出）\n",
        "   - ✍️ 作家 Agent（包含输入输出）\n",
        "   - 📝 编辑 Agent（包含输入输出）\n",
        "   - 每个 Agent 内部的 LLM 调用详情\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初始化状态\n",
        "initial_state = {\n",
        "    \"topic\": \"深度学习中的 Transformer 架构\",\n",
        "    \"research_notes\": \"\",\n",
        "    \"draft_content\": \"\",\n",
        "    \"final_content\": \"\",\n",
        "    \"messages\": [],\n",
        "    \"next_agent\": \"researcher\",\n",
        "    \"iteration\": 0,\n",
        "    \"max_iterations\": 2\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🚀 启动多 Agent 内容创作系统\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n📝 主题: {initial_state['topic']}\")\n",
        "print(f\"\\n💡 执行过程将实时上传到 LangSmith\")\n",
        "print(f\"   访问 https://smith.langchain.com/ 查看详细的执行追踪\")\n",
        "print(f\"\\n🔍 在 LangSmith 中你将看到：\")\n",
        "print(f\"   - 每个 Agent 的执行时间\")\n",
        "print(f\"   - 每个 Agent 的输入和输出\")\n",
        "print(f\"   - 所有 LLM 调用的 Prompt 和响应\")\n",
        "print(f\"   - Token 使用和成本统计\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# 运行工作流\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🎉 内容创作完成！\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n📋 执行流程:\")\n",
        "for msg in final_state[\"messages\"]:\n",
        "    print(f\"  ✓ {msg}\")\n",
        "\n",
        "print(f\"\\n📊 统计信息:\")\n",
        "print(f\"  - 研究笔记: {len(final_state['research_notes'])} 字\")\n",
        "print(f\"  - 文章草稿: {len(final_state['draft_content'])} 字\")\n",
        "print(f\"  - 最终文章: {len(final_state['final_content'])} 字\")\n",
        "print(f\"  - 迭代次数: {final_state['iteration']}/{final_state['max_iterations']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📄 最终文章预览（前 500 字）:\")\n",
        "print(\"=\"*80)\n",
        "print(final_state[\"final_content\"][:500] + \"...\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🔍 查看完整执行详情：\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n1. 访问 LangSmith: https://smith.langchain.com/\")\n",
        "print(f\"2. 选择项目: langgraph-multi-agent\")\n",
        "print(f\"3. 找到最新的 Run（按时间排序）\")\n",
        "print(f\"4. 点击展开，你会看到：\")\n",
        "print(f\"\\n   StateGraph Execution\")\n",
        "print(f\"   ├── 🔬 研究员 Agent\")\n",
        "print(f\"   │   ├── Inputs: {{topic: \\\"{initial_state['topic'][:30]}...\\\"}}\")\n",
        "print(f\"   │   ├── 📚 研究: ... (LLM 调用)\")\n",
        "print(f\"   │   └── Outputs: {{research_notes: \\\"...\\\"}}\")\n",
        "print(f\"   ├── ✍️ 作家 Agent\")\n",
        "print(f\"   │   ├── Inputs: {{research_notes: \\\"...\\\"}}\")\n",
        "print(f\"   │   ├── 📝 撰写: ... (LLM 调用)\")\n",
        "print(f\"   │   └── Outputs: {{draft_content: \\\"...\\\"}}\")\n",
        "print(f\"   └── 📝 编辑 Agent\")\n",
        "print(f\"       ├── Inputs: {{draft_content: \\\"...\\\"}}\")\n",
        "print(f\"       ├── 🔍 编辑: ... (LLM 调用)\")\n",
        "print(f\"       └── Outputs: {{final_content: \\\"...\\\"}}\")\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 二、总结\n",
        "\n",
        "### ✅ 本 Notebook 的关键改进\n",
        "\n",
        "**1. 完整的 Agent 可见性**\n",
        "- 使用 `@traceable` 装饰器让每个 Agent 在 LangSmith 中可见\n",
        "- 可以看到每个 Agent 的输入和输出\n",
        "- 可以看到 Agent 之间的调用关系\n",
        "\n",
        "**2. 详细的调试信息**\n",
        "- 每个 LLM 调用都有 metadata 和 tags\n",
        "- 自定义的 run_name 使追踪更直观\n",
        "- 本地打印语句显示实时执行进度\n",
        "\n",
        "**3. LangSmith 监控能力**\n",
        "- 📊 完整的执行树形结构\n",
        "- ⏱️ 每个 Agent 和 LLM 调用的耗时\n",
        "- 💰 Token 使用和成本统计\n",
        "- 🔍 完整的 Prompt 和响应内容\n",
        "- 🏷️ 通过 tags 筛选和分类\n",
        "\n",
        "### 🎯 掌握的技能\n",
        "\n",
        "1. **LangGraph 多 Agent 系统**\n",
        "   - State 状态管理\n",
        "   - Agent 定义和协作\n",
        "   - 条件路由和工作流编排\n",
        "\n",
        "2. **LangSmith 深度集成**\n",
        "   - `@traceable` 装饰器的使用\n",
        "   - Metadata 和 Tags 的配置\n",
        "   - 执行追踪的最佳实践\n",
        "\n",
        "3. **调试和优化**\n",
        "   - 完整的执行可见性\n",
        "   - 性能瓶颈识别\n",
        "   - 成本分析和优化\n",
        "\n",
        "### 🚀 应用场景\n",
        "\n",
        "- 📝 内容创作团队（本案例）\n",
        "- 🎯 客户服务系统\n",
        "- 🔍 代码审查流程\n",
        "- 📊 数据分析管道\n",
        "- 🤖 智能助手系统\n",
        "\n",
        "### 💡 最佳实践\n",
        "\n",
        "1. **使用 @traceable 装饰器**：让自定义函数在 LangSmith 中可见\n",
        "2. **添加详细的 metadata**：便于后续分析和筛选\n",
        "3. **使用有意义的名称**：emoji + 描述性名称\n",
        "4. **添加本地日志**：本地和云端都能看到执行过程\n",
        "5. **合理使用 tags**：便于分类和筛选\n",
        "\n",
        "---\n",
        "\n",
        "**🎉 恭喜！你现在可以在 LangSmith 中完整追踪多 Agent 系统的执行过程了！**\n",
        "\n",
        "**📍 下一步：**\n",
        "- 访问 LangSmith 查看你的执行记录\n",
        "- 尝试修改 Agent 逻辑\n",
        "- 添加更多 Agent\n",
        "- 实现循环和条件路由\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
