{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 LangGraph 多 Agent 系统实战\n",
    "\n",
    "本 Notebook 展示如何使用 LangGraph 构建复杂的多 Agent 协作系统，并通过 LangSmith 进行详细的监控和调试。\n",
    "\n",
    "## 📋 学习目标\n",
    "\n",
    "- LangGraph 基础概念（State、Node、Edge）\n",
    "- 构建状态机工作流\n",
    "- 多 Agent 协作模式\n",
    "- 条件路由和决策\n",
    "- **使用 LangSmith 监控每个 Agent 的执行细节**\n",
    "- 实战案例：智能内容创作团队\n",
    "\n",
    "## 💡 LangSmith 监控特性\n",
    "\n",
    "在本 Notebook 中，你将能在 LangSmith 上看到：\n",
    "- ✅ 每个 Agent 的执行时间\n",
    "- ✅ 每个 Agent 的输入状态和输出状态\n",
    "- ✅ Agent 之间的调用关系\n",
    "- ✅ 每次 LLM 调用的完整 Prompt 和响应\n",
    "- ✅ Token 使用和成本统计\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 安装依赖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langgraph langchain langchain-openai langsmith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 配置环境变量\n",
    "\n",
    "**系统环境变量**（已在 `~/.zshrc` 中配置）：\n",
    "- `LANGCHAIN_API_KEY` - LangSmith API Key\n",
    "- `OPENAI_API_KEY` - DeepSeek API Key\n",
    "\n",
    "**项目环境变量**（自动设置）：\n",
    "- `LANGCHAIN_TRACING_V2=true` - 启用 LangSmith 追踪\n",
    "- `LANGCHAIN_PROJECT=langgraph-multi-agent` - 项目名称\n",
    "- `OPENAI_API_BASE=https://api.deepseek.com` - DeepSeek API 地址\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 配置环境\n",
      "============================================================\n",
      "\n",
      "📋 配置状态：\n",
      "------------------------------------------------------------\n",
      "✅ OPENAI_API_KEY: sk-9d725...6c29 (系统)\n",
      "✅ OPENAI_API_BASE: https://api.deepseek.com (项目)\n",
      "✅ LANGCHAIN_API_KEY: lsv2_pt_9d1d...4df1 (系统)\n",
      "✅ LANGCHAIN_TRACING_V2: true (项目)\n",
      "✅ LANGCHAIN_PROJECT: langgraph-multi-agent (项目)\n",
      "------------------------------------------------------------\n",
      "\n",
      "✅ 所有配置就绪！\n",
      "✅ 访问 https://smith.langchain.com/ 查看执行详情\n",
      "============================================================\n",
      "\n",
      "✅ LLM 初始化完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"🔧 配置环境\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 自动设置项目环境变量\n",
    "os.environ.setdefault(\"LANGCHAIN_TRACING_V2\", \"true\")\n",
    "os.environ.setdefault(\"LANGCHAIN_PROJECT\", \"langgraph-multi-agent\")\n",
    "os.environ.setdefault(\"OPENAI_API_BASE\", \"https://api.deepseek.com\")\n",
    "\n",
    "# 检查系统环境变量\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "langsmith_key = os.environ.get(\"LANGCHAIN_API_KEY\", \"\")\n",
    "\n",
    "print(\"\\n📋 配置状态：\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "if api_key:\n",
    "    print(f\"✅ OPENAI_API_KEY: {api_key[:8]}...{api_key[-4:]} (系统)\")\n",
    "else:\n",
    "    print(\"❌ OPENAI_API_KEY: 未设置\")\n",
    "\n",
    "print(f\"✅ OPENAI_API_BASE: {os.environ['OPENAI_API_BASE']} (项目)\")\n",
    "\n",
    "if langsmith_key:\n",
    "    print(f\"✅ LANGCHAIN_API_KEY: {langsmith_key[:12]}...{langsmith_key[-4:]} (系统)\")\n",
    "else:\n",
    "    print(\"❌ LANGCHAIN_API_KEY: 未设置\")\n",
    "\n",
    "print(f\"✅ LANGCHAIN_TRACING_V2: {os.environ['LANGCHAIN_TRACING_V2']} (项目)\")\n",
    "print(f\"✅ LANGCHAIN_PROJECT: {os.environ['LANGCHAIN_PROJECT']} (项目)\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "if not api_key or not langsmith_key:\n",
    "    print(\"\\n⚠️  请确保在 ~/.zshrc 中配置了必需的环境变量\")\n",
    "    print(\"   然后重启 Jupyter Kernel\")\n",
    "else:\n",
    "    print(\"\\n✅ 所有配置就绪！\")\n",
    "    print(f\"✅ 访问 https://smith.langchain.com/ 查看执行详情\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 初始化 LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"\\n✅ LLM 初始化完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、多 Agent 内容创作系统\n",
    "\n",
    "### 1.1 定义状态\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AgentState 定义完成\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"多 Agent 系统的共享状态\"\"\"\n",
    "    topic: str                    # 主题\n",
    "    research_notes: str           # 研究笔记\n",
    "    draft_content: str            # 草稿\n",
    "    final_content: str            # 最终内容\n",
    "    messages: Annotated[List, operator.add]  # 执行日志\n",
    "    next_agent: str               # 下一个 Agent\n",
    "    iteration: int                # 当前迭代次数\n",
    "    max_iterations: int           # 最大迭代次数\n",
    "\n",
    "print(\"✅ AgentState 定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 创建 Agent（带完整追踪）\n",
    "\n",
    "每个 Agent 使用 `@traceable` 装饰器，在 LangSmith 中可以看到：\n",
    "- 🔍 Agent 的输入状态\n",
    "- 🔍 Agent 的输出状态  \n",
    "- 🔍 Agent 内部的所有 LLM 调用\n",
    "- 🔍 执行时间和 Token 使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agent 定义完成！\n",
      "\n",
      "💡 每个 Agent 都使用 @traceable 装饰器\n",
      "   在 LangSmith 中可以看到完整的执行过程\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langsmith import traceable\n",
    "\n",
    "# ============================================================================\n",
    "# 研究员 Agent\n",
    "# ============================================================================\n",
    "\n",
    "@traceable(\n",
    "    name=\"🔬 研究员 Agent\",\n",
    "    run_type=\"chain\",\n",
    "    tags=[\"agent\", \"researcher\", \"content-creation\"],\n",
    "    metadata={\"role\": \"researcher\", \"task\": \"research_and_analysis\"}\n",
    ")\n",
    "def researcher_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    研究员 Agent：负责收集和分析信息\n",
    "    \n",
    "    在 LangSmith 中可以看到：\n",
    "    - Input: topic\n",
    "    - Output: research_notes\n",
    "    - 执行时间\n",
    "    - LLM 调用详情\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🔬 [研究员 Agent] 开始执行\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"📥 输入 - 主题: {state['topic']}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"你是一个专业的研究员。请针对以下主题进行研究，提供关键要点和有价值的信息。\n",
    "\n",
    "主题：{topic}\n",
    "\n",
    "请提供：\n",
    "1. 核心概念定义\n",
    "2. 重要特点（3-5个）\n",
    "3. 实际应用场景\n",
    "4. 注意事项\n",
    "\n",
    "研究笔记：\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke(\n",
    "        {\"topic\": state[\"topic\"]},\n",
    "        config={\n",
    "            \"metadata\": {\n",
    "                \"agent\": \"researcher\",\n",
    "                \"step\": \"research\",\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"phase\": \"data_collection\"\n",
    "            },\n",
    "            \"tags\": [\"research_phase\"],\n",
    "            \"run_name\": f\"📚 研究: {state['topic'][:30]}\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"📤 输出 - 生成了 {len(result.content)} 字的研究笔记\")\n",
    "    print(f\"✅ [研究员 Agent] 执行完成\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"research_notes\": result.content,\n",
    "        \"messages\": [f\"[研究员] 完成研究: {state['topic'][:50]}...\"],\n",
    "        \"next_agent\": \"writer\"\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 作家 Agent\n",
    "# ============================================================================\n",
    "\n",
    "@traceable(\n",
    "    name=\"✍️ 作家 Agent\",\n",
    "    run_type=\"chain\",\n",
    "    tags=[\"agent\", \"writer\", \"content-creation\"],\n",
    "    metadata={\"role\": \"writer\", \"task\": \"content_writing\"}\n",
    ")\n",
    "def writer_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    作家 Agent：负责撰写文章\n",
    "    \n",
    "    在 LangSmith 中可以看到：\n",
    "    - Input: research_notes\n",
    "    - Output: draft_content\n",
    "    - 执行时间\n",
    "    - LLM 调用详情\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✍️ [作家 Agent] 开始执行\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"📥 输入 - 研究笔记长度: {len(state['research_notes'])} 字\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"你是一个专业的技术作家。基于研究员提供的笔记，撰写一篇结构清晰、通俗易懂的文章。\n",
    "\n",
    "主题：{topic}\n",
    "\n",
    "研究笔记：\n",
    "{research_notes}\n",
    "\n",
    "要求：\n",
    "- 使用清晰的标题和段落结构\n",
    "- 语言通俗易懂，适合初学者\n",
    "- 包含实例说明\n",
    "- 字数约500字\n",
    "\n",
    "文章内容：\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"research_notes\": state[\"research_notes\"]\n",
    "        },\n",
    "        config={\n",
    "            \"metadata\": {\n",
    "                \"agent\": \"writer\",\n",
    "                \"step\": \"writing\",\n",
    "                \"research_notes_length\": len(state[\"research_notes\"]),\n",
    "                \"phase\": \"content_creation\"\n",
    "            },\n",
    "            \"tags\": [\"writing_phase\"],\n",
    "            \"run_name\": f\"📝 撰写: {state['topic'][:30]}\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"📤 输出 - 生成了 {len(result.content)} 字的文章草稿\")\n",
    "    print(f\"✅ [作家 Agent] 执行完成\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"draft_content\": result.content,\n",
    "        \"messages\": [f\"[作家] 完成初稿撰写\"],\n",
    "        \"next_agent\": \"editor\"\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 编辑 Agent\n",
    "# ============================================================================\n",
    "\n",
    "@traceable(\n",
    "    name=\"📝 编辑 Agent\",\n",
    "    run_type=\"chain\",\n",
    "    tags=[\"agent\", \"editor\", \"content-creation\"],\n",
    "    metadata={\"role\": \"editor\", \"task\": \"review_and_improve\"}\n",
    ")\n",
    "def editor_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    编辑 Agent：负责审核和改进文章\n",
    "    \n",
    "    在 LangSmith 中可以看到：\n",
    "    - Input: draft_content\n",
    "    - Output: final_content\n",
    "    - 当前迭代次数\n",
    "    - 执行时间\n",
    "    - LLM 调用详情\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📝 [编辑 Agent] 开始执行\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"📥 输入 - 草稿长度: {len(state['draft_content'])} 字\")\n",
    "    print(f\"🔄 当前迭代: {state['iteration'] + 1}/{state['max_iterations']}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"你是一个专业的编辑。请审核并改进以下文章。\n",
    "\n",
    "原文：\n",
    "{draft_content}\n",
    "\n",
    "请：\n",
    "1. 检查语法和表达\n",
    "2. 优化结构和逻辑\n",
    "3. 确保内容准确性\n",
    "4. 增强可读性\n",
    "\n",
    "如果文章质量已经很好，保持原样并添加简短评价。\n",
    "如果需要改进，请直接输出改进后的版本。\n",
    "\n",
    "最终文章：\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke(\n",
    "        {\"draft_content\": state[\"draft_content\"]},\n",
    "        config={\n",
    "            \"metadata\": {\n",
    "                \"agent\": \"editor\",\n",
    "                \"step\": \"editing\",\n",
    "                \"iteration\": state[\"iteration\"] + 1,\n",
    "                \"max_iterations\": state[\"max_iterations\"],\n",
    "                \"draft_length\": len(state[\"draft_content\"]),\n",
    "                \"phase\": \"quality_control\"\n",
    "            },\n",
    "            \"tags\": [\"editing_phase\"],\n",
    "            \"run_name\": f\"🔍 编辑: 第{state['iteration'] + 1}轮\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    new_iteration = state[\"iteration\"] + 1\n",
    "    \n",
    "    print(f\"📤 输出 - 最终文章长度: {len(result.content)} 字\")\n",
    "    print(f\"✅ [编辑 Agent] 执行完成\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"final_content\": result.content,\n",
    "        \"messages\": [f\"[编辑] 完成审核和改进\"],\n",
    "        \"next_agent\": \"END\",\n",
    "        \"iteration\": new_iteration\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✅ Agent 定义完成！\")\n",
    "print(\"\\n💡 每个 Agent 都使用 @traceable 装饰器\")\n",
    "print(\"   在 LangSmith 中可以看到完整的执行过程\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 构建工作流\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 工作流构建完成！\n",
      "\n",
      "📊 工作流结构：\n",
      "   研究员 → 作家 → 编辑 → 结束\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# 路由函数：决定下一个节点\n",
    "def route_agent(state: AgentState) -> str:\n",
    "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
    "    if next_agent == \"END\":\n",
    "        return END\n",
    "    return next_agent\n",
    "\n",
    "# 创建图\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 添加节点\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"writer\", writer_agent)\n",
    "workflow.add_node(\"editor\", editor_agent)\n",
    "\n",
    "# 设置入口\n",
    "workflow.set_entry_point(\"researcher\")\n",
    "\n",
    "# 添加条件边\n",
    "workflow.add_conditional_edges(\n",
    "    \"researcher\",\n",
    "    route_agent,\n",
    "    {\"writer\": \"writer\", END: END}\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"writer\",\n",
    "    route_agent,\n",
    "    {\"editor\": \"editor\", END: END}\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"editor\",\n",
    "    route_agent,\n",
    "    {\"writer\": \"writer\", END: END}\n",
    ")\n",
    "\n",
    "# 编译\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"✅ 工作流构建完成！\")\n",
    "print(\"\\n📊 工作流结构：\")\n",
    "print(\"   研究员 → 作家 → 编辑 → 结束\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 运行多 Agent 系统\n",
    "\n",
    "**在 LangSmith 中查看：**\n",
    "1. 访问 https://smith.langchain.com/\n",
    "2. 选择项目：`langgraph-multi-agent`\n",
    "3. 找到最新的 Run\n",
    "4. 展开树形结构，你将看到：\n",
    "   - 🔬 研究员 Agent（包含输入输出）\n",
    "   - ✍️ 作家 Agent（包含输入输出）\n",
    "   - 📝 编辑 Agent（包含输入输出）\n",
    "   - 每个 Agent 内部的 LLM 调用详情\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🚀 启动多 Agent 内容创作系统\n",
      "================================================================================\n",
      "\n",
      "📝 主题: 深度学习中的 Transformer 架构\n",
      "\n",
      "💡 执行过程将实时上传到 LangSmith\n",
      "   访问 https://smith.langchain.com/ 查看详细的执行追踪\n",
      "\n",
      "🔍 在 LangSmith 中你将看到：\n",
      "   - 每个 Agent 的执行时间\n",
      "   - 每个 Agent 的输入和输出\n",
      "   - 所有 LLM 调用的 Prompt 和响应\n",
      "   - Token 使用和成本统计\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "🔬 [研究员 Agent] 开始执行\n",
      "============================================================\n",
      "📥 输入 - 主题: 深度学习中的 Transformer 架构\n",
      "📤 输出 - 生成了 3105 字的研究笔记\n",
      "✅ [研究员 Agent] 执行完成\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "✍️ [作家 Agent] 开始执行\n",
      "============================================================\n",
      "📥 输入 - 研究笔记长度: 3105 字\n",
      "📤 输出 - 生成了 1329 字的文章草稿\n",
      "✅ [作家 Agent] 执行完成\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "📝 [编辑 Agent] 开始执行\n",
      "============================================================\n",
      "📥 输入 - 草稿长度: 1329 字\n",
      "🔄 当前迭代: 1/2\n",
      "📤 输出 - 最终文章长度: 1643 字\n",
      "✅ [编辑 Agent] 执行完成\n",
      "============================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "🎉 内容创作完成！\n",
      "================================================================================\n",
      "\n",
      "📋 执行流程:\n",
      "  ✓ [研究员] 完成研究: 深度学习中的 Transformer 架构...\n",
      "  ✓ [作家] 完成初稿撰写\n",
      "  ✓ [编辑] 完成审核和改进\n",
      "\n",
      "📊 统计信息:\n",
      "  - 研究笔记: 3105 字\n",
      "  - 文章草稿: 1329 字\n",
      "  - 最终文章: 1643 字\n",
      "  - 迭代次数: 1/2\n",
      "\n",
      "================================================================================\n",
      "📄 最终文章预览（前 500 字）:\n",
      "================================================================================\n",
      "### **Transformer：让AI真正“读懂”上下文的革命性架构**\n",
      "\n",
      "在人工智能领域，尤其是在语言理解与生成任务中，Transformer架构的提出堪称一场根本性变革。它不仅是ChatGPT、文心一言等智能助手的核心引擎，更彻底重塑了机器处理序列信息的方式。\n",
      "\n",
      "---\n",
      "\n",
      "#### **一、什么是Transformer？**\n",
      "\n",
      "想象一下，你在阅读一句话时，不是逐词顺序理解，而是能瞬间把握所有词语之间的关联——这正是Transformer的核心能力。\n",
      "\n",
      "该架构由Google团队于2017年提出，完全摒弃了传统的循环处理模式，转而采用名为“自注意力”（Self-Attention）的创新机制。简单来说，自注意力机制允许序列中的每个元素直接与所有其他元素进行“交互”。\n",
      "\n",
      "**举例来说**：在理解“苹果公司发布了新款手机”这句话时，当模型处理“苹果”一词，自注意力机制会同时考量其与“公司”“发布”“手机”等词的关系，从而准确判断这里的“苹果”指品牌而非水果。\n",
      "\n",
      "---\n",
      "\n",
      "#### **二、Transformer的三大核心优势**\n",
      "\n",
      "**1. 全局理解能力**  \n",
      "传统循环神经网络（RN...\n",
      "\n",
      "================================================================================\n",
      "🔍 查看完整执行详情：\n",
      "================================================================================\n",
      "\n",
      "1. 访问 LangSmith: https://smith.langchain.com/\n",
      "2. 选择项目: langgraph-multi-agent\n",
      "3. 找到最新的 Run（按时间排序）\n",
      "4. 点击展开，你会看到：\n",
      "\n",
      "   StateGraph Execution\n",
      "   ├── 🔬 研究员 Agent\n",
      "   │   ├── Inputs: {topic: \"深度学习中的 Transformer 架构...\"}\n",
      "   │   ├── 📚 研究: ... (LLM 调用)\n",
      "   │   └── Outputs: {research_notes: \"...\"}\n",
      "   ├── ✍️ 作家 Agent\n",
      "   │   ├── Inputs: {research_notes: \"...\"}\n",
      "   │   ├── 📝 撰写: ... (LLM 调用)\n",
      "   │   └── Outputs: {draft_content: \"...\"}\n",
      "   └── 📝 编辑 Agent\n",
      "       ├── Inputs: {draft_content: \"...\"}\n",
      "       ├── 🔍 编辑: ... (LLM 调用)\n",
      "       └── Outputs: {final_content: \"...\"}\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 初始化状态\n",
    "initial_state = {\n",
    "    \"topic\": \"深度学习中的 Transformer 架构\",\n",
    "    \"research_notes\": \"\",\n",
    "    \"draft_content\": \"\",\n",
    "    \"final_content\": \"\",\n",
    "    \"messages\": [],\n",
    "    \"next_agent\": \"researcher\",\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 2\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚀 启动多 Agent 内容创作系统\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n📝 主题: {initial_state['topic']}\")\n",
    "print(f\"\\n💡 执行过程将实时上传到 LangSmith\")\n",
    "print(f\"   访问 https://smith.langchain.com/ 查看详细的执行追踪\")\n",
    "print(f\"\\n🔍 在 LangSmith 中你将看到：\")\n",
    "print(f\"   - 每个 Agent 的执行时间\")\n",
    "print(f\"   - 每个 Agent 的输入和输出\")\n",
    "print(f\"   - 所有 LLM 调用的 Prompt 和响应\")\n",
    "print(f\"   - Token 使用和成本统计\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 运行工作流\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 内容创作完成！\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📋 执行流程:\")\n",
    "for msg in final_state[\"messages\"]:\n",
    "    print(f\"  ✓ {msg}\")\n",
    "\n",
    "print(f\"\\n📊 统计信息:\")\n",
    "print(f\"  - 研究笔记: {len(final_state['research_notes'])} 字\")\n",
    "print(f\"  - 文章草稿: {len(final_state['draft_content'])} 字\")\n",
    "print(f\"  - 最终文章: {len(final_state['final_content'])} 字\")\n",
    "print(f\"  - 迭代次数: {final_state['iteration']}/{final_state['max_iterations']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📄 最终文章预览（前 500 字）:\")\n",
    "print(\"=\"*80)\n",
    "print(final_state[\"final_content\"][:500] + \"...\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"🔍 查看完整执行详情：\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n1. 访问 LangSmith: https://smith.langchain.com/\")\n",
    "print(f\"2. 选择项目: langgraph-multi-agent\")\n",
    "print(f\"3. 找到最新的 Run（按时间排序）\")\n",
    "print(f\"4. 点击展开，你会看到：\")\n",
    "print(f\"\\n   StateGraph Execution\")\n",
    "print(f\"   ├── 🔬 研究员 Agent\")\n",
    "print(f\"   │   ├── Inputs: {{topic: \\\"{initial_state['topic'][:30]}...\\\"}}\")\n",
    "print(f\"   │   ├── 📚 研究: ... (LLM 调用)\")\n",
    "print(f\"   │   └── Outputs: {{research_notes: \\\"...\\\"}}\")\n",
    "print(f\"   ├── ✍️ 作家 Agent\")\n",
    "print(f\"   │   ├── Inputs: {{research_notes: \\\"...\\\"}}\")\n",
    "print(f\"   │   ├── 📝 撰写: ... (LLM 调用)\")\n",
    "print(f\"   │   └── Outputs: {{draft_content: \\\"...\\\"}}\")\n",
    "print(f\"   └── 📝 编辑 Agent\")\n",
    "print(f\"       ├── Inputs: {{draft_content: \\\"...\\\"}}\")\n",
    "print(f\"       ├── 🔍 编辑: ... (LLM 调用)\")\n",
    "print(f\"       └── Outputs: {{final_content: \\\"...\\\"}}\")\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、总结\n",
    "\n",
    "### ✅ 本 Notebook 的关键改进\n",
    "\n",
    "**1. 完整的 Agent 可见性**\n",
    "- 使用 `@traceable` 装饰器让每个 Agent 在 LangSmith 中可见\n",
    "- 可以看到每个 Agent 的输入和输出\n",
    "- 可以看到 Agent 之间的调用关系\n",
    "\n",
    "**2. 详细的调试信息**\n",
    "- 每个 LLM 调用都有 metadata 和 tags\n",
    "- 自定义的 run_name 使追踪更直观\n",
    "- 本地打印语句显示实时执行进度\n",
    "\n",
    "**3. LangSmith 监控能力**\n",
    "- 📊 完整的执行树形结构\n",
    "- ⏱️ 每个 Agent 和 LLM 调用的耗时\n",
    "- 💰 Token 使用和成本统计\n",
    "- 🔍 完整的 Prompt 和响应内容\n",
    "- 🏷️ 通过 tags 筛选和分类\n",
    "\n",
    "### 🎯 掌握的技能\n",
    "\n",
    "1. **LangGraph 多 Agent 系统**\n",
    "   - State 状态管理\n",
    "   - Agent 定义和协作\n",
    "   - 条件路由和工作流编排\n",
    "\n",
    "2. **LangSmith 深度集成**\n",
    "   - `@traceable` 装饰器的使用\n",
    "   - Metadata 和 Tags 的配置\n",
    "   - 执行追踪的最佳实践\n",
    "\n",
    "3. **调试和优化**\n",
    "   - 完整的执行可见性\n",
    "   - 性能瓶颈识别\n",
    "   - 成本分析和优化\n",
    "\n",
    "### 🚀 应用场景\n",
    "\n",
    "- 📝 内容创作团队（本案例）\n",
    "- 🎯 客户服务系统\n",
    "- 🔍 代码审查流程\n",
    "- 📊 数据分析管道\n",
    "- 🤖 智能助手系统\n",
    "\n",
    "### 💡 最佳实践\n",
    "\n",
    "1. **使用 @traceable 装饰器**：让自定义函数在 LangSmith 中可见\n",
    "2. **添加详细的 metadata**：便于后续分析和筛选\n",
    "3. **使用有意义的名称**：emoji + 描述性名称\n",
    "4. **添加本地日志**：本地和云端都能看到执行过程\n",
    "5. **合理使用 tags**：便于分类和筛选\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 恭喜！你现在可以在 LangSmith 中完整追踪多 Agent 系统的执行过程了！**\n",
    "\n",
    "**📍 下一步：**\n",
    "- 访问 LangSmith 查看你的执行记录\n",
    "- 尝试修改 Agent 逻辑\n",
    "- 添加更多 Agent\n",
    "- 实现循环和条件路由\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
