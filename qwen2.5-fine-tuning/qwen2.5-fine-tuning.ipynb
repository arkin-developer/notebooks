{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e6565e-d437-46a9-b294-d024e162f573",
   "metadata": {},
   "source": [
    "# 🎯 Qwen2.5系列模型**LoRA/QLoRA** **微调案例**\n",
    "\n",
    "> 说明：先用一个兼容的小模型（例如 `Qwen/Qwen2.5-1.5B-Instruct`）跑通流程，后续将 `MODEL_ID` 替换为你找到的 DeepSeek 模型仓库名即可，代码无需改动。\n",
    "> \n",
    "\n",
    "**目标**：在单卡 A10（24GB）上，以 *小参数量* 的模型为例（本案例采用ModelScope来替换HuggingFace），用 **LoRA/QLoRA** 跑通一次完整的 *指令微调*（Instruction Tuning）流程。  \n",
    "**硬件建议**：A10 24GB；  \n",
    "**软件建议**：Python 3.10+、CUDA 12.x、PyTorch 2.3+。\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 本教程包括\n",
    "1. LoRA/QLoRA 简介\n",
    "2. 硬件检测与配置环境\n",
    "3. 模型与数据集下载  \n",
    "4. 数据预处理 \n",
    "5. LoRA微调\n",
    "6. 模型测试评估\n",
    "\n",
    "> 注：全流程都在 **Jupyter Lab** 中逐格运行即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cb777-2b7d-4310-9259-f30e8aad9dad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 一、LoRA / QLoRA 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe3ac9-fde6-4188-a104-6fe1ad57b723",
   "metadata": {},
   "source": [
    "### LoRA（Low-Rank Adaptation）\n",
    "LoRA 是一种 **轻量化模型微调方法**，它的核心思想是：  \n",
    "- 在保持原始预训练模型参数 **冻结不变** 的前提下，只在部分权重矩阵（通常是 Transformer 的注意力层）上引入 **低秩矩阵分解**。  \n",
    "- 用一个低秩的参数矩阵（A、B）来近似原始大矩阵的更新，从而 **大幅减少训练参数量**。  \n",
    "- 优点：  \n",
    "  - **参数高效**：只需训练极少量的新增参数（可低至 0.1%）。  \n",
    "  - **存储友好**：多个下游任务可以共享同一个基础模型，仅保存不同任务的 LoRA 权重。  \n",
    "  - **部署灵活**：推理时直接将 LoRA 权重合并到原模型，无需额外计算开销。\n",
    "\n",
    "> 简单理解：LoRA 就像是在大模型的“固定主干”上，插入一些 **小而聪明的适配器**，让它快速学会新任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec29c50-b0e1-4548-a630-f06b887a8ce1",
   "metadata": {},
   "source": [
    "### QLoRA（Quantized LoRA）本文不涉及\n",
    "QLoRA 是对 LoRA 的进一步优化，它结合了 **量化技术**，使得大模型的微调在 **单卡消费级显卡** 上也可行。  \n",
    "- 核心思路：  \n",
    "  1. 先将大模型的参数进行 **4-bit 量化（NF4 方案）**，降低显存占用。  \n",
    "  2. 在量化后的权重上，应用 **LoRA 适配器** 进行微调。  \n",
    "  3. 训练时仅更新 LoRA 层，而量化权重保持冻结。  \n",
    "\n",
    "- 优点：  \n",
    "  - **极致显存节省**：可在一张 24GB 显存的 GPU 上微调百亿参数模型。  \n",
    "  - **保持性能**：量化后的 QLoRA 与全精度微调效果接近甚至相当。  \n",
    "  - **实用性强**：特别适合个人开发者和中小团队。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7f704-0602-4eee-974c-f7edbe51c71e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 对比总结\n",
    "| 方法   | 主要手段                   | 显存消耗 | 训练参数量 | 适用场景 |\n",
    "|--------|---------------------------|----------|------------|----------|\n",
    "| LoRA   | 低秩矩阵分解               | 较低     | 千万级别   | 中等规模模型的高效微调 |\n",
    "| QLoRA  | 量化（4-bit） + LoRA 适配 | 极低     | 千万级别   | 超大模型在消费级 GPU 上的微调 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe81e3-9470-422f-b479-7b118f1bbd03",
   "metadata": {},
   "source": [
    "## 二、硬件检测与配置环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80687ecd-4115-4970-acd4-135208628c36",
   "metadata": {},
   "source": [
    "### 硬件检测（Linux）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b0e2c0-e622-4ee7-bb91-b6e53130fb26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:58:52.872083Z",
     "iopub.status.busy": "2025-08-26T17:58:52.871953Z",
     "iopub.status.idle": "2025-08-26T17:58:53.999404Z",
     "shell.execute_reply": "2025-08-26T17:58:53.998998Z",
     "shell.execute_reply.started": "2025-08-26T17:58:52.872070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "操作系统: Linux\n",
      "系统版本: #1 SMP Mon Mar 10 11:07:41 CST 2025\n",
      "发行版本: 5.10.134-18.0.2.lifsea8.x86_64\n",
      "详细信息: Linux-5.10.134-18.0.2.lifsea8.x86_64-x86_64-with-glibc2.35\n",
      "Python版本: 3.11.11 (main, Mar 11 2025, 18:25:39) [GCC 11.4.0]\n",
      "处理器: x86_64\n",
      "机器类型: x86_64\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: gputil in /usr/local/lib/python3.11/site-packages (1.4.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "显卡型号: NVIDIA A10\n",
      "显存总量: 23028.0 MB\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "\n",
    "print(\"操作系统:\", platform.system())          # Windows / Linux / Darwin (macOS)\n",
    "print(\"系统版本:\", platform.version())         # 内核或版本号\n",
    "print(\"发行版本:\", platform.release())         # 例如 10 / 11 / 22.6.0\n",
    "print(\"详细信息:\", platform.platform())        # 汇总\n",
    "print(\"Python版本:\", sys.version)             # Python 解释器版本\n",
    "print(\"处理器:\", platform.processor())         # CPU 信息\n",
    "print(\"机器类型:\", platform.machine())         # x86_64 / arm64\n",
    "\n",
    "# 安装检测显卡的依赖\n",
    "%pip install gputil\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"显卡型号: {gpu.name}\")\n",
    "    print(f\"显存总量: {gpu.memoryTotal} MB\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c85d87-cf4c-4461-a35f-ae0ed02b6c11",
   "metadata": {},
   "source": [
    "### 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e562bedc-2f0d-4ee4-9fec-61263667dce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:58:54.000438Z",
     "iopub.status.busy": "2025-08-26T17:58:54.000246Z",
     "iopub.status.idle": "2025-08-26T17:58:59.940007Z",
     "shell.execute_reply": "2025-08-26T17:58:59.939448Z",
     "shell.execute_reply.started": "2025-08-26T17:58:54.000422Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.3.1+cu121 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.3.1+cu121\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers==4.55.4 in /usr/local/lib/python3.11/site-packages (4.55.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (2025.1.31)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: modelscope==1.29.0 in /usr/local/lib/python3.11/site-packages (1.29.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (3.17.0)\n",
      "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (65.5.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.29.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.29.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.29.0) (2025.1.31)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: peft==0.17.1 in /usr/local/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (2.3.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (4.55.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (1.10.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (0.34.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2024.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (1.1.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.17.1) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.17.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.17.1) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers->peft==0.17.1) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers->peft==0.17.1) (0.21.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: datasets==3.2.0 in /usr/local/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (3.12.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.2.0) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->datasets==3.2.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==3.2.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==3.2.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: accelerate==1.10.0 in /usr/local/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (2.3.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (2024.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (1.1.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate==1.10.0) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate==1.10.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate==1.10.0) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.3.1+cu121\n",
    "%pip install transformers==4.55.4\n",
    "%pip install modelscope==1.29.0\n",
    "%pip install peft==0.17.1\n",
    "%pip install datasets==3.2.0\n",
    "%pip install accelerate==1.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae0ef2-b29b-47c0-b000-2377b64d2c4e",
   "metadata": {},
   "source": [
    "### 检查环境版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6cad49f-9ba7-4f2a-b5b3-51f63735617e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:58:59.940781Z",
     "iopub.status.busy": "2025-08-26T17:58:59.940629Z",
     "iopub.status.idle": "2025-08-26T17:59:10.587187Z",
     "shell.execute_reply": "2025-08-26T17:59:10.586775Z",
     "shell.execute_reply.started": "2025-08-26T17:58:59.940766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:07.036101: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-27 01:59:07.623431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-27 01:59:08.838843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.3.1+cu121\n",
      "transformers: 4.55.4\n",
      "modelscope: 1.29.0\n",
      "peft: 0.17.1\n",
      "datasets: 3.2.0\n",
      "accelerate: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "# 📌 打印脚本相关库的版本信息\n",
    "import torch, transformers, modelscope, peft\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "\n",
    "# transformers 是 peft 和 modelscope 依赖的核心库\n",
    "try:\n",
    "    import transformers\n",
    "    print(\"transformers:\", transformers.__version__)\n",
    "except ImportError:\n",
    "    print(\"transformers: 未安装\")\n",
    "\n",
    "try:\n",
    "    import modelscope\n",
    "    print(\"modelscope:\", modelscope.__version__)\n",
    "except ImportError:\n",
    "    print(\"modelscope: 未安装\")\n",
    "\n",
    "try:\n",
    "    import peft\n",
    "    print(\"peft:\", peft.__version__)\n",
    "except ImportError:\n",
    "    print(\"peft: 未安装\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(\"datasets:\", datasets.__version__)\n",
    "except ImportError:\n",
    "    print(\"datasets: 未安装\")\n",
    "\n",
    "try:\n",
    "    import accelerate\n",
    "    print(\"accelerate:\", accelerate.__version__)\n",
    "except ImportError:\n",
    "    print(\"accelerate: 未安装\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97315bf-cb93-4ceb-8bd6-6da5da3748af",
   "metadata": {},
   "source": [
    "## 三、模型与数据集下载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfaeffd-b73a-491e-8273-a8db6a069535",
   "metadata": {},
   "source": [
    "### Qwen2.5-1.5B模型下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e89730e-3b76-47ed-9c85-06672b867adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:59:10.587927Z",
     "iopub.status.busy": "2025-08-26T17:59:10.587649Z",
     "iopub.status.idle": "2025-08-26T17:59:28.787989Z",
     "shell.execute_reply": "2025-08-26T17:59:28.787573Z",
     "shell.execute_reply.started": "2025-08-26T17:59:10.587912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:11,412 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:12,225 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"qwen/Qwen2.5-1.5B-Instruct\"  # 可替换\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d92ea8-11cc-49a8-8df6-9cb7bf3df8e5",
   "metadata": {},
   "source": [
    "### alpaca数据集下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea33c99f-f5fa-4115-b4dc-e3000b5f2f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:59:28.788685Z",
     "iopub.status.busy": "2025-08-26T17:59:28.788491Z",
     "iopub.status.idle": "2025-08-26T17:59:38.759889Z",
     "shell.execute_reply": "2025-08-26T17:59:38.759492Z",
     "shell.execute_reply.started": "2025-08-26T17:59:28.788672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:29,044 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n",
      "2025-08-27 01:59:29,714 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from AI-ModelScope/alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n",
      "2025-08-27 01:59:29,714 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from AI-ModelScope/alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n",
      "2025-08-27 01:59:29,714 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from AI-ModelScope/alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "\n",
    "ds =  MsDataset.load('AI-ModelScope/alpaca-gpt4-data-zh', subset_name='default', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef368533-dbe1-42ed-a8c2-2f07509923d8",
   "metadata": {},
   "source": [
    "## 四、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb9f6d-22ef-404d-8649-2910e5e9911b",
   "metadata": {},
   "source": [
    "### 计算max_length\n",
    "根据数据集的token长度来计算最合适的长度，有利于数据预处理的速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4135b13f-365d-4a47-9f6d-67b06e651009",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-08-26T18:00:46.565661Z",
     "iopub.status.busy": "2025-08-26T18:00:46.565357Z",
     "iopub.status.idle": "2025-08-26T18:00:49.381990Z",
     "shell.execute_reply": "2025-08-26T18:00:49.381539Z",
     "shell.execute_reply.started": "2025-08-26T18:00:46.565638Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.67.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "开始统计，抽样 5000 条数据 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2857.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Token 长度统计结果 ===\n",
      "最大长度: 532\n",
      "平均长度: 143.24\n",
      "95% 分位数长度: 293\n",
      "=========================\n",
      "👉 推荐 max_length = 293\n",
      "(模型支持的最大长度 = 131072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def recommend_max_length(dataset, tokenizer, sample_size=5000, quantile=95):\n",
    "    \"\"\"\n",
    "    自动统计 token 长度分布，并推荐 max_length\n",
    "    Args:\n",
    "        dataset: MsDataset 对象\n",
    "        tokenizer: HF AutoTokenizer\n",
    "        sample_size: 抽样数量（避免全量太慢）\n",
    "        quantile: 分位数（默认95）\n",
    "    \"\"\"\n",
    "    total = min(sample_size, len(dataset))\n",
    "    lengths = []\n",
    "\n",
    "    print(f\"开始统计，抽样 {total} 条数据 ...\")\n",
    "\n",
    "    for i in tqdm(range(total)):\n",
    "        ex = dataset[i]\n",
    "        instruction = ex.get(\"instruction\", \"\")\n",
    "        input_text = ex.get(\"input\", \"\") or \"\"\n",
    "        output_text = ex.get(\"output\", \"\")\n",
    "\n",
    "        if input_text.strip():\n",
    "            prompt = f\"指令: {instruction}\\n输入: {input_text}\\n回答:\"\n",
    "        else:\n",
    "            prompt = f\"指令: {instruction}\\n回答:\"\n",
    "\n",
    "        full_text = prompt + output_text\n",
    "        tokenized = tokenizer(full_text, truncation=False)\n",
    "        lengths.append(len(tokenized[\"input_ids\"]))\n",
    "\n",
    "    max_len = max(lengths)\n",
    "    avg_len = np.mean(lengths)\n",
    "    q_len = np.percentile(lengths, quantile)\n",
    "\n",
    "    print(\"\\n=== Token 长度统计结果 ===\")\n",
    "    print(f\"最大长度: {max_len}\")\n",
    "    print(f\"平均长度: {avg_len:.2f}\")\n",
    "    print(f\"{quantile}% 分位数长度: {q_len:.0f}\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"👉 推荐 max_length = {int(min(q_len, tokenizer.model_max_length))}\")\n",
    "    print(f\"(模型支持的最大长度 = {tokenizer.model_max_length})\")\n",
    "\n",
    "    return int(min(q_len, tokenizer.model_max_length))\n",
    "\n",
    "\n",
    "# 计算数据集应该定义的最大长度\n",
    "max_length = recommend_max_length(ds, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53410742-ec2d-4383-ad76-43cb6b997ca4",
   "metadata": {},
   "source": [
    "### 预处理（构造Dataset）\n",
    "需要针对自己的数据集范式来编写，这里只针对alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f40f313-12aa-4dab-a9aa-7a2197706475",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-08-26T18:01:50.344842Z",
     "iopub.status.busy": "2025-08-26T18:01:50.344550Z",
     "iopub.status.idle": "2025-08-26T18:01:50.411198Z",
     "shell.execute_reply": "2025-08-26T18:01:50.410786Z",
     "shell.execute_reply.started": "2025-08-26T18:01:50.344826Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据处理完成\n"
     ]
    }
   ],
   "source": [
    "# 自定义数据处理函数(需要针对自己的数据集范式来编写，这里只针对alpaca)\n",
    "def preprocess(example):\n",
    "    # 丢掉 instruction 或 output 缺失的样本\n",
    "    if not example['instruction'] or not example['output']:\n",
    "        return None\n",
    "\n",
    "    # alpaca 数据有指令、输入、输出三个标签\n",
    "    instruction = example['instruction']\n",
    "    input_text = example.get('input') or \"\"  # input 可能为 None\n",
    "    output_text = example['output']\n",
    "\n",
    "    if input_text.strip():\n",
    "        prompt = f\"指令: {instruction}\\n输入: {input_text}\\n回答:\"\n",
    "    else:\n",
    "        prompt = f\"指令: {instruction}\\n回答:\"\n",
    "\n",
    "    full_text = prompt + output_text\n",
    "\n",
    "    enc = tokenizer(\n",
    "        full_text,  # 需要进行token化的文本\n",
    "        truncation=True,  # 文本过大的时候是否截断\n",
    "        max_length=max_length,  # 根据模型和数据集决定最合适的\n",
    "        padding=\"max_length\",  # 🔹 保证长度一致，DataLoader 堆叠安全\n",
    "        return_tensors=\"pt\"  # 返回的数据类型，pt:pytorch.tensor; tf:tensorflow; np:numpy\n",
    "    )\n",
    "    # 单个样本是字典格式\n",
    "    return {\n",
    "        \"input_ids\": enc[\"input_ids\"][0],\n",
    "        \"labels\": enc[\"input_ids\"][0]\n",
    "    }\n",
    "\n",
    "train_dataset = ds.map(preprocess)\n",
    "train_dataset = train_dataset.filter(lambda x: x is not None)\n",
    "\n",
    "print('数据处理完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d17b5-dcff-4b59-949c-3bdccc212392",
   "metadata": {},
   "source": [
    "### 构造DataLoader\n",
    "将预处理好的Dataset进行Padding后方便拼接成多个batch的向量，为训练作准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee1615a-3038-4ffc-9eb7-7f42a0188d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:00.301646Z",
     "iopub.status.busy": "2025-08-26T18:02:00.301241Z",
     "iopub.status.idle": "2025-08-26T18:02:00.323938Z",
     "shell.execute_reply": "2025-08-26T18:02:00.323577Z",
     "shell.execute_reply.started": "2025-08-26T18:02:00.301631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数: 48818\n",
      "训练集样本数: 39054\n",
      "测试集样本数: 9764\n",
      "小训练集样本数: 2000\n",
      "小测试集样本数: 500\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# 🛠️ 自定义批处理函数 (collate_fn)\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    作用：\n",
    "    - DataLoader 会把一个 batch 的样本（list[dict]）传进来\n",
    "    - 这里需要手动拼接成 tensor，并且对齐长度（pad）\n",
    "    \"\"\"\n",
    "\n",
    "    # 取出每个样本的 input_ids 和 labels，转成 tensor\n",
    "    input_ids = [torch.tensor(item[\"input_ids\"]) for item in batch]\n",
    "    labels = [torch.tensor(item[\"labels\"]) for item in batch]\n",
    "\n",
    "    # 🔹 对 input_ids 做 padding\n",
    "    #   - batch_first=True: 结果形状 (batch_size, seq_len)\n",
    "    #   - padding_value=tokenizer.pad_token_id: 使用 tokenizer 的 pad_token_id 填充\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # 🔹 对 labels 做 padding\n",
    "    #   - 注意这里 padding_value = -100\n",
    "    #   - 在 PyTorch 的 CrossEntropyLoss 里，-100 会被忽略，不参与 loss 计算\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(\n",
    "        labels, batch_first=True, padding_value=-100\n",
    "    )\n",
    "\n",
    "    # 返回字典，方便直接喂给模型\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "\n",
    "# 在数据预处理后，分割训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 获取数据集的总长度\n",
    "total_samples = len(train_dataset)\n",
    "print(f\"总样本数: {total_samples}\")\n",
    "\n",
    "# 设置随机种子确保可重复性\n",
    "np.random.seed(42)\n",
    "\n",
    "# 分割训练集和测试集 (80% 训练, 20% 测试)\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(total_samples), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 创建训练集和测试集\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "test_subset = Subset(train_dataset, test_indices)\n",
    "\n",
    "print(f\"训练集样本数: {len(train_subset)}\")\n",
    "print(f\"测试集样本数: {len(test_subset)}\")\n",
    "\n",
    "# 为了快速验证，可以只取部分数据\n",
    "small_train_dataset = Subset(train_subset, range(min(2000, len(train_subset))))\n",
    "small_test_dataset = Subset(test_subset, range(min(500, len(test_subset))))\n",
    "\n",
    "print(f\"小训练集样本数: {len(small_train_dataset)}\")\n",
    "print(f\"小测试集样本数: {len(small_test_dataset)}\")\n",
    "\n",
    "# 构建训练和测试的 DataLoader\n",
    "train_loader = DataLoader(\n",
    "    small_train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    small_test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,  # 测试时不需要打乱\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3096f-ff18-4add-b275-678d51aea408",
   "metadata": {},
   "source": [
    "## 五、LoRA微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fe51a-3b1d-44d2-aba4-a1bd46903665",
   "metadata": {},
   "source": [
    "### LoRA参数说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7645b00-73b5-46f9-83fe-ad0145c55b83",
   "metadata": {},
   "source": [
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=4,                          \n",
    "    lora_alpha=16,               \n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  \n",
    "    lora_dropout=0.05,             \n",
    "    bias=\"none\",               \n",
    "    task_type=\"CAUSAL_LM\"         \n",
    ")\n",
    "```\n",
    "\n",
    "r=4\n",
    "- 表示低秩矩阵的秩值（rank），值越大 → 适配能力更强 → 参数量也随之增加。  \n",
    "- 这里选择 `4`，意味着 **轻量级训练**，适合小规模任务或快速实验。  \n",
    "\n",
    "lora_alpha=16\n",
    "- 缩放因子，用于调整 LoRA 的输出幅度。  \n",
    "- 一般经验是 **lora_alpha ≈ 2 × r**，所以这里 `16` 配合 `r=4` 是合理的。  \n",
    "\n",
    "target_modules=[\"q_proj\", \"v_proj\"]\n",
    "- LoRA 只在注意力机制的 **Query** 和 **Value** 投影层中生效。  \n",
    "- 这是最常见的设置，既保证效果，又控制参数量。\n",
    "- [\"q_proj\", \"v_proj\"] → 默认推荐，90% 的场景适用（对话、问答、指令跟随）。\n",
    "- [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] → 全量 Attention，参数量大一些，适合任务更复杂（如多模态对齐）。\n",
    "- [\"gate_proj\", \"up_proj\", \"down_proj\"] → 改 MLP 层，适合需要调整“知识表达”的场景（例如数学推理）。\n",
    "- [\"q_proj\", \"v_proj\", \"down_proj\"] → 混合方式，有时能进一步提升性能。\n",
    "\n",
    "lora_dropout=0.05\n",
    "- 在 LoRA 层中添加 **5% 的 dropout**，提升泛化能力。  \n",
    "- 数据量很大时可以调低到 `0`；数据少时可以适当调高（如 `0.1`）。  \n",
    "\n",
    "bias=\"none\"\n",
    "- 不训练 bias 参数，保证模型轻量化。  \n",
    "- 大多数场景下用 `\"none\"` 即可。  \n",
    "\n",
    "task_type=\"CAUSAL_LM\"\n",
    "- 表示任务是 **自回归语言建模**（比如 Qwen、GPT 类模型）。  \n",
    "- 必须和任务类型一致，否则 forward 过程会报错。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25a924-a0ca-4779-9006-59be35ecb388",
   "metadata": {},
   "source": [
    "### 配置 LoRA 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f547e8-9520-40aa-a9dd-3aeef97f305f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:14.210337Z",
     "iopub.status.busy": "2025-08-26T18:02:14.210066Z",
     "iopub.status.idle": "2025-08-26T18:02:15.611953Z",
     "shell.execute_reply": "2025-08-26T18:02:15.611408Z",
     "shell.execute_reply.started": "2025-08-26T18:02:14.210321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 544,768 || all params: 1,544,259,072 || trainable%: 0.0353\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4,            \n",
    "    lora_alpha=16,                \n",
    "    target_modules=[\"q_proj\", \"v_proj\"], \n",
    "    lora_dropout=0.05,             \n",
    "    bias=\"none\",                    \n",
    "    task_type=\"CAUSAL_LM\"           \n",
    ")\n",
    "\n",
    "# 🚀 将基础模型包装为 PEFT 模型\n",
    "model = get_peft_model(model, lora_config)  # 这里默认会冻结非LoRA的参数\n",
    "\n",
    "# 打印当前可训练参数量（仅 LoRA 部分），其余参数被冻结\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 训练超参数\n",
    "num_train_epochs = 2  # 对完整的数据集训练多少个批次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6e3f0-b17b-4001-9884-b41af16157b2",
   "metadata": {},
   "source": [
    "### 确认参数是否冻结\n",
    "这里只需要训练LoRA新增的参数层\n",
    "输出应该只包含 lora_A、lora_B 之类的增量参数名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08575633-4676-4e2d-94dd-aba87aff7062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:22.341597Z",
     "iopub.status.busy": "2025-08-26T18:02:22.341021Z",
     "iopub.status.idle": "2025-08-26T18:02:22.346958Z",
     "shell.execute_reply": "2025-08-26T18:02:22.346462Z",
     "shell.execute_reply.started": "2025-08-26T18:02:22.341577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:  # 这里只打印有梯度信息的\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb750b2e-e557-4946-90d3-254efded1b21",
   "metadata": {},
   "source": [
    "### 开始微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07bd5b04-8876-4438-b711-db19c396adfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:30.384307Z",
     "iopub.status.busy": "2025-08-26T18:02:30.383865Z",
     "iopub.status.idle": "2025-08-26T18:15:36.563907Z",
     "shell.execute_reply": "2025-08-26T18:15:36.563472Z",
     "shell.execute_reply.started": "2025-08-26T18:02:30.384287Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始第 1/2 轮训练...\n",
      "Epoch 1/2 | Step 0/500 | Loss 4.3384 | Avg Loss 4.3384 | Progress 1/1000\n",
      "Epoch 1/2 | Step 100/500 | Loss 1.0286 | Avg Loss 1.2016 | Progress 101/1000\n",
      "Epoch 1/2 | Step 200/500 | Loss 0.7692 | Avg Loss 1.0262 | Progress 201/1000\n",
      "Epoch 1/2 | Step 300/500 | Loss 0.3082 | Avg Loss 0.9605 | Progress 301/1000\n",
      "Epoch 1/2 | Step 400/500 | Loss 0.4948 | Avg Loss 0.9209 | Progress 401/1000\n",
      "第 1 轮训练完成，平均损失: 0.8999\n",
      "\n",
      "开始第 2/2 轮训练...\n",
      "Epoch 2/2 | Step 0/500 | Loss 0.6446 | Avg Loss 0.6446 | Progress 501/1000\n",
      "Epoch 2/2 | Step 100/500 | Loss 0.4342 | Avg Loss 0.7611 | Progress 601/1000\n",
      "Epoch 2/2 | Step 200/500 | Loss 0.9296 | Avg Loss 0.7682 | Progress 701/1000\n",
      "Epoch 2/2 | Step 300/500 | Loss 1.0355 | Avg Loss 0.7783 | Progress 801/1000\n",
      "Epoch 2/2 | Step 400/500 | Loss 0.5083 | Avg Loss 0.7844 | Progress 901/1000\n",
      "第 2 轮训练完成，平均损失: 0.7941\n",
      "\n",
      "训练完成！\n",
      "正在保存模型到: ./qwen2.5-finetuned-lora\n",
      "模型和配置已保存到: ./qwen2.5-finetuned-lora\n",
      "可训练参数数量: 544,768\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import os\n",
    "\n",
    "# 创建保存目录\n",
    "model_save_path = \"./qwen2.5-finetuned-lora\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# 优化器设置\n",
    "optimizer = AdamW(model.parameters(), lr=2e-4)\n",
    "\n",
    "# 训练循环\n",
    "model.train()\n",
    "total_steps = len(train_loader) * num_train_epochs\n",
    "current_step = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    print(f\"\\n开始第 {epoch + 1}/{num_train_epochs} 轮训练...\")\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(model.device)\n",
    "        labels = batch[\"labels\"].to(model.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        current_step += 1\n",
    "\n",
    "        # 每 100 个 step 打印一次进度\n",
    "        if step % 100 == 0:\n",
    "            avg_loss = epoch_loss / (step + 1)\n",
    "            print(f\"Epoch {epoch + 1}/{num_train_epochs} | Step {step}/{len(train_loader)} | \"\n",
    "                  f\"Loss {loss.item():.4f} | Avg Loss {avg_loss:.4f} | \"\n",
    "                  f\"Progress {current_step}/{total_steps}\")\n",
    "    \n",
    "    # 每轮结束后打印平均损失\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"第 {epoch + 1} 轮训练完成，平均损失: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"\\n训练完成！\")\n",
    "\n",
    "# 保存微调后的模型\n",
    "print(f\"正在保存模型到: {model_save_path}\")\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# 保存训练配置信息\n",
    "import json\n",
    "config_info = {\n",
    "    \"model_id\": model_id,\n",
    "    \"lora_config\": {\n",
    "        \"r\": lora_config.r,\n",
    "        \"lora_alpha\": lora_config.lora_alpha,\n",
    "        \"target_modules\": list(lora_config.target_modules),  # 将set转换为list\n",
    "        \"lora_dropout\": lora_config.lora_dropout,\n",
    "        \"bias\": lora_config.bias,\n",
    "        \"task_type\": lora_config.task_type\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"num_epochs\": num_train_epochs,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"batch_size\": 4,\n",
    "        \"total_steps\": total_steps\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_save_path, \"training_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_info, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"模型和配置已保存到: {model_save_path}\")\n",
    "print(f\"可训练参数数量: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484e090-c227-419b-a238-a5f5e1e585e6",
   "metadata": {},
   "source": [
    "## 六、模型测试评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243242d-2ce8-453d-920f-1d8236b9bf8e",
   "metadata": {},
   "source": [
    "### 模型加载\n",
    "加载微调后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b0715e-2d47-499a-98b9-5cf691f40062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:16:47.322170Z",
     "iopub.status.busy": "2025-08-26T18:16:47.321867Z",
     "iopub.status.idle": "2025-08-26T18:16:48.928727Z",
     "shell.execute_reply": "2025-08-26T18:16:48.928224Z",
     "shell.execute_reply.started": "2025-08-26T18:16:47.322135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 02:16:48,187 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微调后的模型加载完成\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# 重新加载基础模型\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 加载 LoRA 权重\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, model_save_path)\n",
    "finetuned_model.eval()  # 设置为评估模式\n",
    "\n",
    "print(\"微调后的模型加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41deefc-fed1-4f6d-ac20-e7098efe4580",
   "metadata": {},
   "source": [
    "### 测试\n",
    "用部份未经过训练的数据集进行测试，这里采用的是交叉熵损失（CrossEntropyLoss）  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cae18c1-5a64-494c-8742-9d5d35df3bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:16:58.409012Z",
     "iopub.status.busy": "2025-08-26T18:16:58.408746Z",
     "iopub.status.idle": "2025-08-26T18:35:27.118762Z",
     "shell.execute_reply": "2025-08-26T18:35:27.118374Z",
     "shell.execute_reply.started": "2025-08-26T18:16:58.408996Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始测试微调后的模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "测试中:   0%|          | 0/125 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   1%|          | 1/125 [00:09<19:12,  9.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   2%|▏         | 2/125 [00:18<18:43,  9.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   2%|▏         | 3/125 [00:27<18:22,  9.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   3%|▎         | 4/125 [00:36<18:06,  8.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   4%|▍         | 5/125 [00:45<17:54,  8.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   5%|▍         | 6/125 [00:53<17:43,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   6%|▌         | 7/125 [01:02<17:32,  8.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   6%|▋         | 8/125 [01:11<17:24,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   7%|▋         | 9/125 [01:20<17:17,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   8%|▊         | 10/125 [01:29<17:04,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:   9%|▉         | 11/125 [01:38<17:00,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  10%|▉         | 12/125 [01:47<16:53,  8.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  10%|█         | 13/125 [01:56<16:42,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  11%|█         | 14/125 [02:05<16:32,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  12%|█▏        | 15/125 [02:14<16:22,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  13%|█▎        | 16/125 [02:23<16:12,  8.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  14%|█▎        | 17/125 [02:32<16:07,  8.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  14%|█▍        | 18/125 [02:41<15:58,  8.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  15%|█▌        | 19/125 [02:50<15:50,  8.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  16%|█▌        | 20/125 [02:59<15:44,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  17%|█▋        | 21/125 [03:08<15:36,  9.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  18%|█▊        | 22/125 [03:17<15:28,  9.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  18%|█▊        | 23/125 [03:26<15:18,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  19%|█▉        | 24/125 [03:35<15:09,  9.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  20%|██        | 25/125 [03:44<15:00,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  21%|██        | 26/125 [03:53<14:52,  9.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  22%|██▏       | 27/125 [04:02<14:42,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  22%|██▏       | 28/125 [04:11<14:33,  9.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  23%|██▎       | 29/125 [04:20<14:23,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  24%|██▍       | 30/125 [04:29<14:15,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  25%|██▍       | 31/125 [04:38<14:05,  8.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  26%|██▌       | 32/125 [04:47<13:57,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  26%|██▋       | 33/125 [04:56<13:46,  8.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  27%|██▋       | 34/125 [05:05<13:36,  8.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  28%|██▊       | 35/125 [05:14<13:25,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  29%|██▉       | 36/125 [05:23<13:15,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  30%|██▉       | 37/125 [05:31<13:03,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  30%|███       | 38/125 [05:40<12:52,  8.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  31%|███       | 39/125 [05:49<12:42,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  32%|███▏      | 40/125 [05:58<12:34,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  33%|███▎      | 41/125 [06:07<12:24,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  34%|███▎      | 42/125 [06:16<12:15,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  34%|███▍      | 43/125 [06:24<12:04,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  35%|███▌      | 44/125 [06:33<11:53,  8.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  36%|███▌      | 45/125 [06:42<11:43,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  37%|███▋      | 46/125 [06:51<11:33,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  38%|███▊      | 47/125 [07:00<11:25,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  38%|███▊      | 48/125 [07:08<11:17,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  39%|███▉      | 49/125 [07:17<11:08,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  40%|████      | 50/125 [07:26<10:59,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  41%|████      | 51/125 [07:35<10:50,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  42%|████▏     | 52/125 [07:44<10:42,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  42%|████▏     | 53/125 [07:52<10:33,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  43%|████▎     | 54/125 [08:01<10:25,  8.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  44%|████▍     | 55/125 [08:10<10:18,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  45%|████▍     | 56/125 [08:19<10:10,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  46%|████▌     | 57/125 [08:28<10:00,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  46%|████▋     | 58/125 [08:37<09:52,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  47%|████▋     | 59/125 [08:46<09:45,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  48%|████▊     | 60/125 [08:54<09:38,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  49%|████▉     | 61/125 [09:03<09:30,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  50%|████▉     | 62/125 [09:12<09:21,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  50%|█████     | 63/125 [09:21<09:12,  8.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  51%|█████     | 64/125 [09:30<09:02,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  52%|█████▏    | 65/125 [09:39<08:51,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  53%|█████▎    | 66/125 [09:48<08:41,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  54%|█████▎    | 67/125 [09:56<08:31,  8.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  54%|█████▍    | 68/125 [10:05<08:25,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  55%|█████▌    | 69/125 [10:14<08:15,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  56%|█████▌    | 70/125 [10:23<08:05,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  57%|█████▋    | 71/125 [10:32<07:59,  8.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  58%|█████▊    | 72/125 [10:41<07:51,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  58%|█████▊    | 73/125 [10:50<07:44,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  59%|█████▉    | 74/125 [10:59<07:35,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  60%|██████    | 75/125 [11:08<07:27,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  61%|██████    | 76/125 [11:17<07:18,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  62%|██████▏   | 77/125 [11:26<07:09,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  62%|██████▏   | 78/125 [11:35<06:58,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  63%|██████▎   | 79/125 [11:43<06:48,  8.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  64%|██████▍   | 80/125 [11:52<06:38,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  65%|██████▍   | 81/125 [12:01<06:28,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  66%|██████▌   | 82/125 [12:10<06:19,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  66%|██████▋   | 83/125 [12:19<06:10,  8.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  67%|██████▋   | 84/125 [12:27<06:00,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  68%|██████▊   | 85/125 [12:36<05:51,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  69%|██████▉   | 86/125 [12:45<05:42,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  70%|██████▉   | 87/125 [12:54<05:35,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  70%|███████   | 88/125 [13:03<05:28,  8.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  71%|███████   | 89/125 [13:12<05:19,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  72%|███████▏  | 90/125 [13:21<05:10,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  73%|███████▎  | 91/125 [13:29<05:00,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  74%|███████▎  | 92/125 [13:38<04:51,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  74%|███████▍  | 93/125 [13:47<04:43,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  75%|███████▌  | 94/125 [13:56<04:34,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  76%|███████▌  | 95/125 [14:05<04:25,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  77%|███████▋  | 96/125 [14:13<04:16,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  78%|███████▊  | 97/125 [14:22<04:06,  8.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  78%|███████▊  | 98/125 [14:31<03:57,  8.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  79%|███████▉  | 99/125 [14:40<03:48,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  80%|████████  | 100/125 [14:49<03:39,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  81%|████████  | 101/125 [14:57<03:30,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  82%|████████▏ | 102/125 [15:06<03:22,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  82%|████████▏ | 103/125 [15:15<03:13,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  83%|████████▎ | 104/125 [15:24<03:04,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  84%|████████▍ | 105/125 [15:32<02:55,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  85%|████████▍ | 106/125 [15:41<02:46,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  86%|████████▌ | 107/125 [15:50<02:37,  8.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  86%|████████▋ | 108/125 [15:59<02:28,  8.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  87%|████████▋ | 109/125 [16:08<02:20,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  88%|████████▊ | 110/125 [16:16<02:11,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  89%|████████▉ | 111/125 [16:25<02:03,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  90%|████████▉ | 112/125 [16:34<01:54,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  90%|█████████ | 113/125 [16:43<01:45,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  91%|█████████ | 114/125 [16:51<01:36,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  92%|█████████▏| 115/125 [17:00<01:27,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  93%|█████████▎| 116/125 [17:09<01:18,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  94%|█████████▎| 117/125 [17:18<01:10,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  94%|█████████▍| 118/125 [17:27<01:01,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  95%|█████████▌| 119/125 [17:35<00:52,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  96%|█████████▌| 120/125 [17:44<00:43,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  97%|█████████▋| 121/125 [17:53<00:35,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  98%|█████████▊| 122/125 [18:02<00:26,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  98%|█████████▊| 123/125 [18:10<00:17,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中:  99%|█████████▉| 124/125 [18:19<00:08,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "测试中: 100%|██████████| 125/125 [18:28<00:00,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集平均损失: 0.8200\n",
      "测试样本数: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "def evaluate_model(model, test_loader, tokenizer):\n",
    "    \"\"\"\n",
    "    评估模型在测试集上的表现\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"测试中\"):\n",
    "            input_ids = batch[\"input_ids\"].to(model.device)\n",
    "            labels = batch[\"labels\"].to(model.device)\n",
    "            \n",
    "            # 计算损失\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # 生成预测\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens=max_length,  # 最大生成100个新token\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            # 解码预测结果和目标\n",
    "            for i in range(len(generated_ids)):\n",
    "                # 获取输入部分（用于提取指令）\n",
    "                input_text = tokenizer.decode(input_ids[i], skip_special_tokens=True)\n",
    "                \n",
    "                # 获取生成的部分（去掉输入部分）\n",
    "                generated_text = tokenizer.decode(generated_ids[i][len(input_ids[i]):], skip_special_tokens=True)\n",
    "                \n",
    "                # 获取目标答案\n",
    "                target_text = tokenizer.decode(labels[i][labels[i] != -100], skip_special_tokens=True)\n",
    "                \n",
    "                all_predictions.append(generated_text.strip())\n",
    "                all_targets.append(target_text.strip())\n",
    "    \n",
    "    # 计算平均损失\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    return avg_loss, all_predictions, all_targets\n",
    "\n",
    "# 执行测试\n",
    "print(\"开始测试微调后的模型...\")\n",
    "test_loss, predictions, targets = evaluate_model(finetuned_model, test_loader, tokenizer)\n",
    "\n",
    "print(f\"测试集平均损失: {test_loss:.4f}\")\n",
    "print(f\"测试样本数: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce1c79-b8fb-491c-93ab-fc38c8cc87f6",
   "metadata": {},
   "source": [
    "### LLM模型其他常见指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16187a-deba-4cd8-a422-23a785d0411b",
   "metadata": {},
   "source": [
    "| 指标                   | 说明                  | 适用场景        |\n",
    "| -------------------- | ------------------- | ----------- |\n",
    "| **BLEU**             | n-gram 精确匹配         | 翻译、摘要       |\n",
    "| **ROUGE**            | 关注 recall（覆盖率）      | 摘要生成、问答     |\n",
    "| **METEOR**           | 考虑同义词匹配             | 文本生成        |\n",
    "| **BERTScore**        | 基于语义嵌入比较文本相似度       | 生成任务，语义评价   |\n",
    "| **Exact Match (EM)** | 完全匹配                | 问答、选择题、逻辑输出 |\n",
    "| **Perplexity (困惑度)** | 模型预测 token 的概率反映流畅度 | 文本生成、语言建模   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beba284-8802-4cba-b5b5-44dde5215d2f",
   "metadata": {},
   "source": [
    "### 计算BERTScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19093e-5068-458e-80fc-fa56fd371b1c",
   "metadata": {},
   "source": [
    "| 指标                | 含义               | 值域     | 越大越好？  |\n",
    "| ----------------- | ---------------- | ------ | ------ |\n",
    "| **Precision (P)** | 生成文本和目标文本语义重叠的比例 | 0 \\~ 1 | ✅ 越大越好 |\n",
    "| **Recall (R)**    | 目标文本中被生成文本覆盖的比例  | 0 \\~ 1 | ✅ 越大越好 |\n",
    "| **F1-score (F1)** | P 和 R 的调和平均      | 0 \\~ 1 | ✅ 越大越好 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2424cfee-7520-4949-88ff-f33b513603da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:36:51.340282Z",
     "iopub.status.busy": "2025-08-26T18:36:51.339993Z",
     "iopub.status.idle": "2025-08-26T18:37:13.341487Z",
     "shell.execute_reply": "2025-08-26T18:37:13.340633Z",
     "shell.execute_reply.started": "2025-08-26T18:36:51.340262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/site-packages (from bert-score) (2.3.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/site-packages (from bert-score) (2.3.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/site-packages (from bert-score) (4.55.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from bert-score) (3.10.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.8.93)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheck your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:704\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    703\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x7f3448666550>: Failed to establish a new connection: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3448666550>: Failed to establish a new connection: [Errno 101] Network is unreachable'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m429\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3448666550>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 67401b3e-0660-4c5b-a10d-0c0fd03c81d2)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1661\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1662\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1663\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1664\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is on.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1665\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhead_call_error\u001b[39;00m\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbert_score\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m score\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 假设 predictions 和 targets 已经是你的生成结果和真实答案列表\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m P, R, F1 = \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# lang 可以根据任务选择 'en' 或 'zh'\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# P, R, F1 都是 tensor，形状为 [样本数]\u001b[39;00m\n\u001b[32m      9\u001b[39m avg_precision = P.mean().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/bert_score/score.py:97\u001b[39m, in \u001b[36mscore\u001b[39m\u001b[34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_layers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     95\u001b[39m     num_layers = model2layers[model_type]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m tokenizer = \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m model = get_model(model_type, num_layers, all_layers)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/bert_score/utils.py:329\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m(model_type, use_fast)\u001b[39m\n\u001b[32m    326\u001b[39m     model_type = cache_scibert(model_type)\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version.parse(trans_version) >= version.parse(\u001b[33m\"\u001b[39m\u001b[33m4.0.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_fast, \u001b[33m\"\u001b[39m\u001b[33mFast tokenizer is not available for version < 4.0.0\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1069\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1067\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1250\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1247\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1248\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1252\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:649\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    647\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:708\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    704\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    707\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    723\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:553\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;66;03m# Here we only raise if both flags for missing entry and connection errors are True (because it can be raised\u001b[39;00m\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[39;00m\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    554\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to load the files, and couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find them in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    555\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m cached files.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCheck your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    557\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# snapshot_download will not raise EntryNotFoundError, but hf_hub_download can. If this is the case, it will be treated\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# later on anyway and re-raised if needed\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, HTTPError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
      "\u001b[31mOSError\u001b[39m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheck your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "%pip install bert-score\n",
    "\n",
    "from bert_score import score\n",
    "\n",
    "# 假设 predictions 和 targets 已经是你的生成结果和真实答案列表\n",
    "P, R, F1 = score(predictions, targets, lang=\"zh\", verbose=True)  # lang 可以根据任务选择 'en' 或 'zh'\n",
    "\n",
    "# P, R, F1 都是 tensor，形状为 [样本数]\n",
    "avg_precision = P.mean().item()\n",
    "avg_recall = R.mean().item()\n",
    "avg_f1 = F1.mean().item()\n",
    "\n",
    "print(f\"BERTScore 平均 Precision: {avg_precision:.4f}\")\n",
    "print(f\"BERTScore 平均 Recall:    {avg_recall:.4f}\")\n",
    "print(f\"BERTScore 平均 F1:        {avg_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "share": {
   "datetime": "2025-08-26T18:37:20.068Z",
   "image": {
    "name": "modelscope:1.29.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.29.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04"
   },
   "instance": "dsw-p7b6usueey5pxo2vcy",
   "spec": {
    "id": "ecs.gn7i-c8g1.2xlarge",
    "type": "GPU"
   },
   "uid": "1189516462147384"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
