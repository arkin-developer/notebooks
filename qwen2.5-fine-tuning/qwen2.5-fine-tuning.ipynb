{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e6565e-d437-46a9-b294-d024e162f573",
   "metadata": {},
   "source": [
    "# ğŸ¯ Qwen2.5ç³»åˆ—æ¨¡å‹**LoRA/QLoRA** **å¾®è°ƒæ¡ˆä¾‹**\n",
    "\n",
    "> è¯´æ˜ï¼šå…ˆç”¨ä¸€ä¸ªå…¼å®¹çš„å°æ¨¡å‹ï¼ˆä¾‹å¦‚ `Qwen/Qwen2.5-1.5B-Instruct`ï¼‰è·‘é€šæµç¨‹ï¼Œåç»­å°† `MODEL_ID` æ›¿æ¢ä¸ºä½ æ‰¾åˆ°çš„ DeepSeek æ¨¡å‹ä»“åº“åå³å¯ï¼Œä»£ç æ— éœ€æ”¹åŠ¨ã€‚\n",
    "> \n",
    "\n",
    "**ç›®æ ‡**ï¼šåœ¨å•å¡ A10ï¼ˆ24GBï¼‰ä¸Šï¼Œä»¥ *å°å‚æ•°é‡* çš„æ¨¡å‹ä¸ºä¾‹ï¼ˆæœ¬æ¡ˆä¾‹é‡‡ç”¨ModelScopeæ¥æ›¿æ¢HuggingFaceï¼‰ï¼Œç”¨ **LoRA/QLoRA** è·‘é€šä¸€æ¬¡å®Œæ•´çš„ *æŒ‡ä»¤å¾®è°ƒ*ï¼ˆInstruction Tuningï¼‰æµç¨‹ã€‚  \n",
    "**ç¡¬ä»¶å»ºè®®**ï¼šA10 24GBï¼›  \n",
    "**è½¯ä»¶å»ºè®®**ï¼šPython 3.10+ã€CUDA 12.xã€PyTorch 2.3+ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… æœ¬æ•™ç¨‹åŒ…æ‹¬\n",
    "1. LoRA/QLoRA ç®€ä»‹\n",
    "2. ç¡¬ä»¶æ£€æµ‹ä¸é…ç½®ç¯å¢ƒ\n",
    "3. æ¨¡å‹ä¸æ•°æ®é›†ä¸‹è½½  \n",
    "4. æ•°æ®é¢„å¤„ç† \n",
    "5. LoRAå¾®è°ƒ\n",
    "6. æ¨¡å‹æµ‹è¯•è¯„ä¼°\n",
    "\n",
    "> æ³¨ï¼šå…¨æµç¨‹éƒ½åœ¨ **Jupyter Lab** ä¸­é€æ ¼è¿è¡Œå³å¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cb777-2b7d-4310-9259-f30e8aad9dad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ä¸€ã€LoRA / QLoRA ç®€ä»‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe3ac9-fde6-4188-a104-6fe1ad57b723",
   "metadata": {},
   "source": [
    "### LoRAï¼ˆLow-Rank Adaptationï¼‰\n",
    "LoRA æ˜¯ä¸€ç§ **è½»é‡åŒ–æ¨¡å‹å¾®è°ƒæ–¹æ³•**ï¼Œå®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š  \n",
    "- åœ¨ä¿æŒåŸå§‹é¢„è®­ç»ƒæ¨¡å‹å‚æ•° **å†»ç»“ä¸å˜** çš„å‰æä¸‹ï¼Œåªåœ¨éƒ¨åˆ†æƒé‡çŸ©é˜µï¼ˆé€šå¸¸æ˜¯ Transformer çš„æ³¨æ„åŠ›å±‚ï¼‰ä¸Šå¼•å…¥ **ä½ç§©çŸ©é˜µåˆ†è§£**ã€‚  \n",
    "- ç”¨ä¸€ä¸ªä½ç§©çš„å‚æ•°çŸ©é˜µï¼ˆAã€Bï¼‰æ¥è¿‘ä¼¼åŸå§‹å¤§çŸ©é˜µçš„æ›´æ–°ï¼Œä»è€Œ **å¤§å¹…å‡å°‘è®­ç»ƒå‚æ•°é‡**ã€‚  \n",
    "- ä¼˜ç‚¹ï¼š  \n",
    "  - **å‚æ•°é«˜æ•ˆ**ï¼šåªéœ€è®­ç»ƒæå°‘é‡çš„æ–°å¢å‚æ•°ï¼ˆå¯ä½è‡³ 0.1%ï¼‰ã€‚  \n",
    "  - **å­˜å‚¨å‹å¥½**ï¼šå¤šä¸ªä¸‹æ¸¸ä»»åŠ¡å¯ä»¥å…±äº«åŒä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼Œä»…ä¿å­˜ä¸åŒä»»åŠ¡çš„ LoRA æƒé‡ã€‚  \n",
    "  - **éƒ¨ç½²çµæ´»**ï¼šæ¨ç†æ—¶ç›´æ¥å°† LoRA æƒé‡åˆå¹¶åˆ°åŸæ¨¡å‹ï¼Œæ— éœ€é¢å¤–è®¡ç®—å¼€é”€ã€‚\n",
    "\n",
    "> ç®€å•ç†è§£ï¼šLoRA å°±åƒæ˜¯åœ¨å¤§æ¨¡å‹çš„â€œå›ºå®šä¸»å¹²â€ä¸Šï¼Œæ’å…¥ä¸€äº› **å°è€Œèªæ˜çš„é€‚é…å™¨**ï¼Œè®©å®ƒå¿«é€Ÿå­¦ä¼šæ–°ä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec29c50-b0e1-4548-a630-f06b887a8ce1",
   "metadata": {},
   "source": [
    "### QLoRAï¼ˆQuantized LoRAï¼‰æœ¬æ–‡ä¸æ¶‰åŠ\n",
    "QLoRA æ˜¯å¯¹ LoRA çš„è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå®ƒç»“åˆäº† **é‡åŒ–æŠ€æœ¯**ï¼Œä½¿å¾—å¤§æ¨¡å‹çš„å¾®è°ƒåœ¨ **å•å¡æ¶ˆè´¹çº§æ˜¾å¡** ä¸Šä¹Ÿå¯è¡Œã€‚  \n",
    "- æ ¸å¿ƒæ€è·¯ï¼š  \n",
    "  1. å…ˆå°†å¤§æ¨¡å‹çš„å‚æ•°è¿›è¡Œ **4-bit é‡åŒ–ï¼ˆNF4 æ–¹æ¡ˆï¼‰**ï¼Œé™ä½æ˜¾å­˜å ç”¨ã€‚  \n",
    "  2. åœ¨é‡åŒ–åçš„æƒé‡ä¸Šï¼Œåº”ç”¨ **LoRA é€‚é…å™¨** è¿›è¡Œå¾®è°ƒã€‚  \n",
    "  3. è®­ç»ƒæ—¶ä»…æ›´æ–° LoRA å±‚ï¼Œè€Œé‡åŒ–æƒé‡ä¿æŒå†»ç»“ã€‚  \n",
    "\n",
    "- ä¼˜ç‚¹ï¼š  \n",
    "  - **æè‡´æ˜¾å­˜èŠ‚çœ**ï¼šå¯åœ¨ä¸€å¼  24GB æ˜¾å­˜çš„ GPU ä¸Šå¾®è°ƒç™¾äº¿å‚æ•°æ¨¡å‹ã€‚  \n",
    "  - **ä¿æŒæ€§èƒ½**ï¼šé‡åŒ–åçš„ QLoRA ä¸å…¨ç²¾åº¦å¾®è°ƒæ•ˆæœæ¥è¿‘ç”šè‡³ç›¸å½“ã€‚  \n",
    "  - **å®ç”¨æ€§å¼º**ï¼šç‰¹åˆ«é€‚åˆä¸ªäººå¼€å‘è€…å’Œä¸­å°å›¢é˜Ÿã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7f704-0602-4eee-974c-f7edbe51c71e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### å¯¹æ¯”æ€»ç»“\n",
    "| æ–¹æ³•   | ä¸»è¦æ‰‹æ®µ                   | æ˜¾å­˜æ¶ˆè€— | è®­ç»ƒå‚æ•°é‡ | é€‚ç”¨åœºæ™¯ |\n",
    "|--------|---------------------------|----------|------------|----------|\n",
    "| LoRA   | ä½ç§©çŸ©é˜µåˆ†è§£               | è¾ƒä½     | åƒä¸‡çº§åˆ«   | ä¸­ç­‰è§„æ¨¡æ¨¡å‹çš„é«˜æ•ˆå¾®è°ƒ |\n",
    "| QLoRA  | é‡åŒ–ï¼ˆ4-bitï¼‰ + LoRA é€‚é… | æä½     | åƒä¸‡çº§åˆ«   | è¶…å¤§æ¨¡å‹åœ¨æ¶ˆè´¹çº§ GPU ä¸Šçš„å¾®è°ƒ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe81e3-9470-422f-b479-7b118f1bbd03",
   "metadata": {},
   "source": [
    "## äºŒã€ç¡¬ä»¶æ£€æµ‹ä¸é…ç½®ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80687ecd-4115-4970-acd4-135208628c36",
   "metadata": {},
   "source": [
    "### ç¡¬ä»¶æ£€æµ‹ï¼ˆLinuxï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b0e2c0-e622-4ee7-bb91-b6e53130fb26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:58:52.872083Z",
     "iopub.status.busy": "2025-08-26T17:58:52.871953Z",
     "iopub.status.idle": "2025-08-26T17:58:53.999404Z",
     "shell.execute_reply": "2025-08-26T17:58:53.998998Z",
     "shell.execute_reply.started": "2025-08-26T17:58:52.872070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ“ä½œç³»ç»Ÿ: Linux\n",
      "ç³»ç»Ÿç‰ˆæœ¬: #1 SMP Mon Mar 10 11:07:41 CST 2025\n",
      "å‘è¡Œç‰ˆæœ¬: 5.10.134-18.0.2.lifsea8.x86_64\n",
      "è¯¦ç»†ä¿¡æ¯: Linux-5.10.134-18.0.2.lifsea8.x86_64-x86_64-with-glibc2.35\n",
      "Pythonç‰ˆæœ¬: 3.11.11 (main, Mar 11 2025, 18:25:39) [GCC 11.4.0]\n",
      "å¤„ç†å™¨: x86_64\n",
      "æœºå™¨ç±»å‹: x86_64\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: gputil in /usr/local/lib/python3.11/site-packages (1.4.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "æ˜¾å¡å‹å·: NVIDIA A10\n",
      "æ˜¾å­˜æ€»é‡: 23028.0 MB\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "\n",
    "print(\"æ“ä½œç³»ç»Ÿ:\", platform.system())          # Windows / Linux / Darwin (macOS)\n",
    "print(\"ç³»ç»Ÿç‰ˆæœ¬:\", platform.version())         # å†…æ ¸æˆ–ç‰ˆæœ¬å·\n",
    "print(\"å‘è¡Œç‰ˆæœ¬:\", platform.release())         # ä¾‹å¦‚ 10 / 11 / 22.6.0\n",
    "print(\"è¯¦ç»†ä¿¡æ¯:\", platform.platform())        # æ±‡æ€»\n",
    "print(\"Pythonç‰ˆæœ¬:\", sys.version)             # Python è§£é‡Šå™¨ç‰ˆæœ¬\n",
    "print(\"å¤„ç†å™¨:\", platform.processor())         # CPU ä¿¡æ¯\n",
    "print(\"æœºå™¨ç±»å‹:\", platform.machine())         # x86_64 / arm64\n",
    "\n",
    "# å®‰è£…æ£€æµ‹æ˜¾å¡çš„ä¾èµ–\n",
    "%pip install gputil\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"æ˜¾å¡å‹å·: {gpu.name}\")\n",
    "    print(f\"æ˜¾å­˜æ€»é‡: {gpu.memoryTotal} MB\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c85d87-cf4c-4461-a35f-ae0ed02b6c11",
   "metadata": {},
   "source": [
    "### é…ç½®ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e562bedc-2f0d-4ee4-9fec-61263667dce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:58:54.000438Z",
     "iopub.status.busy": "2025-08-26T17:58:54.000246Z",
     "iopub.status.idle": "2025-08-26T17:58:59.940007Z",
     "shell.execute_reply": "2025-08-26T17:58:59.939448Z",
     "shell.execute_reply.started": "2025-08-26T17:58:54.000422Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.3.1+cu121 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.3.1+cu121\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers==4.55.4 in /usr/local/lib/python3.11/site-packages (4.55.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers==4.55.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers==4.55.4) (2025.1.31)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: modelscope==1.29.0 in /usr/local/lib/python3.11/site-packages (1.29.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (3.17.0)\n",
      "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (65.5.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/site-packages (from modelscope==1.29.0) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.29.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.29.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.29.0) (2025.1.31)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: peft==0.17.1 in /usr/local/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (2.3.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (4.55.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (1.10.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/site-packages (from peft==0.17.1) (0.34.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2024.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (1.1.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.17.1) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.17.1) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.17.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.17.1) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers->peft==0.17.1) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers->peft==0.17.1) (0.21.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: datasets==3.2.0 in /usr/local/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (3.12.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from datasets==3.2.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.2.0) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->datasets==3.2.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==3.2.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==3.2.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: accelerate==1.10.0 in /usr/local/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (2.3.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from accelerate==1.10.0) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (2024.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.10.0) (1.1.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.10.0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate==1.10.0) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate==1.10.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.10.0) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate==1.10.0) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.3.1+cu121\n",
    "%pip install transformers==4.55.4\n",
    "%pip install modelscope==1.29.0\n",
    "%pip install peft==0.17.1\n",
    "%pip install datasets==3.2.0\n",
    "%pip install accelerate==1.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae0ef2-b29b-47c0-b000-2377b64d2c4e",
   "metadata": {},
   "source": [
    "### æ£€æŸ¥ç¯å¢ƒç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6cad49f-9ba7-4f2a-b5b3-51f63735617e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:58:59.940781Z",
     "iopub.status.busy": "2025-08-26T17:58:59.940629Z",
     "iopub.status.idle": "2025-08-26T17:59:10.587187Z",
     "shell.execute_reply": "2025-08-26T17:59:10.586775Z",
     "shell.execute_reply.started": "2025-08-26T17:58:59.940766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:07.036101: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-27 01:59:07.623431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-27 01:59:08.838843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.3.1+cu121\n",
      "transformers: 4.55.4\n",
      "modelscope: 1.29.0\n",
      "peft: 0.17.1\n",
      "datasets: 3.2.0\n",
      "accelerate: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ æ‰“å°è„šæœ¬ç›¸å…³åº“çš„ç‰ˆæœ¬ä¿¡æ¯\n",
    "import torch, transformers, modelscope, peft\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "\n",
    "# transformers æ˜¯ peft å’Œ modelscope ä¾èµ–çš„æ ¸å¿ƒåº“\n",
    "try:\n",
    "    import transformers\n",
    "    print(\"transformers:\", transformers.__version__)\n",
    "except ImportError:\n",
    "    print(\"transformers: æœªå®‰è£…\")\n",
    "\n",
    "try:\n",
    "    import modelscope\n",
    "    print(\"modelscope:\", modelscope.__version__)\n",
    "except ImportError:\n",
    "    print(\"modelscope: æœªå®‰è£…\")\n",
    "\n",
    "try:\n",
    "    import peft\n",
    "    print(\"peft:\", peft.__version__)\n",
    "except ImportError:\n",
    "    print(\"peft: æœªå®‰è£…\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(\"datasets:\", datasets.__version__)\n",
    "except ImportError:\n",
    "    print(\"datasets: æœªå®‰è£…\")\n",
    "\n",
    "try:\n",
    "    import accelerate\n",
    "    print(\"accelerate:\", accelerate.__version__)\n",
    "except ImportError:\n",
    "    print(\"accelerate: æœªå®‰è£…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97315bf-cb93-4ceb-8bd6-6da5da3748af",
   "metadata": {},
   "source": [
    "## ä¸‰ã€æ¨¡å‹ä¸æ•°æ®é›†ä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfaeffd-b73a-491e-8273-a8db6a069535",
   "metadata": {},
   "source": [
    "### Qwen2.5-1.5Bæ¨¡å‹ä¸‹è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e89730e-3b76-47ed-9c85-06672b867adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:59:10.587927Z",
     "iopub.status.busy": "2025-08-26T17:59:10.587649Z",
     "iopub.status.idle": "2025-08-26T17:59:28.787989Z",
     "shell.execute_reply": "2025-08-26T17:59:28.787573Z",
     "shell.execute_reply.started": "2025-08-26T17:59:10.587912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:11,412 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:12,225 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"qwen/Qwen2.5-1.5B-Instruct\"  # å¯æ›¿æ¢\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d92ea8-11cc-49a8-8df6-9cb7bf3df8e5",
   "metadata": {},
   "source": [
    "### alpacaæ•°æ®é›†ä¸‹è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea33c99f-f5fa-4115-b4dc-e3000b5f2f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T17:59:28.788685Z",
     "iopub.status.busy": "2025-08-26T17:59:28.788491Z",
     "iopub.status.idle": "2025-08-26T17:59:38.759889Z",
     "shell.execute_reply": "2025-08-26T17:59:38.759492Z",
     "shell.execute_reply.started": "2025-08-26T17:59:28.788672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 01:59:29,044 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n",
      "2025-08-27 01:59:29,714 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from AI-ModelScope/alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n",
      "2025-08-27 01:59:29,714 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from AI-ModelScope/alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n",
      "2025-08-27 01:59:29,714 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from AI-ModelScope/alpaca-gpt4-data-zh. Please make sure that you can trust the external codes.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "\n",
    "ds =  MsDataset.load('AI-ModelScope/alpaca-gpt4-data-zh', subset_name='default', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef368533-dbe1-42ed-a8c2-2f07509923d8",
   "metadata": {},
   "source": [
    "## å››ã€æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb9f6d-22ef-404d-8649-2910e5e9911b",
   "metadata": {},
   "source": [
    "### è®¡ç®—max_length\n",
    "æ ¹æ®æ•°æ®é›†çš„tokené•¿åº¦æ¥è®¡ç®—æœ€åˆé€‚çš„é•¿åº¦ï¼Œæœ‰åˆ©äºæ•°æ®é¢„å¤„ç†çš„é€Ÿåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4135b13f-365d-4a47-9f6d-67b06e651009",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-08-26T18:00:46.565661Z",
     "iopub.status.busy": "2025-08-26T18:00:46.565357Z",
     "iopub.status.idle": "2025-08-26T18:00:49.381990Z",
     "shell.execute_reply": "2025-08-26T18:00:49.381539Z",
     "shell.execute_reply.started": "2025-08-26T18:00:46.565638Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.67.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "å¼€å§‹ç»Ÿè®¡ï¼ŒæŠ½æ · 5000 æ¡æ•°æ® ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:01<00:00, 2857.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Token é•¿åº¦ç»Ÿè®¡ç»“æœ ===\n",
      "æœ€å¤§é•¿åº¦: 532\n",
      "å¹³å‡é•¿åº¦: 143.24\n",
      "95% åˆ†ä½æ•°é•¿åº¦: 293\n",
      "=========================\n",
      "ğŸ‘‰ æ¨è max_length = 293\n",
      "(æ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦ = 131072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def recommend_max_length(dataset, tokenizer, sample_size=5000, quantile=95):\n",
    "    \"\"\"\n",
    "    è‡ªåŠ¨ç»Ÿè®¡ token é•¿åº¦åˆ†å¸ƒï¼Œå¹¶æ¨è max_length\n",
    "    Args:\n",
    "        dataset: MsDataset å¯¹è±¡\n",
    "        tokenizer: HF AutoTokenizer\n",
    "        sample_size: æŠ½æ ·æ•°é‡ï¼ˆé¿å…å…¨é‡å¤ªæ…¢ï¼‰\n",
    "        quantile: åˆ†ä½æ•°ï¼ˆé»˜è®¤95ï¼‰\n",
    "    \"\"\"\n",
    "    total = min(sample_size, len(dataset))\n",
    "    lengths = []\n",
    "\n",
    "    print(f\"å¼€å§‹ç»Ÿè®¡ï¼ŒæŠ½æ · {total} æ¡æ•°æ® ...\")\n",
    "\n",
    "    for i in tqdm(range(total)):\n",
    "        ex = dataset[i]\n",
    "        instruction = ex.get(\"instruction\", \"\")\n",
    "        input_text = ex.get(\"input\", \"\") or \"\"\n",
    "        output_text = ex.get(\"output\", \"\")\n",
    "\n",
    "        if input_text.strip():\n",
    "            prompt = f\"æŒ‡ä»¤: {instruction}\\nè¾“å…¥: {input_text}\\nå›ç­”:\"\n",
    "        else:\n",
    "            prompt = f\"æŒ‡ä»¤: {instruction}\\nå›ç­”:\"\n",
    "\n",
    "        full_text = prompt + output_text\n",
    "        tokenized = tokenizer(full_text, truncation=False)\n",
    "        lengths.append(len(tokenized[\"input_ids\"]))\n",
    "\n",
    "    max_len = max(lengths)\n",
    "    avg_len = np.mean(lengths)\n",
    "    q_len = np.percentile(lengths, quantile)\n",
    "\n",
    "    print(\"\\n=== Token é•¿åº¦ç»Ÿè®¡ç»“æœ ===\")\n",
    "    print(f\"æœ€å¤§é•¿åº¦: {max_len}\")\n",
    "    print(f\"å¹³å‡é•¿åº¦: {avg_len:.2f}\")\n",
    "    print(f\"{quantile}% åˆ†ä½æ•°é•¿åº¦: {q_len:.0f}\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"ğŸ‘‰ æ¨è max_length = {int(min(q_len, tokenizer.model_max_length))}\")\n",
    "    print(f\"(æ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦ = {tokenizer.model_max_length})\")\n",
    "\n",
    "    return int(min(q_len, tokenizer.model_max_length))\n",
    "\n",
    "\n",
    "# è®¡ç®—æ•°æ®é›†åº”è¯¥å®šä¹‰çš„æœ€å¤§é•¿åº¦\n",
    "max_length = recommend_max_length(ds, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53410742-ec2d-4383-ad76-43cb6b997ca4",
   "metadata": {},
   "source": [
    "### é¢„å¤„ç†ï¼ˆæ„é€ Datasetï¼‰\n",
    "éœ€è¦é’ˆå¯¹è‡ªå·±çš„æ•°æ®é›†èŒƒå¼æ¥ç¼–å†™ï¼Œè¿™é‡Œåªé’ˆå¯¹alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f40f313-12aa-4dab-a9aa-7a2197706475",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-08-26T18:01:50.344842Z",
     "iopub.status.busy": "2025-08-26T18:01:50.344550Z",
     "iopub.status.idle": "2025-08-26T18:01:50.411198Z",
     "shell.execute_reply": "2025-08-26T18:01:50.410786Z",
     "shell.execute_reply.started": "2025-08-26T18:01:50.344826Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å¤„ç†å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# è‡ªå®šä¹‰æ•°æ®å¤„ç†å‡½æ•°(éœ€è¦é’ˆå¯¹è‡ªå·±çš„æ•°æ®é›†èŒƒå¼æ¥ç¼–å†™ï¼Œè¿™é‡Œåªé’ˆå¯¹alpaca)\n",
    "def preprocess(example):\n",
    "    # ä¸¢æ‰ instruction æˆ– output ç¼ºå¤±çš„æ ·æœ¬\n",
    "    if not example['instruction'] or not example['output']:\n",
    "        return None\n",
    "\n",
    "    # alpaca æ•°æ®æœ‰æŒ‡ä»¤ã€è¾“å…¥ã€è¾“å‡ºä¸‰ä¸ªæ ‡ç­¾\n",
    "    instruction = example['instruction']\n",
    "    input_text = example.get('input') or \"\"  # input å¯èƒ½ä¸º None\n",
    "    output_text = example['output']\n",
    "\n",
    "    if input_text.strip():\n",
    "        prompt = f\"æŒ‡ä»¤: {instruction}\\nè¾“å…¥: {input_text}\\nå›ç­”:\"\n",
    "    else:\n",
    "        prompt = f\"æŒ‡ä»¤: {instruction}\\nå›ç­”:\"\n",
    "\n",
    "    full_text = prompt + output_text\n",
    "\n",
    "    enc = tokenizer(\n",
    "        full_text,  # éœ€è¦è¿›è¡ŒtokenåŒ–çš„æ–‡æœ¬\n",
    "        truncation=True,  # æ–‡æœ¬è¿‡å¤§çš„æ—¶å€™æ˜¯å¦æˆªæ–­\n",
    "        max_length=max_length,  # æ ¹æ®æ¨¡å‹å’Œæ•°æ®é›†å†³å®šæœ€åˆé€‚çš„\n",
    "        padding=\"max_length\",  # ğŸ”¹ ä¿è¯é•¿åº¦ä¸€è‡´ï¼ŒDataLoader å †å å®‰å…¨\n",
    "        return_tensors=\"pt\"  # è¿”å›çš„æ•°æ®ç±»å‹ï¼Œpt:pytorch.tensor; tf:tensorflow; np:numpy\n",
    "    )\n",
    "    # å•ä¸ªæ ·æœ¬æ˜¯å­—å…¸æ ¼å¼\n",
    "    return {\n",
    "        \"input_ids\": enc[\"input_ids\"][0],\n",
    "        \"labels\": enc[\"input_ids\"][0]\n",
    "    }\n",
    "\n",
    "train_dataset = ds.map(preprocess)\n",
    "train_dataset = train_dataset.filter(lambda x: x is not None)\n",
    "\n",
    "print('æ•°æ®å¤„ç†å®Œæˆ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d17b5-dcff-4b59-949c-3bdccc212392",
   "metadata": {},
   "source": [
    "### æ„é€ DataLoader\n",
    "å°†é¢„å¤„ç†å¥½çš„Datasetè¿›è¡ŒPaddingåæ–¹ä¾¿æ‹¼æ¥æˆå¤šä¸ªbatchçš„å‘é‡ï¼Œä¸ºè®­ç»ƒä½œå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee1615a-3038-4ffc-9eb7-7f42a0188d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:00.301646Z",
     "iopub.status.busy": "2025-08-26T18:02:00.301241Z",
     "iopub.status.idle": "2025-08-26T18:02:00.323938Z",
     "shell.execute_reply": "2025-08-26T18:02:00.323577Z",
     "shell.execute_reply.started": "2025-08-26T18:02:00.301631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ€»æ ·æœ¬æ•°: 48818\n",
      "è®­ç»ƒé›†æ ·æœ¬æ•°: 39054\n",
      "æµ‹è¯•é›†æ ·æœ¬æ•°: 9764\n",
      "å°è®­ç»ƒé›†æ ·æœ¬æ•°: 2000\n",
      "å°æµ‹è¯•é›†æ ·æœ¬æ•°: 500\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# ğŸ› ï¸ è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•° (collate_fn)\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    ä½œç”¨ï¼š\n",
    "    - DataLoader ä¼šæŠŠä¸€ä¸ª batch çš„æ ·æœ¬ï¼ˆlist[dict]ï¼‰ä¼ è¿›æ¥\n",
    "    - è¿™é‡Œéœ€è¦æ‰‹åŠ¨æ‹¼æ¥æˆ tensorï¼Œå¹¶ä¸”å¯¹é½é•¿åº¦ï¼ˆpadï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    # å–å‡ºæ¯ä¸ªæ ·æœ¬çš„ input_ids å’Œ labelsï¼Œè½¬æˆ tensor\n",
    "    input_ids = [torch.tensor(item[\"input_ids\"]) for item in batch]\n",
    "    labels = [torch.tensor(item[\"labels\"]) for item in batch]\n",
    "\n",
    "    # ğŸ”¹ å¯¹ input_ids åš padding\n",
    "    #   - batch_first=True: ç»“æœå½¢çŠ¶ (batch_size, seq_len)\n",
    "    #   - padding_value=tokenizer.pad_token_id: ä½¿ç”¨ tokenizer çš„ pad_token_id å¡«å……\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # ğŸ”¹ å¯¹ labels åš padding\n",
    "    #   - æ³¨æ„è¿™é‡Œ padding_value = -100\n",
    "    #   - åœ¨ PyTorch çš„ CrossEntropyLoss é‡Œï¼Œ-100 ä¼šè¢«å¿½ç•¥ï¼Œä¸å‚ä¸ loss è®¡ç®—\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(\n",
    "        labels, batch_first=True, padding_value=-100\n",
    "    )\n",
    "\n",
    "    # è¿”å›å­—å…¸ï¼Œæ–¹ä¾¿ç›´æ¥å–‚ç»™æ¨¡å‹\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "\n",
    "# åœ¨æ•°æ®é¢„å¤„ç†åï¼Œåˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# è·å–æ•°æ®é›†çš„æ€»é•¿åº¦\n",
    "total_samples = len(train_dataset)\n",
    "print(f\"æ€»æ ·æœ¬æ•°: {total_samples}\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§\n",
    "np.random.seed(42)\n",
    "\n",
    "# åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›† (80% è®­ç»ƒ, 20% æµ‹è¯•)\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(total_samples), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "test_subset = Subset(train_dataset, test_indices)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_subset)}\")\n",
    "print(f\"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_subset)}\")\n",
    "\n",
    "# ä¸ºäº†å¿«é€ŸéªŒè¯ï¼Œå¯ä»¥åªå–éƒ¨åˆ†æ•°æ®\n",
    "small_train_dataset = Subset(train_subset, range(min(2000, len(train_subset))))\n",
    "small_test_dataset = Subset(test_subset, range(min(500, len(test_subset))))\n",
    "\n",
    "print(f\"å°è®­ç»ƒé›†æ ·æœ¬æ•°: {len(small_train_dataset)}\")\n",
    "print(f\"å°æµ‹è¯•é›†æ ·æœ¬æ•°: {len(small_test_dataset)}\")\n",
    "\n",
    "# æ„å»ºè®­ç»ƒå’Œæµ‹è¯•çš„ DataLoader\n",
    "train_loader = DataLoader(\n",
    "    small_train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    small_test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,  # æµ‹è¯•æ—¶ä¸éœ€è¦æ‰“ä¹±\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3096f-ff18-4add-b275-678d51aea408",
   "metadata": {},
   "source": [
    "## äº”ã€LoRAå¾®è°ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fe51a-3b1d-44d2-aba4-a1bd46903665",
   "metadata": {},
   "source": [
    "### LoRAå‚æ•°è¯´æ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7645b00-73b5-46f9-83fe-ad0145c55b83",
   "metadata": {},
   "source": [
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=4,                          \n",
    "    lora_alpha=16,               \n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  \n",
    "    lora_dropout=0.05,             \n",
    "    bias=\"none\",               \n",
    "    task_type=\"CAUSAL_LM\"         \n",
    ")\n",
    "```\n",
    "\n",
    "r=4\n",
    "- è¡¨ç¤ºä½ç§©çŸ©é˜µçš„ç§©å€¼ï¼ˆrankï¼‰ï¼Œå€¼è¶Šå¤§ â†’ é€‚é…èƒ½åŠ›æ›´å¼º â†’ å‚æ•°é‡ä¹Ÿéšä¹‹å¢åŠ ã€‚  \n",
    "- è¿™é‡Œé€‰æ‹© `4`ï¼Œæ„å‘³ç€ **è½»é‡çº§è®­ç»ƒ**ï¼Œé€‚åˆå°è§„æ¨¡ä»»åŠ¡æˆ–å¿«é€Ÿå®éªŒã€‚  \n",
    "\n",
    "lora_alpha=16\n",
    "- ç¼©æ”¾å› å­ï¼Œç”¨äºè°ƒæ•´ LoRA çš„è¾“å‡ºå¹…åº¦ã€‚  \n",
    "- ä¸€èˆ¬ç»éªŒæ˜¯ **lora_alpha â‰ˆ 2 Ã— r**ï¼Œæ‰€ä»¥è¿™é‡Œ `16` é…åˆ `r=4` æ˜¯åˆç†çš„ã€‚  \n",
    "\n",
    "target_modules=[\"q_proj\", \"v_proj\"]\n",
    "- LoRA åªåœ¨æ³¨æ„åŠ›æœºåˆ¶çš„ **Query** å’Œ **Value** æŠ•å½±å±‚ä¸­ç”Ÿæ•ˆã€‚  \n",
    "- è¿™æ˜¯æœ€å¸¸è§çš„è®¾ç½®ï¼Œæ—¢ä¿è¯æ•ˆæœï¼Œåˆæ§åˆ¶å‚æ•°é‡ã€‚\n",
    "- [\"q_proj\", \"v_proj\"] â†’ é»˜è®¤æ¨èï¼Œ90% çš„åœºæ™¯é€‚ç”¨ï¼ˆå¯¹è¯ã€é—®ç­”ã€æŒ‡ä»¤è·Ÿéšï¼‰ã€‚\n",
    "- [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] â†’ å…¨é‡ Attentionï¼Œå‚æ•°é‡å¤§ä¸€äº›ï¼Œé€‚åˆä»»åŠ¡æ›´å¤æ‚ï¼ˆå¦‚å¤šæ¨¡æ€å¯¹é½ï¼‰ã€‚\n",
    "- [\"gate_proj\", \"up_proj\", \"down_proj\"] â†’ æ”¹ MLP å±‚ï¼Œé€‚åˆéœ€è¦è°ƒæ•´â€œçŸ¥è¯†è¡¨è¾¾â€çš„åœºæ™¯ï¼ˆä¾‹å¦‚æ•°å­¦æ¨ç†ï¼‰ã€‚\n",
    "- [\"q_proj\", \"v_proj\", \"down_proj\"] â†’ æ··åˆæ–¹å¼ï¼Œæœ‰æ—¶èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚\n",
    "\n",
    "lora_dropout=0.05\n",
    "- åœ¨ LoRA å±‚ä¸­æ·»åŠ  **5% çš„ dropout**ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚  \n",
    "- æ•°æ®é‡å¾ˆå¤§æ—¶å¯ä»¥è°ƒä½åˆ° `0`ï¼›æ•°æ®å°‘æ—¶å¯ä»¥é€‚å½“è°ƒé«˜ï¼ˆå¦‚ `0.1`ï¼‰ã€‚  \n",
    "\n",
    "bias=\"none\"\n",
    "- ä¸è®­ç»ƒ bias å‚æ•°ï¼Œä¿è¯æ¨¡å‹è½»é‡åŒ–ã€‚  \n",
    "- å¤§å¤šæ•°åœºæ™¯ä¸‹ç”¨ `\"none\"` å³å¯ã€‚  \n",
    "\n",
    "task_type=\"CAUSAL_LM\"\n",
    "- è¡¨ç¤ºä»»åŠ¡æ˜¯ **è‡ªå›å½’è¯­è¨€å»ºæ¨¡**ï¼ˆæ¯”å¦‚ Qwenã€GPT ç±»æ¨¡å‹ï¼‰ã€‚  \n",
    "- å¿…é¡»å’Œä»»åŠ¡ç±»å‹ä¸€è‡´ï¼Œå¦åˆ™ forward è¿‡ç¨‹ä¼šæŠ¥é”™ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25a924-a0ca-4779-9006-59be35ecb388",
   "metadata": {},
   "source": [
    "### é…ç½® LoRA è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f547e8-9520-40aa-a9dd-3aeef97f305f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:14.210337Z",
     "iopub.status.busy": "2025-08-26T18:02:14.210066Z",
     "iopub.status.idle": "2025-08-26T18:02:15.611953Z",
     "shell.execute_reply": "2025-08-26T18:02:15.611408Z",
     "shell.execute_reply.started": "2025-08-26T18:02:14.210321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 544,768 || all params: 1,544,259,072 || trainable%: 0.0353\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4,            \n",
    "    lora_alpha=16,                \n",
    "    target_modules=[\"q_proj\", \"v_proj\"], \n",
    "    lora_dropout=0.05,             \n",
    "    bias=\"none\",                    \n",
    "    task_type=\"CAUSAL_LM\"           \n",
    ")\n",
    "\n",
    "# ğŸš€ å°†åŸºç¡€æ¨¡å‹åŒ…è£…ä¸º PEFT æ¨¡å‹\n",
    "model = get_peft_model(model, lora_config)  # è¿™é‡Œé»˜è®¤ä¼šå†»ç»“éLoRAçš„å‚æ•°\n",
    "\n",
    "# æ‰“å°å½“å‰å¯è®­ç»ƒå‚æ•°é‡ï¼ˆä»… LoRA éƒ¨åˆ†ï¼‰ï¼Œå…¶ä½™å‚æ•°è¢«å†»ç»“\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# è®­ç»ƒè¶…å‚æ•°\n",
    "num_train_epochs = 2  # å¯¹å®Œæ•´çš„æ•°æ®é›†è®­ç»ƒå¤šå°‘ä¸ªæ‰¹æ¬¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6e3f0-b17b-4001-9884-b41af16157b2",
   "metadata": {},
   "source": [
    "### ç¡®è®¤å‚æ•°æ˜¯å¦å†»ç»“\n",
    "è¿™é‡Œåªéœ€è¦è®­ç»ƒLoRAæ–°å¢çš„å‚æ•°å±‚\n",
    "è¾“å‡ºåº”è¯¥åªåŒ…å« lora_Aã€lora_B ä¹‹ç±»çš„å¢é‡å‚æ•°å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08575633-4676-4e2d-94dd-aba87aff7062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:22.341597Z",
     "iopub.status.busy": "2025-08-26T18:02:22.341021Z",
     "iopub.status.idle": "2025-08-26T18:02:22.346958Z",
     "shell.execute_reply": "2025-08-26T18:02:22.346462Z",
     "shell.execute_reply.started": "2025-08-26T18:02:22.341577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:  # è¿™é‡Œåªæ‰“å°æœ‰æ¢¯åº¦ä¿¡æ¯çš„\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb750b2e-e557-4946-90d3-254efded1b21",
   "metadata": {},
   "source": [
    "### å¼€å§‹å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07bd5b04-8876-4438-b711-db19c396adfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:02:30.384307Z",
     "iopub.status.busy": "2025-08-26T18:02:30.383865Z",
     "iopub.status.idle": "2025-08-26T18:15:36.563907Z",
     "shell.execute_reply": "2025-08-26T18:15:36.563472Z",
     "shell.execute_reply.started": "2025-08-26T18:02:30.384287Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "å¼€å§‹ç¬¬ 1/2 è½®è®­ç»ƒ...\n",
      "Epoch 1/2 | Step 0/500 | Loss 4.3384 | Avg Loss 4.3384 | Progress 1/1000\n",
      "Epoch 1/2 | Step 100/500 | Loss 1.0286 | Avg Loss 1.2016 | Progress 101/1000\n",
      "Epoch 1/2 | Step 200/500 | Loss 0.7692 | Avg Loss 1.0262 | Progress 201/1000\n",
      "Epoch 1/2 | Step 300/500 | Loss 0.3082 | Avg Loss 0.9605 | Progress 301/1000\n",
      "Epoch 1/2 | Step 400/500 | Loss 0.4948 | Avg Loss 0.9209 | Progress 401/1000\n",
      "ç¬¬ 1 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.8999\n",
      "\n",
      "å¼€å§‹ç¬¬ 2/2 è½®è®­ç»ƒ...\n",
      "Epoch 2/2 | Step 0/500 | Loss 0.6446 | Avg Loss 0.6446 | Progress 501/1000\n",
      "Epoch 2/2 | Step 100/500 | Loss 0.4342 | Avg Loss 0.7611 | Progress 601/1000\n",
      "Epoch 2/2 | Step 200/500 | Loss 0.9296 | Avg Loss 0.7682 | Progress 701/1000\n",
      "Epoch 2/2 | Step 300/500 | Loss 1.0355 | Avg Loss 0.7783 | Progress 801/1000\n",
      "Epoch 2/2 | Step 400/500 | Loss 0.5083 | Avg Loss 0.7844 | Progress 901/1000\n",
      "ç¬¬ 2 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.7941\n",
      "\n",
      "è®­ç»ƒå®Œæˆï¼\n",
      "æ­£åœ¨ä¿å­˜æ¨¡å‹åˆ°: ./qwen2.5-finetuned-lora\n",
      "æ¨¡å‹å’Œé…ç½®å·²ä¿å­˜åˆ°: ./qwen2.5-finetuned-lora\n",
      "å¯è®­ç»ƒå‚æ•°æ•°é‡: 544,768\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import os\n",
    "\n",
    "# åˆ›å»ºä¿å­˜ç›®å½•\n",
    "model_save_path = \"./qwen2.5-finetuned-lora\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# ä¼˜åŒ–å™¨è®¾ç½®\n",
    "optimizer = AdamW(model.parameters(), lr=2e-4)\n",
    "\n",
    "# è®­ç»ƒå¾ªç¯\n",
    "model.train()\n",
    "total_steps = len(train_loader) * num_train_epochs\n",
    "current_step = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    print(f\"\\nå¼€å§‹ç¬¬ {epoch + 1}/{num_train_epochs} è½®è®­ç»ƒ...\")\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(model.device)\n",
    "        labels = batch[\"labels\"].to(model.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        current_step += 1\n",
    "\n",
    "        # æ¯ 100 ä¸ª step æ‰“å°ä¸€æ¬¡è¿›åº¦\n",
    "        if step % 100 == 0:\n",
    "            avg_loss = epoch_loss / (step + 1)\n",
    "            print(f\"Epoch {epoch + 1}/{num_train_epochs} | Step {step}/{len(train_loader)} | \"\n",
    "                  f\"Loss {loss.item():.4f} | Avg Loss {avg_loss:.4f} | \"\n",
    "                  f\"Progress {current_step}/{total_steps}\")\n",
    "    \n",
    "    # æ¯è½®ç»“æŸåæ‰“å°å¹³å‡æŸå¤±\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"ç¬¬ {epoch + 1} è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"\\nè®­ç»ƒå®Œæˆï¼\")\n",
    "\n",
    "# ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹\n",
    "print(f\"æ­£åœ¨ä¿å­˜æ¨¡å‹åˆ°: {model_save_path}\")\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# ä¿å­˜è®­ç»ƒé…ç½®ä¿¡æ¯\n",
    "import json\n",
    "config_info = {\n",
    "    \"model_id\": model_id,\n",
    "    \"lora_config\": {\n",
    "        \"r\": lora_config.r,\n",
    "        \"lora_alpha\": lora_config.lora_alpha,\n",
    "        \"target_modules\": list(lora_config.target_modules),  # å°†setè½¬æ¢ä¸ºlist\n",
    "        \"lora_dropout\": lora_config.lora_dropout,\n",
    "        \"bias\": lora_config.bias,\n",
    "        \"task_type\": lora_config.task_type\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"num_epochs\": num_train_epochs,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"batch_size\": 4,\n",
    "        \"total_steps\": total_steps\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_save_path, \"training_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_info, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"æ¨¡å‹å’Œé…ç½®å·²ä¿å­˜åˆ°: {model_save_path}\")\n",
    "print(f\"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484e090-c227-419b-a238-a5f5e1e585e6",
   "metadata": {},
   "source": [
    "## å…­ã€æ¨¡å‹æµ‹è¯•è¯„ä¼°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243242d-2ce8-453d-920f-1d8236b9bf8e",
   "metadata": {},
   "source": [
    "### æ¨¡å‹åŠ è½½\n",
    "åŠ è½½å¾®è°ƒåçš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b0715e-2d47-499a-98b9-5cf691f40062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:16:47.322170Z",
     "iopub.status.busy": "2025-08-26T18:16:47.321867Z",
     "iopub.status.idle": "2025-08-26T18:16:48.928727Z",
     "shell.execute_reply": "2025-08-26T18:16:48.928224Z",
     "shell.execute_reply.started": "2025-08-26T18:16:47.322135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 02:16:48,187 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¾®è°ƒåçš„æ¨¡å‹åŠ è½½å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# é‡æ–°åŠ è½½åŸºç¡€æ¨¡å‹\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# åŠ è½½ LoRA æƒé‡\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, model_save_path)\n",
    "finetuned_model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "\n",
    "print(\"å¾®è°ƒåçš„æ¨¡å‹åŠ è½½å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41deefc-fed1-4f6d-ac20-e7098efe4580",
   "metadata": {},
   "source": [
    "### æµ‹è¯•\n",
    "ç”¨éƒ¨ä»½æœªç»è¿‡è®­ç»ƒçš„æ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼Œè¿™é‡Œé‡‡ç”¨çš„æ˜¯äº¤å‰ç†µæŸå¤±ï¼ˆCrossEntropyLossï¼‰  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cae18c1-5a64-494c-8742-9d5d35df3bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:16:58.409012Z",
     "iopub.status.busy": "2025-08-26T18:16:58.408746Z",
     "iopub.status.idle": "2025-08-26T18:35:27.118762Z",
     "shell.execute_reply": "2025-08-26T18:35:27.118374Z",
     "shell.execute_reply.started": "2025-08-26T18:16:58.408996Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•ä¸­:   0%|          | 0/125 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   1%|          | 1/125 [00:09<19:12,  9.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   2%|â–         | 2/125 [00:18<18:43,  9.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   2%|â–         | 3/125 [00:27<18:22,  9.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   3%|â–         | 4/125 [00:36<18:06,  8.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   4%|â–         | 5/125 [00:45<17:54,  8.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   5%|â–         | 6/125 [00:53<17:43,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   6%|â–Œ         | 7/125 [01:02<17:32,  8.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   6%|â–‹         | 8/125 [01:11<17:24,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   7%|â–‹         | 9/125 [01:20<17:17,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   8%|â–Š         | 10/125 [01:29<17:04,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:   9%|â–‰         | 11/125 [01:38<17:00,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  10%|â–‰         | 12/125 [01:47<16:53,  8.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  10%|â–ˆ         | 13/125 [01:56<16:42,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  11%|â–ˆ         | 14/125 [02:05<16:32,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  12%|â–ˆâ–        | 15/125 [02:14<16:22,  8.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  13%|â–ˆâ–        | 16/125 [02:23<16:12,  8.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  14%|â–ˆâ–        | 17/125 [02:32<16:07,  8.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  14%|â–ˆâ–        | 18/125 [02:41<15:58,  8.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  15%|â–ˆâ–Œ        | 19/125 [02:50<15:50,  8.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  16%|â–ˆâ–Œ        | 20/125 [02:59<15:44,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  17%|â–ˆâ–‹        | 21/125 [03:08<15:36,  9.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  18%|â–ˆâ–Š        | 22/125 [03:17<15:28,  9.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  18%|â–ˆâ–Š        | 23/125 [03:26<15:18,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  19%|â–ˆâ–‰        | 24/125 [03:35<15:09,  9.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  20%|â–ˆâ–ˆ        | 25/125 [03:44<15:00,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  21%|â–ˆâ–ˆ        | 26/125 [03:53<14:52,  9.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  22%|â–ˆâ–ˆâ–       | 27/125 [04:02<14:42,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  22%|â–ˆâ–ˆâ–       | 28/125 [04:11<14:33,  9.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  23%|â–ˆâ–ˆâ–       | 29/125 [04:20<14:23,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  24%|â–ˆâ–ˆâ–       | 30/125 [04:29<14:15,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  25%|â–ˆâ–ˆâ–       | 31/125 [04:38<14:05,  8.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  26%|â–ˆâ–ˆâ–Œ       | 32/125 [04:47<13:57,  9.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  26%|â–ˆâ–ˆâ–‹       | 33/125 [04:56<13:46,  8.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  27%|â–ˆâ–ˆâ–‹       | 34/125 [05:05<13:36,  8.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  28%|â–ˆâ–ˆâ–Š       | 35/125 [05:14<13:25,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  29%|â–ˆâ–ˆâ–‰       | 36/125 [05:23<13:15,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  30%|â–ˆâ–ˆâ–‰       | 37/125 [05:31<13:03,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 38/125 [05:40<12:52,  8.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  31%|â–ˆâ–ˆâ–ˆ       | 39/125 [05:49<12:42,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [05:58<12:34,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 41/125 [06:07<12:24,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 42/125 [06:16<12:15,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [06:24<12:04,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [06:33<11:53,  8.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [06:42<11:43,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [06:51<11:33,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [07:00<11:25,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [07:08<11:17,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [07:17<11:08,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [07:26<10:59,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [07:35<10:50,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [07:44<10:42,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [07:52<10:33,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/125 [08:01<10:25,  8.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [08:10<10:18,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [08:19<10:10,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [08:28<10:00,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [08:37<09:52,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [08:46<09:45,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [08:54<09:38,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [09:03<09:30,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [09:12<09:21,  8.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [09:21<09:12,  8.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [09:30<09:02,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [09:39<08:51,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/125 [09:48<08:41,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/125 [09:56<08:31,  8.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [10:05<08:25,  8.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [10:14<08:15,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [10:23<08:05,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [10:32<07:59,  8.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [10:41<07:51,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [10:50<07:44,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [10:59<07:35,  8.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [11:08<07:27,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [11:17<07:18,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [11:26<07:09,  8.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [11:35<06:58,  8.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/125 [11:43<06:48,  8.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [11:52<06:38,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [12:01<06:28,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [12:10<06:19,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [12:19<06:10,  8.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [12:27<06:00,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [12:36<05:51,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [12:45<05:42,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [12:54<05:35,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [13:03<05:28,  8.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [13:12<05:19,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [13:21<05:10,  8.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 91/125 [13:29<05:00,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/125 [13:38<04:51,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [13:47<04:43,  8.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [13:56<04:34,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [14:05<04:25,  8.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [14:13<04:16,  8.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [14:22<04:06,  8.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [14:31<03:57,  8.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [14:40<03:48,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [14:49<03:39,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [14:57<03:30,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [15:06<03:22,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [15:15<03:13,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/125 [15:24<03:04,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [15:32<02:55,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [15:41<02:46,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [15:50<02:37,  8.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [15:59<02:28,  8.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [16:08<02:20,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [16:16<02:11,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [16:25<02:03,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [16:34<01:54,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [16:43<01:45,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [16:51<01:36,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [17:00<01:27,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 116/125 [17:09<01:18,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/125 [17:18<01:10,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [17:27<01:01,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [17:35<00:52,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [17:44<00:43,  8.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [17:53<00:35,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [18:02<00:26,  8.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [18:10<00:17,  8.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [18:19<00:08,  8.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "æµ‹è¯•ä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [18:28<00:00,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•é›†å¹³å‡æŸå¤±: 0.8200\n",
      "æµ‹è¯•æ ·æœ¬æ•°: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "def evaluate_model(model, test_loader, tokenizer):\n",
    "    \"\"\"\n",
    "    è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"æµ‹è¯•ä¸­\"):\n",
    "            input_ids = batch[\"input_ids\"].to(model.device)\n",
    "            labels = batch[\"labels\"].to(model.device)\n",
    "            \n",
    "            # è®¡ç®—æŸå¤±\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # ç”Ÿæˆé¢„æµ‹\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens=max_length,  # æœ€å¤§ç”Ÿæˆ100ä¸ªæ–°token\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            # è§£ç é¢„æµ‹ç»“æœå’Œç›®æ ‡\n",
    "            for i in range(len(generated_ids)):\n",
    "                # è·å–è¾“å…¥éƒ¨åˆ†ï¼ˆç”¨äºæå–æŒ‡ä»¤ï¼‰\n",
    "                input_text = tokenizer.decode(input_ids[i], skip_special_tokens=True)\n",
    "                \n",
    "                # è·å–ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆå»æ‰è¾“å…¥éƒ¨åˆ†ï¼‰\n",
    "                generated_text = tokenizer.decode(generated_ids[i][len(input_ids[i]):], skip_special_tokens=True)\n",
    "                \n",
    "                # è·å–ç›®æ ‡ç­”æ¡ˆ\n",
    "                target_text = tokenizer.decode(labels[i][labels[i] != -100], skip_special_tokens=True)\n",
    "                \n",
    "                all_predictions.append(generated_text.strip())\n",
    "                all_targets.append(target_text.strip())\n",
    "    \n",
    "    # è®¡ç®—å¹³å‡æŸå¤±\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    return avg_loss, all_predictions, all_targets\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "print(\"å¼€å§‹æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹...\")\n",
    "test_loss, predictions, targets = evaluate_model(finetuned_model, test_loader, tokenizer)\n",
    "\n",
    "print(f\"æµ‹è¯•é›†å¹³å‡æŸå¤±: {test_loss:.4f}\")\n",
    "print(f\"æµ‹è¯•æ ·æœ¬æ•°: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce1c79-b8fb-491c-93ab-fc38c8cc87f6",
   "metadata": {},
   "source": [
    "### LLMæ¨¡å‹å…¶ä»–å¸¸è§æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16187a-deba-4cd8-a422-23a785d0411b",
   "metadata": {},
   "source": [
    "| æŒ‡æ ‡                   | è¯´æ˜                  | é€‚ç”¨åœºæ™¯        |\n",
    "| -------------------- | ------------------- | ----------- |\n",
    "| **BLEU**             | n-gram ç²¾ç¡®åŒ¹é…         | ç¿»è¯‘ã€æ‘˜è¦       |\n",
    "| **ROUGE**            | å…³æ³¨ recallï¼ˆè¦†ç›–ç‡ï¼‰      | æ‘˜è¦ç”Ÿæˆã€é—®ç­”     |\n",
    "| **METEOR**           | è€ƒè™‘åŒä¹‰è¯åŒ¹é…             | æ–‡æœ¬ç”Ÿæˆ        |\n",
    "| **BERTScore**        | åŸºäºè¯­ä¹‰åµŒå…¥æ¯”è¾ƒæ–‡æœ¬ç›¸ä¼¼åº¦       | ç”Ÿæˆä»»åŠ¡ï¼Œè¯­ä¹‰è¯„ä»·   |\n",
    "| **Exact Match (EM)** | å®Œå…¨åŒ¹é…                | é—®ç­”ã€é€‰æ‹©é¢˜ã€é€»è¾‘è¾“å‡º |\n",
    "| **Perplexity (å›°æƒ‘åº¦)** | æ¨¡å‹é¢„æµ‹ token çš„æ¦‚ç‡åæ˜ æµç•…åº¦ | æ–‡æœ¬ç”Ÿæˆã€è¯­è¨€å»ºæ¨¡   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beba284-8802-4cba-b5b5-44dde5215d2f",
   "metadata": {},
   "source": [
    "### è®¡ç®—BERTScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19093e-5068-458e-80fc-fa56fd371b1c",
   "metadata": {},
   "source": [
    "| æŒ‡æ ‡                | å«ä¹‰               | å€¼åŸŸ     | è¶Šå¤§è¶Šå¥½ï¼Ÿ  |\n",
    "| ----------------- | ---------------- | ------ | ------ |\n",
    "| **Precision (P)** | ç”Ÿæˆæ–‡æœ¬å’Œç›®æ ‡æ–‡æœ¬è¯­ä¹‰é‡å çš„æ¯”ä¾‹ | 0 \\~ 1 | âœ… è¶Šå¤§è¶Šå¥½ |\n",
    "| **Recall (R)**    | ç›®æ ‡æ–‡æœ¬ä¸­è¢«ç”Ÿæˆæ–‡æœ¬è¦†ç›–çš„æ¯”ä¾‹  | 0 \\~ 1 | âœ… è¶Šå¤§è¶Šå¥½ |\n",
    "| **F1-score (F1)** | P å’Œ R çš„è°ƒå’Œå¹³å‡      | 0 \\~ 1 | âœ… è¶Šå¤§è¶Šå¥½ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2424cfee-7520-4949-88ff-f33b513603da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T18:36:51.340282Z",
     "iopub.status.busy": "2025-08-26T18:36:51.339993Z",
     "iopub.status.idle": "2025-08-26T18:37:13.341487Z",
     "shell.execute_reply": "2025-08-26T18:37:13.340633Z",
     "shell.execute_reply.started": "2025-08-26T18:36:51.340262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/site-packages (from bert-score) (2.3.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/site-packages (from bert-score) (2.3.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/site-packages (from bert-score) (4.55.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from bert-score) (3.10.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.8.93)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheck your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:704\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    703\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x7f3448666550>: Failed to establish a new connection: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3448666550>: Failed to establish a new connection: [Errno 101] Network is unreachable'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m429\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3448666550>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 67401b3e-0660-4c5b-a10d-0c0fd03c81d2)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1661\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1662\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1663\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1664\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is on.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1665\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhead_call_error\u001b[39;00m\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbert_score\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m score\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# å‡è®¾ predictions å’Œ targets å·²ç»æ˜¯ä½ çš„ç”Ÿæˆç»“æœå’ŒçœŸå®ç­”æ¡ˆåˆ—è¡¨\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m P, R, F1 = \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# lang å¯ä»¥æ ¹æ®ä»»åŠ¡é€‰æ‹© 'en' æˆ– 'zh'\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# P, R, F1 éƒ½æ˜¯ tensorï¼Œå½¢çŠ¶ä¸º [æ ·æœ¬æ•°]\u001b[39;00m\n\u001b[32m      9\u001b[39m avg_precision = P.mean().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/bert_score/score.py:97\u001b[39m, in \u001b[36mscore\u001b[39m\u001b[34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_layers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     95\u001b[39m     num_layers = model2layers[model_type]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m tokenizer = \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m model = get_model(model_type, num_layers, all_layers)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/bert_score/utils.py:329\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m(model_type, use_fast)\u001b[39m\n\u001b[32m    326\u001b[39m     model_type = cache_scibert(model_type)\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version.parse(trans_version) >= version.parse(\u001b[33m\"\u001b[39m\u001b[33m4.0.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_fast, \u001b[33m\"\u001b[39m\u001b[33mFast tokenizer is not available for version < 4.0.0\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1069\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1067\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1250\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1247\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1248\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1252\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:649\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    647\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:708\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    704\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    707\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    723\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:553\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;66;03m# Here we only raise if both flags for missing entry and connection errors are True (because it can be raised\u001b[39;00m\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[39;00m\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    554\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to load the files, and couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find them in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    555\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m cached files.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCheck your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    557\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# snapshot_download will not raise EntryNotFoundError, but hf_hub_download can. If this is the case, it will be treated\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# later on anyway and re-raised if needed\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, HTTPError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
      "\u001b[31mOSError\u001b[39m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheck your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "%pip install bert-score\n",
    "\n",
    "from bert_score import score\n",
    "\n",
    "# å‡è®¾ predictions å’Œ targets å·²ç»æ˜¯ä½ çš„ç”Ÿæˆç»“æœå’ŒçœŸå®ç­”æ¡ˆåˆ—è¡¨\n",
    "P, R, F1 = score(predictions, targets, lang=\"zh\", verbose=True)  # lang å¯ä»¥æ ¹æ®ä»»åŠ¡é€‰æ‹© 'en' æˆ– 'zh'\n",
    "\n",
    "# P, R, F1 éƒ½æ˜¯ tensorï¼Œå½¢çŠ¶ä¸º [æ ·æœ¬æ•°]\n",
    "avg_precision = P.mean().item()\n",
    "avg_recall = R.mean().item()\n",
    "avg_f1 = F1.mean().item()\n",
    "\n",
    "print(f\"BERTScore å¹³å‡ Precision: {avg_precision:.4f}\")\n",
    "print(f\"BERTScore å¹³å‡ Recall:    {avg_recall:.4f}\")\n",
    "print(f\"BERTScore å¹³å‡ F1:        {avg_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "share": {
   "datetime": "2025-08-26T18:37:20.068Z",
   "image": {
    "name": "modelscope:1.29.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.29.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04"
   },
   "instance": "dsw-p7b6usueey5pxo2vcy",
   "spec": {
    "id": "ecs.gn7i-c8g1.2xlarge",
    "type": "GPU"
   },
   "uid": "1189516462147384"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
