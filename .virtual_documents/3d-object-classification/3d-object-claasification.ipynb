











# 安装必要的依赖包
%pip install datasets
%pip install open3d
%pip install matplotlib
%pip install numpy
%pip install plotly
%pip install trimesh



# 导入必要的库
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from datasets import load_dataset
import os
import requests
from tqdm import tqdm
import zipfile






# 数据结构分析（只显示存储方式）
print("=== 数据结构分析 ===")
print(f"数据集分割: {list(dataset.keys())}")
print(f"训练集: {len(dataset['train'])} 样本")
print(f"测试集: {len(dataset['test'])} 样本")

# 分析数据存储结构
sample = dataset['train'][0]
print(f"\n数据存储结构:")
print(f"  字段: {list(sample.keys())}")

# 分析每个字段的存储方式
for key, value in sample.items():
    if hasattr(value, 'shape'):
        print(f"  {key}: 数组存储, shape {value.shape}")
    elif isinstance(value, (int, float)):
        print(f"  {key}: 数值存储, 值 {value}")
    elif isinstance(value, str):
        print(f"  {key}: 字符串存储, 长度 {len(value)}")
    else:
        print(f"  {key}: {type(value).__name__} 存储")

# 分析标签结构
print(f"\n标签分析:")
label = sample.get('label', sample.get('class', sample.get('category', 'N/A')))
print(f"  标签字段: {'label' if 'label' in sample else 'class' if 'class' in sample else 'category'}")
print(f"  标签值: {label}")
print(f"  标签类型: {type(label).__name__}")

# 检查标签范围
if isinstance(label, (int, float)):
    print(f"  标签范围: 数值型标签")
else:
    print(f"  标签范围: 字符串型标签")



# 点云数据存储分析
def analyze_point_cloud_storage(sample):
    """分析点云数据的存储方式"""
    # 查找点云数据字段
    points_key = None
    for key in sample.keys():
        if 'point' in key.lower() or 'data' in key.lower():
            points_key = key
            break
    
    if points_key:
        points = sample[points_key]
        print(f"点云数据字段: {points_key}")
        print(f"  存储方式: 数组存储")
        print(f"  数据形状: {points.shape}")
        print(f"  数据类型: {points.dtype}")
        print(f"  数据范围: [{points.min():.3f}, {points.max():.3f}]")
        return points
    else:
        print("未找到点云数据字段")
        return None

# 分析数据存储方式
print("=== 点云数据存储分析 ===")
sample_data = dataset['train'][0]
points = analyze_point_cloud_storage(sample_data)

if points is not None:
    print(f"\n点云数据特点:")
    print(f"  维度: {points.shape[1]}D (X, Y, Z坐标)")
    print(f"  点数: {points.shape[0]} 个点")
    print(f"  存储格式: NumPy数组")
    print(f"  内存占用: {points.nbytes / 1024:.1f} KB")



# 标签系统分析
def analyze_label_system(dataset, sample_size=100):
    """分析标签系统的结构"""
    train_data = dataset['train']
    sample_data = train_data[:sample_size]
    
    print("=== 标签系统分析 ===")
    
    # 分析标签字段
    sample = sample_data[0]
    label_field = None
    for key in ['label', 'class', 'category', 'target']:
        if key in sample:
            label_field = key
            break
    
    print(f"标签字段: {label_field}")
    
    # 分析标签类型和分布
    labels = []
    for item in sample_data:
        label = item.get(label_field, 'N/A')
        labels.append(label)
    
    unique_labels = set(labels)
    print(f"标签类型: {type(labels[0]).__name__}")
    print(f"唯一标签数: {len(unique_labels)}")
    print(f"标签范围: {min(labels)} - {max(labels)}" if isinstance(labels[0], (int, float)) else "字符串标签")
    
    # 显示标签分布
    from collections import Counter
    label_counts = Counter(labels)
    print(f"\n标签分布（前10个）:")
    for label, count in label_counts.most_common(10):
        print(f"  {label}: {count} 个样本")
    
    return label_field, unique_labels

# 分析标签系统
label_field, unique_labels = analyze_label_system(dataset)



# 数据存储总结
def summarize_data_storage(dataset):
    """总结数据存储方式"""
    print("=== 数据存储总结 ===")
    
    # 数据集基本信息
    train_data = dataset['train']
    test_data = dataset['test']
    sample = train_data[0]
    
    print(f"数据集结构:")
    print(f"  训练集: {len(train_data)} 样本")
    print(f"  测试集: {len(test_data)} 样本")
    print(f"  样本字段: {list(sample.keys())}")
    
    # 点云数据存储
    points_key = None
    for key in sample.keys():
        if 'point' in key.lower() or 'data' in key.lower():
            points_key = key
            break
    
    if points_key:
        points = sample[points_key]
        print(f"\n点云数据存储:")
        print(f"  字段名: {points_key}")
        print(f"  存储格式: NumPy数组")
        print(f"  数据形状: {points.shape}")
        print(f"  数据类型: {points.dtype}")
        print(f"  内存占用: {points.nbytes / 1024:.1f} KB")
    
    # 标签存储
    label_field = None
    for key in ['label', 'class', 'category', 'target']:
        if key in sample:
            label_field = key
            break
    
    if label_field:
        label = sample[label_field]
        print(f"\n标签存储:")
        print(f"  字段名: {label_field}")
        print(f"  标签类型: {type(label).__name__}")
        print(f"  标签值: {label}")
    
    print(f"\n数据访问方式:")
    print(f"  dataset['train'][index] - 访问训练样本")
    print(f"  dataset['test'][index] - 访问测试样本")
    print(f"  sample['{points_key}'] - 访问点云数据")
    print(f"  sample['{label_field}'] - 访问标签")

# 执行数据存储总结
summarize_data_storage(dataset)






# 从Hugging Face下载ModelNet40数据集
print("正在从Hugging Face下载ModelNet40数据集...")

# 使用jxie/modelnet40数据集
dataset = load_dataset("jxie/modelnet40")

print("数据集下载完成！")
print(f"数据集结构: {dataset}")
print(f"训练集大小: {len(dataset['train'])}")
print(f"测试集大小: {len(dataset['test'])}")



# 查看数据集的基本信息
print("=== 数据集基本信息 ===")
print(f"特征字段: {dataset['train'].features}")
print(f"样本示例: {dataset['train'][0]}")

# 查看类别分布
train_labels = [item['label'] for item in dataset['train']]
test_labels = [item['label'] for item in dataset['test']]

print(f"\n训练集标签范围: {min(train_labels)} - {max(train_labels)}")
print(f"测试集标签范围: {min(test_labels)} - {max(test_labels)}")

# 统计每个类别的样本数量
from collections import Counter
train_label_counts = Counter(train_labels)
test_label_counts = Counter(test_labels)

print(f"\n训练集类别分布（前10个）:")
for label, count in train_label_counts.most_common(10):
    print(f"类别 {label}: {count} 个样本")

print(f"\n测试集类别分布（前10个）:")
for label, count in test_label_counts.most_common(10):
    print(f"类别 {label}: {count} 个样本")






# 定义ModelNet40的40个类别名称
modelnet40_classes = [
    'airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair',
    'cone', 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box',
    'guitar', 'keyboard', 'lamp', 'laptop', 'mantel', 'monitor', 'night_stand',
    'person', 'piano', 'plant', 'radio', 'range_hood', 'sink', 'sofa', 'stairs',
    'stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox'
]

print("ModelNet40数据集包含的40个类别:")
for i, class_name in enumerate(modelnet40_classes):
    print(f"{i:2d}. {class_name}")

# 创建标签到类别名称的映射
label_to_class = {i: class_name for i, class_name in enumerate(modelnet40_classes)}
class_to_label = {class_name: i for i, class_name in enumerate(modelnet40_classes)}

print(f"\n标签映射示例:")
print(f"标签 0 -> {label_to_class[0]}")
print(f"标签 5 -> {label_to_class[5]}")
print(f"标签 39 -> {label_to_class[39]}")



# 数据预处理函数
def preprocess_point_cloud(points, num_points=1024):
    """
    预处理点云数据
    Args:
        points: 原始点云数据 (N, 3)
        num_points: 目标点数
    Returns:
        处理后的点云数据
    """
    # 随机采样到固定点数
    if len(points) > num_points:
        indices = np.random.choice(len(points), num_points, replace=False)
        points = points[indices]
    elif len(points) < num_points:
        # 如果点数不足，随机重复采样
        indices = np.random.choice(len(points), num_points, replace=True)
        points = points[indices]
    
    # 归一化到单位球
    centroid = np.mean(points, axis=0)
    points = points - centroid
    max_dist = np.max(np.linalg.norm(points, axis=1))
    points = points / max_dist
    
    return points

# 测试数据预处理
sample_data = dataset['train'][0]
print("原始数据示例:")
print(f"点云形状: {sample_data['points'].shape}")
print(f"标签: {sample_data['label']} -> {label_to_class[sample_data['label']]}")

# 预处理示例数据
processed_points = preprocess_point_cloud(sample_data['points'])
print(f"\n预处理后点云形状: {processed_points.shape}")
print(f"点云范围: [{processed_points.min():.3f}, {processed_points.max():.3f}]")






# 使用Plotly进行3D点云可视化
def visualize_point_cloud_plotly(points, title="3D Point Cloud", colors=None):
    """
    使用Plotly可视化3D点云
    Args:
        points: 点云数据 (N, 3)
        title: 图表标题
        colors: 颜色数组，可选
    """
    if colors is None:
        colors = points[:, 2]  # 使用Z坐标作为颜色
    
    fig = go.Figure(data=[go.Scatter3d(
        x=points[:, 0],
        y=points[:, 1], 
        z=points[:, 2],
        mode='markers',
        marker=dict(
            size=2,
            color=colors,
            colorscale='Viridis',
            opacity=0.8
        ),
        text=[f'Point {i}' for i in range(len(points))],
        hovertemplate='X: %{x}<br>Y: %{y}<br>Z: %{z}<extra></extra>'
    )])
    
    fig.update_layout(
        title=title,
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z',
            aspectmode='cube'
        ),
        width=800,
        height=600
    )
    
    return fig

# 可视化几个不同类别的样本
print("正在生成3D可视化...")

# 选择几个不同类别的样本进行展示
sample_indices = [0, 100, 200, 300, 400]  # 选择5个样本
figs = []

for i, idx in enumerate(sample_indices):
    sample = dataset['train'][idx]
    points = preprocess_point_cloud(sample['points'])
    class_name = label_to_class[sample['label']]
    
    fig = visualize_point_cloud_plotly(
        points, 
        title=f"样本 {i+1}: {class_name} (标签: {sample['label']})"
    )
    figs.append(fig)

# 显示第一个样本
print("显示第一个3D样本:")
figs[0].show()



# 使用Matplotlib进行2D投影可视化
def visualize_point_cloud_2d(points, title="2D Projection", ax=None):
    """
    使用Matplotlib可视化3D点云的2D投影
    Args:
        points: 点云数据 (N, 3)
        title: 图表标题
        ax: matplotlib轴对象
    """
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(8, 6))
    
    # XY平面投影
    ax.scatter(points[:, 0], points[:, 1], c=points[:, 2], 
               cmap='viridis', s=1, alpha=0.6)
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_title(title)
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal')
    
    return ax

# 创建多个子图展示不同类别的样本
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

print("生成2D投影可视化...")

for i, idx in enumerate(sample_indices[:6]):  # 显示前6个样本
    sample = dataset['train'][idx]
    points = preprocess_point_cloud(sample['points'])
    class_name = label_to_class[sample['label']]
    
    visualize_point_cloud_2d(
        points, 
        title=f"{class_name} (标签: {sample['label']})",
        ax=axes[i]
    )

# 隐藏多余的子图
for i in range(len(sample_indices), len(axes)):
    axes[i].set_visible(False)

plt.tight_layout()
plt.show()



# 数据集统计分析
def analyze_dataset_statistics(dataset):
    """
    分析数据集的统计信息
    """
    train_data = dataset['train']
    test_data = dataset['test']
    
    # 统计每个类别的样本数量
    train_labels = [item['label'] for item in train_data]
    test_labels = [item['label'] for item in test_data]
    
    train_counts = Counter(train_labels)
    test_counts = Counter(test_labels)
    
    # 计算点云大小统计
    train_point_counts = [len(item['points']) for item in train_data]
    test_point_counts = [len(item['points']) for item in test_data]
    
    print("=== 数据集统计信息 ===")
    print(f"训练集样本数: {len(train_data)}")
    print(f"测试集样本数: {len(test_data)}")
    print(f"总样本数: {len(train_data) + len(test_data)}")
    print(f"类别数: {len(set(train_labels))}")
    
    print(f"\n训练集点云大小统计:")
    print(f"  平均点数: {np.mean(train_point_counts):.1f}")
    print(f"  最小点数: {min(train_point_counts)}")
    print(f"  最大点数: {max(train_point_counts)}")
    print(f"  标准差: {np.std(train_point_counts):.1f}")
    
    print(f"\n测试集点云大小统计:")
    print(f"  平均点数: {np.mean(test_point_counts):.1f}")
    print(f"  最小点数: {min(test_point_counts)}")
    print(f"  最大点数: {max(test_point_counts)}")
    print(f"  标准差: {np.std(test_point_counts):.1f}")
    
    return train_counts, test_counts

# 执行统计分析
train_counts, test_counts = analyze_dataset_statistics(dataset)



# 可视化类别分布
def plot_class_distribution(train_counts, test_counts, top_n=20):
    """
    绘制类别分布图
    """
    # 获取前N个最常见的类别
    common_classes = set(train_counts.keys()) & set(test_counts.keys())
    common_classes = sorted(common_classes)[:top_n]
    
    train_values = [train_counts[cls] for cls in common_classes]
    test_values = [test_counts[cls] for cls in common_classes]
    class_names = [label_to_class[cls] for cls in common_classes]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # 训练集分布
    ax1.bar(range(len(common_classes)), train_values, color='skyblue', alpha=0.7)
    ax1.set_xlabel('类别')
    ax1.set_ylabel('样本数量')
    ax1.set_title('训练集类别分布（前20个）')
    ax1.set_xticks(range(len(common_classes)))
    ax1.set_xticklabels(class_names, rotation=45, ha='right')
    ax1.grid(True, alpha=0.3)
    
    # 测试集分布
    ax2.bar(range(len(common_classes)), test_values, color='lightcoral', alpha=0.7)
    ax2.set_xlabel('类别')
    ax2.set_ylabel('样本数量')
    ax2.set_title('测试集类别分布（前20个）')
    ax2.set_xticks(range(len(common_classes)))
    ax2.set_xticklabels(class_names, rotation=45, ha='right')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# 绘制类别分布图
print("生成类别分布可视化...")
plot_class_distribution(train_counts, test_counts)










